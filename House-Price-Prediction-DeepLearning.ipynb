{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Library.DataAnalyzer import DataAnalyzer\n",
    "from Library.DataPreprocessor import DataPreprocessor\n",
    "from Library.DataVisualizer import DataVisualizer\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "analyzer = DataAnalyzer()\n",
    "visualizer = DataVisualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.calculateNullValuesSum(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>3211800140</td>\n",
       "      <td>20150205T000000</td>\n",
       "      <td>493500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1800</td>\n",
       "      <td>16026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1390</td>\n",
       "      <td>410</td>\n",
       "      <td>1972</td>\n",
       "      <td>0</td>\n",
       "      <td>98008</td>\n",
       "      <td>47.5815</td>\n",
       "      <td>-122.121</td>\n",
       "      <td>2210</td>\n",
       "      <td>13959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>2288000090</td>\n",
       "      <td>20150429T000000</td>\n",
       "      <td>980000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2260</td>\n",
       "      <td>17711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5498</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>2880</td>\n",
       "      <td>16594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>7852011040</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>589000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2910</td>\n",
       "      <td>5776</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2910</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5388</td>\n",
       "      <td>-121.870</td>\n",
       "      <td>2550</td>\n",
       "      <td>6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9430</th>\n",
       "      <td>6117501755</td>\n",
       "      <td>20141230T000000</td>\n",
       "      <td>355000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2230</td>\n",
       "      <td>11536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1220</td>\n",
       "      <td>1010</td>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>98166</td>\n",
       "      <td>47.4409</td>\n",
       "      <td>-122.348</td>\n",
       "      <td>2170</td>\n",
       "      <td>12465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>3546000090</td>\n",
       "      <td>20150224T000000</td>\n",
       "      <td>199500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1690</td>\n",
       "      <td>8901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1690</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>98030</td>\n",
       "      <td>47.3546</td>\n",
       "      <td>-122.176</td>\n",
       "      <td>1690</td>\n",
       "      <td>7532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "10145  3211800140  20150205T000000  493500.0         3       1.75   \n",
       "3500   2288000090  20150429T000000  980000.0         4       1.75   \n",
       "12239  7852011040  20140521T000000  589000.0         4       2.50   \n",
       "9430   6117501755  20141230T000000  355000.0         4       1.50   \n",
       "4269   3546000090  20150224T000000  199500.0         3       1.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "10145         1800     16026     1.0           0     0  ...      8   \n",
       "3500          2260     17711     1.0           0     1  ...      9   \n",
       "12239         2910      5776     2.0           0     2  ...      8   \n",
       "9430          2230     11536     1.0           0     1  ...      7   \n",
       "4269          1690      8901     1.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "10145        1390            410      1972             0    98008  47.5815   \n",
       "3500         2260              0      1968             0    98040  47.5498   \n",
       "12239        2910              0      1998             0    98065  47.5388   \n",
       "9430         1220           1010      1954             0    98166  47.4409   \n",
       "4269         1690              0      1986             0    98030  47.3546   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "10145 -122.121           2210       13959  \n",
       "3500  -122.214           2880       16594  \n",
       "12239 -121.870           2550        6750  \n",
       "9430  -122.348           2170       12465  \n",
       "4269  -122.176           1690        7532  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.zipcode = df.zipcode.astype(\"category\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAGsCAYAAAC/7fziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtJklEQVR4nO3de3DU5b3H8U8Wk024bBKgJAQDJ2rlJgaBGnPU2JZMgmWsoGcqEAtHIxw19IDxqNAKQo8tEI4eUREO01F6porCmYIKXki5ZdTIZSHhIqZoqdHghgFMFsiFwD7nD8xvXIPyZNl0E3i/Zn4z2ef33We/z/50P+zub3ejjDFGAADgvFyRbgAAgI6C0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYuizSDURSIBDQoUOH1K1bN0VFRUW6HQBABBhjdPz4caWkpMjl+v7nkpd0aB46dEipqamRbgMA0A58/vnnuvzyy7+35pIOzW7dukk6e0d5PJ4IdwMAiAS/36/U1FQnE77PJR2azS/JejweQhMALnE2b9NxIhAAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgKVL+vc0w6WyslJHjhyJdBuSpJ49e6pv376RbgMALkqE5gWqrKxU//4D1dBQF+lWJEmxsZ1VUbGf4ASANkBoXqAjR458HZh/kjQwwt3sV0PD3Tpy5AihCQBtgNAMm4GShkW6CQBAG+JEIAAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWWh2aJSUluu2225SSkqKoqCitWbPG2dfU1KTHHntMQ4YMUZcuXZSSkqKJEyfq0KFDQXMcO3ZMeXl58ng8SkhIUH5+vk6cOBFUs3v3bt18882KjY1VamqqioqKWvSyatUqDRgwQLGxsRoyZIjeeuut1i4HAABrrQ7NkydPKj09XYsXL26xr66uTjt37tSsWbO0c+dO/fnPf1ZFRYV+/vOfB9Xl5eVp3759Ki4u1tq1a1VSUqIpU6Y4+/1+v3JyctSvXz95vV4tXLhQc+bM0bJly5yaDz74QOPHj1d+fr527dqlMWPGaMyYMdq7d29rlwQAgJUoY4wJ+cpRUVq9erXGjBnznTXbt2/X9ddfr88++0x9+/bV/v37NWjQIG3fvl0jRoyQJL3zzjv62c9+pi+++EIpKSlasmSJfvOb38jn8ykmJkaSNGPGDK1Zs0Yff/yxJOmuu+7SyZMntXbtWue2brjhBg0dOlRLly49Zy+NjY1qbGx0Lvv9fqWmpurIkSPyeDwh3Qfl5eXKysqSVCIpPaQ5wqdcUpZKSkqUnh7pXgCgY/D7/erZs6dqa2vPmwWXtXUztbW1ioqKUkJCgiSptLRUCQkJTmBKUnZ2tlwul7Zu3aqxY8eqtLRUWVlZTmBKUm5urhYsWKCvvvpKiYmJKi0tVWFhYdBt5ebmBr1c/G3z5s3T3LlzW4yvX79enTt3DnmNK1askFT19RZpK1RVVaWqqvbQCwC0f3V1dda1bRqaDQ0NeuyxxzR+/HgnvX0+n3r16hXcxGWXqXv37vL5fE5NWlpaUE1SUpKzLzExUT6fzxn7Zk3zHOcyc+bMoKBtfqaZk5PDM00AuET5/X7r2jYLzaamJv3iF7+QMUZLlixpq5tpFbfbLbfb3WI8Ojpa0dHRIc3pcrlUX1+vs28PhzZH+Lgk1cvlcoW8HgC41LTm8bJNQrM5MD/77DNt3Lgx6FlccnKyDh8+HFR/+vRpHTt2TMnJyU5NdXV1UE3z5fPVNO8HACDcwv45zebAPHDggP7yl7+oR48eQfszMzNVU1Mjr9frjG3cuFGBQEAZGRlOTUlJiZqampya4uJi9e/fX4mJiU7Nhg0bguYuLi5WZmZmuJcEAICkEELzxIkTKisrU1lZmSTp4MGDKisrU2VlpZqamvQv//Iv2rFjh15++WWdOXNGPp9PPp9Pp06dkiQNHDhQo0aN0uTJk7Vt2za9//77mjp1qsaNG6eUlBRJ0oQJExQTE6P8/Hzt27dPr732mhYtWhT0fuS0adP0zjvv6KmnntLHH3+sOXPmaMeOHZo6dWoY7hYAAM7BtNKmTZuMpBbbpEmTzMGDB8+5T5LZtGmTM8fRo0fN+PHjTdeuXY3H4zH33HOPOX78eNDtlJeXm5tuusm43W7Tp08fM3/+/Ba9rFy50lx99dUmJibGDB482Kxbt65Va6mtrTWSTG1tbWvvBofX6/16jV4jmQhvZ3vxer0hrwcALjWtyYIL+pxmR+f3+xUfH2/12ZzvsnPnTg0fPlySV9KwsPYXQjeShsvr9WrYsEj3AgAdQ2uygO+eBQDAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYanVolpSU6LbbblNKSoqioqK0Zs2aoP3GGM2ePVu9e/dWXFycsrOzdeDAgaCaY8eOKS8vTx6PRwkJCcrPz9eJEyeCanbv3q2bb75ZsbGxSk1NVVFRUYteVq1apQEDBig2NlZDhgzRW2+91drlAABgrdWhefLkSaWnp2vx4sXn3F9UVKRnn31WS5cu1datW9WlSxfl5uaqoaHBqcnLy9O+fftUXFystWvXqqSkRFOmTHH2+/1+5eTkqF+/fvJ6vVq4cKHmzJmjZcuWOTUffPCBxo8fr/z8fO3atUtjxozRmDFjtHfv3tYuCQAAO+YCSDKrV692LgcCAZOcnGwWLlzojNXU1Bi3221WrFhhjDHmo48+MpLM9u3bnZq3337bREVFmaqqKmOMMS+88IJJTEw0jY2NTs1jjz1m+vfv71z+xS9+YUaPHh3UT0ZGhvm3f/s36/5ra2uNJFNbW2t9nW/zer1GkpG8RjIR3s724vV6Q14PAFxqWpMFl4UzgA8ePCifz6fs7GxnLD4+XhkZGSotLdW4ceNUWlqqhIQEjRgxwqnJzs6Wy+XS1q1bNXbsWJWWliorK0sxMTFOTW5urhYsWKCvvvpKiYmJKi0tVWFhYdDt5+bmtni5+JsaGxvV2NjoXPb7/ZKkpqYmNTU1hbTmQCCguLg4SQFJoc0RPgFJcQoEAiGvBwAuNa15vAxraPp8PklSUlJS0HhSUpKzz+fzqVevXsFNXHaZunfvHlSTlpbWYo7mfYmJifL5fN97O+cyb948zZ07t8X4+vXr1blzZ5slntOKFSskVX29RdoKVVVVqaqqPfQCAO1fXV2ddW1YQ7O9mzlzZtCzU7/fr9TUVOXk5Mjj8YQ0Z3l5ubKysiSVSEoPT6MhK5eUpZKSEqWnR7oXAOgYml91tBHW0ExOTpYkVVdXq3fv3s54dXW1hg4d6tQcPnw46HqnT5/WsWPHnOsnJyeruro6qKb58vlqmvefi9vtltvtbjEeHR2t6OhomyW24HK5VF9fr7PnVIU2R/i4JNXL5XKFvB4AuNS05vEyrJ/TTEtLU3JysjZs2OCM+f1+bd26VZmZmZKkzMxM1dTUyOv1OjUbN25UIBBQRkaGU1NSUhL0OnNxcbH69++vxMREp+abt9Nc03w7AACEW6tD88SJEyorK1NZWZmksyf/lJWVqbKyUlFRUZo+fbqefPJJvfHGG9qzZ48mTpyolJQUjRkzRpI0cOBAjRo1SpMnT9a2bdv0/vvva+rUqRo3bpxSUlIkSRMmTFBMTIzy8/O1b98+vfbaa1q0aFHQS6vTpk3TO++8o6eeekoff/yx5syZox07dmjq1KkXfq8AAHAurT01d9OmTV9/xCJ4mzRpkjHm7MdOZs2aZZKSkozb7TYjR440FRUVQXMcPXrUjB8/3nTt2tV4PB5zzz33mOPHjwfVlJeXm5tuusm43W7Tp08fM3/+/Ba9rFy50lx99dUmJibGDB482Kxbt65Va+EjJwCA1mRBlDHGRCyxI8zv9ys+Pl61tbUhnwi0c+dODR8+XJJX0rCw9hdCN5KGy+v1atiwSPcCAB1Da7KA754FAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS5dFugGE3/79+yPdgqNnz57q27dvpNsAgLAgNC8qX0py6e677450I47Y2M6qqNhPcAK4KBCaF5UaSQFJf5I0MLKtSJL2q6Hhbh05coTQBHBRIDQvSgMlDYt0EwBw0eFEIAAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS2EPzTNnzmjWrFlKS0tTXFycrrzySv3nf/6njDFOjTFGs2fPVu/evRUXF6fs7GwdOHAgaJ5jx44pLy9PHo9HCQkJys/P14kTJ4Jqdu/erZtvvlmxsbFKTU1VUVFRuJcDAIAj7KG5YMECLVmyRM8//7z279+vBQsWqKioSM8995xTU1RUpGeffVZLly7V1q1b1aVLF+Xm5qqhocGpycvL0759+1RcXKy1a9eqpKREU6ZMcfb7/X7l5OSoX79+8nq9WrhwoebMmaNly5aFe0kAAJxlwmz06NHm3nvvDRq74447TF5enjHGmEAgYJKTk83ChQud/TU1NcbtdpsVK1YYY4z56KOPjCSzfft2p+btt982UVFRpqqqyhhjzAsvvGASExNNY2OjU/PYY4+Z/v37W/daW1trJJna2trWL/RrXq/XSDKS10gmwtuf2lEv5us+ZLxeb8j3LwC0tdZkwWXhDuF//ud/1rJly/TXv/5VV199tcrLy/Xee+/p6aefliQdPHhQPp9P2dnZznXi4+OVkZGh0tJSjRs3TqWlpUpISNCIESOcmuzsbLlcLm3dulVjx45VaWmpsrKyFBMT49Tk5uZqwYIF+uqrr5SYmNiit8bGRjU2NjqX/X6/JKmpqUlNTU0hrTcQCCguLk5SQFJoc4RXe+olIClOgUAg5PsXANpaax6fwh6aM2bMkN/v14ABA9SpUyedOXNGv/vd75SXlydJ8vl8kqSkpKSg6yUlJTn7fD6fevXqFdzoZZepe/fuQTVpaWkt5mjed67QnDdvnubOndtifP369ercuXMoy5UkrVixQlLV11skdZXUXnpptkJVVVWqqmov/QBAsLq6OuvasIfmypUr9fLLL+uVV17R4MGDVVZWpunTpyslJUWTJk0K9821ysyZM1VYWOhc9vv9Sk1NVU5OjjweT0hzlpeXKysrS1KJpPTwNBqylZImt5NeJKlcUpZKSkqUnt4e+gGAlppfdbQR9tB85JFHNGPGDI0bN06SNGTIEH322WeaN2+eJk2apOTkZElSdXW1evfu7VyvurpaQ4cOlSQlJyfr8OHDQfOePn1ax44dc66fnJys6urqoJrmy8013+Z2u+V2u1uMR0dHKzo6OoTVSi6XS/X19Tp7TlVoc4RXe+rFJaleLpcr5PsXANpaax6fwn72bF1dnVyu4Gk7deqkQCAgSUpLS1NycrI2bNjg7Pf7/dq6dasyMzMlSZmZmaqpqZHX63VqNm7cqEAgoIyMDKempKQk6LXo4uJi9e/f/5wvzQIAcKHCHpq33Xabfve732ndunX6+9//rtWrV+vpp5/W2LFjJUlRUVGaPn26nnzySb3xxhvas2ePJk6cqJSUFI0ZM0aSNHDgQI0aNUqTJ0/Wtm3b9P7772vq1KkaN26cUlJSJEkTJkxQTEyM8vPztW/fPr322mtatGhR0MuvAACEVbhP3fX7/WbatGmmb9++JjY21lxxxRXmN7/5TdBHQwKBgJk1a5ZJSkoybrfbjBw50lRUVATNc/ToUTN+/HjTtWtX4/F4zD333GOOHz8eVFNeXm5uuukm43a7TZ8+fcz8+fNb1SsfOeEjJwDQmiyIMsaYiKZ2BPn9fsXHx6u2tjbkE4F27typ4cOHS/JKGhbW/lrvZUl3t5NeJGmnpOHyer0aNqw99AMALbUmC/juWQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLbRKaVVVVuvvuu9WjRw/FxcVpyJAh2rFjh7PfGKPZs2erd+/eiouLU3Z2tg4cOBA0x7Fjx5SXlyePx6OEhATl5+frxIkTQTW7d+/WzTffrNjYWKWmpqqoqKgtlgMAgKQ2CM2vvvpKN954o6Kjo/X222/ro48+0lNPPaXExESnpqioSM8++6yWLl2qrVu3qkuXLsrNzVVDQ4NTk5eXp3379qm4uFhr165VSUmJpkyZ4uz3+/3KyclRv3795PV6tXDhQs2ZM0fLli0L95IAAJAkXRbuCRcsWKDU1FS99NJLzlhaWprztzFGzzzzjB5//HHdfvvtkqT//d//VVJSktasWaNx48Zp//79euedd7R9+3aNGDFCkvTcc8/pZz/7mf7rv/5LKSkpevnll3Xq1Cm9+OKLiomJ0eDBg1VWVqann346KFy/qbGxUY2Njc5lv98vSWpqalJTU1NI6w0EAoqLi5MUkBTaHOHVnnoJSIpTIBAI+f4FgLbWmsenKGOMCeeNDxo0SLm5ufriiy+0ZcsW9enTRw8++KAmT54sSfrb3/6mK6+8Urt27dLQoUOd691yyy0aOnSoFi1apBdffFEPP/ywvvrqK2f/6dOnFRsbq1WrVmns2LGaOHGi/H6/1qxZ49Rs2rRJP/3pT3Xs2LGgZ7bN5syZo7lz57YYf+WVV9S5c+fw3QkAgA6jrq5OEyZMUG1trTwez/fWhv2Z5t/+9jctWbJEhYWF+vWvf63t27fr3//93xUTE6NJkybJ5/NJkpKSkoKul5SU5Ozz+Xzq1atXcKOXXabu3bsH1XzzGew35/T5fOcMzZkzZ6qwsNC57Pf7lZqaqpycnPPeUd+lvLxcWVlZkkokpYc0R/islDS5nfQiSeWSslRSUqL09PbQDwC01Pyqo42wh2YgENCIESP0+9//XpJ03XXXae/evVq6dKkmTZoU7ptrFbfbLbfb3WI8Ojpa0dHRIc3pcrlUX1+vs28PhzZHeLWnXlyS6uVyuUK+fwGgrbXm8SnsJwL17t1bgwYNChobOHCgKisrJUnJycmSpOrq6qCa6upqZ19ycrIOHz4ctP/06dM6duxYUM255vjmbQAAEE5hD80bb7xRFRUVQWN//etf1a9fP0lnTwpKTk7Whg0bnP1+v19bt25VZmamJCkzM1M1NTXyer1OzcaNGxUIBJSRkeHUlJSUBL2BW1xcrP79+5/zpVkAAC5U2EPzoYce0ocffqjf//73+uSTT/TKK69o2bJlKigokCRFRUVp+vTpevLJJ/XGG29oz549mjhxolJSUjRmzBhJZ5+Zjho1SpMnT9a2bdv0/vvva+rUqRo3bpxSUlIkSRMmTFBMTIzy8/O1b98+vfbaa1q0aFHQe5YAAISVaQNvvvmmueaaa4zb7TYDBgwwy5YtC9ofCATMrFmzTFJSknG73WbkyJGmoqIiqObo0aNm/PjxpmvXrsbj8Zh77rnHHD9+PKimvLzc3HTTTcbtdps+ffqY+fPnt6rP2tpaI8nU1taGtlBjjNfrNZKM5DWSifD2p3bUi/m6Dxmv1xvy/QsAba01WRD2j5x0JH6/X/Hx8VanGX+XnTt3avjw4ZK8koaFtb/We1nS3e2kF0naKWm4vF6vhg1rD/0AQEutyQK+exYAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYKnNQ3P+/PmKiorS9OnTnbGGhgYVFBSoR48e6tq1q+68805VV1cHXa+yslKjR49W586d1atXLz3yyCM6ffp0UM3mzZs1bNgwud1uXXXVVVq+fHlbLwcAcAlr09Dcvn27/ud//kfXXntt0PhDDz2kN998U6tWrdKWLVt06NAh3XHHHc7+M2fOaPTo0Tp16pQ++OAD/fGPf9Ty5cs1e/Zsp+bgwYMaPXq0fvKTn6isrEzTp0/Xfffdp3fffbctlwQAuJSZNnL8+HHzwx/+0BQXF5tbbrnFTJs2zRhjTE1NjYmOjjarVq1yavfv328kmdLSUmOMMW+99ZZxuVzG5/M5NUuWLDEej8c0NjYaY4x59NFHzeDBg4Nu86677jK5ubnWPdbW1hpJpra2NtRlGq/XayQZyWskE+HtT+2oF/N1HzJerzfk+xcA2lprsuCytgrjgoICjR49WtnZ2XryySedca/Xq6amJmVnZztjAwYMUN++fVVaWqobbrhBpaWlGjJkiJKSkpya3NxcPfDAA9q3b5+uu+46lZaWBs3RXPPNl4G/rbGxUY2Njc5lv98vSWpqalJTU1NI6wwEAoqLi5MUkBTaHOHVnnoJSIpTIBAI+f4FgLbWmsenNgnNV199VTt37tT27dtb7PP5fIqJiVFCQkLQeFJSknw+n1PzzcBs3t+87/tq/H6/6uvrvw6yYPPmzdPcuXNbjK9fv16dO3e2X+C3rFixQlLV11skdZXUXnpptkJVVVWqqmov/QBAsLq6OuvasIfm559/rmnTpqm4uFixsbHhnv6CzJw5U4WFhc5lv9+v1NRU5eTkyOPxhDRneXm5srKyJJVISg9PoyFbKWlyO+lFksolZamkpETp6e2hHwBoqflVRxthD02v16vDhw9r2LBhztiZM2dUUlKi559/Xu+++65OnTqlmpqaoGeb1dXVSk5OliQlJydr27ZtQfM2n137zZpvn3FbXV0tj8dzzmeZkuR2u+V2u1uMR0dHKzo6uvWLleRyuVRfX6+z51SFNkd4tadeXJLq5XK5Qr5/AaCttebxKexnz44cOVJ79uxRWVmZs40YMUJ5eXnO39HR0dqwYYNznYqKClVWViozM1OSlJmZqT179ujw4cNOTXFxsTwejwYNGuTUfHOO5prmOQAACLewP9Ps1q2brrnmmqCxLl26qEePHs54fn6+CgsL1b17d3k8Hv3qV79SZmambrjhBklSTk6OBg0apF/+8pcqKiqSz+fT448/roKCAueZ4v3336/nn39ejz76qO69915t3LhRK1eu1Lp168K9JAAAJLXRiUDn89///d9yuVy688471djYqNzcXL3wwgvO/k6dOmnt2rV64IEHlJmZqS5dumjSpEn67W9/69SkpaVp3bp1euihh7Ro0SJdfvnl+sMf/qDc3NxILAkAcAmIMsaYSDcRKX6/X/Hx8aqtrQ35RKCdO3dq+PDhkryShp2vvI29LOnudtKLJO2UNFxerzfoPW4AaE9akwV89ywAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwFLYQ3PevHn60Y9+pG7duqlXr14aM2aMKioqgmoaGhpUUFCgHj16qGvXrrrzzjtVXV0dVFNZWanRo0erc+fO6tWrlx555BGdPn06qGbz5s0aNmyY3G63rrrqKi1fvjzcywEAwBH20NyyZYsKCgr04Ycfqri4WE1NTcrJydHJkyedmoceekhvvvmmVq1apS1btujQoUO64447nP1nzpzR6NGjderUKX3wwQf64x//qOXLl2v27NlOzcGDBzV69Gj95Cc/UVlZmaZPn6777rtP7777briXBADAWaaNHT582EgyW7ZsMcYYU1NTY6Kjo82qVaucmv379xtJprS01BhjzFtvvWVcLpfx+XxOzZIlS4zH4zGNjY3GGGMeffRRM3jw4KDbuuuuu0xubq51b7W1tUaSqa2tDXl9Xq/XSDKS10gmwtuf2lEv5us+ZLxeb8j3LwC0tdZkwWVtHcq1tbWSpO7du0uSvF6vmpqalJ2d7dQMGDBAffv2VWlpqW644QaVlpZqyJAhSkpKcmpyc3P1wAMPaN++fbruuutUWloaNEdzzfTp07+zl8bGRjU2NjqX/X6/JKmpqUlNTU0hrS8QCCguLk5SQFJoc4RXe+olIClOgUAg5PsXANpaax6f2jQ0A4GApk+frhtvvFHXXHONJMnn8ykmJkYJCQlBtUlJSfL5fE7NNwOzeX/zvu+r8fv9qq+v/zrIgs2bN09z585tMb5+/Xp17tw5tEVKWrFihaSqr7dI6iqpvfTSbIWqqqpUVdVe+gGAYHV1dda1bRqaBQUF2rt3r9577722vBlrM2fOVGFhoXPZ7/crNTVVOTk58ng8Ic1ZXl6urKwsSSWS0sPTaMhWSprcTnqRpHJJWSopKVF6envoBwBaan7V0UabhebUqVO1du1alZSU6PLLL3fGk5OTderUKdXU1AQ926yurlZycrJTs23btqD5ms+u/WbNt8+4ra6ulsfjOeezTElyu91yu90txqOjoxUdHd36RUpyuVyqr6/X2XOqQpsjvNpTLy5J9XK5XCHfvwDQ1lrz+BT2s2eNMZo6dapWr16tjRs3Ki0tLWj/8OHDFR0drQ0bNjhjFRUVqqysVGZmpiQpMzNTe/bs0eHDh52a4uJieTweDRo0yKn55hzNNc1zAAAQbmF/pllQUKBXXnlFr7/+urp16+a8BxkfH6+4uDjFx8crPz9fhYWF6t69uzwej371q18pMzNTN9xwgyQpJydHgwYN0i9/+UsVFRXJ5/Pp8ccfV0FBgfNM8f7779fzzz+vRx99VPfee682btyolStXat26deFeEgAAZ4X71F1J59xeeuklp6a+vt48+OCDJjEx0XTu3NmMHTvWfPnll0Hz/P3vfze33nqriYuLMz179jQPP/ywaWpqCqrZtGmTGTp0qImJiTFXXHFF0G3Y4CMnfOQEACL6kRNjzHlrYmNjtXjxYi1evPg7a/r166e33nrre+f58Y9/rF27drW6RwAAQsF3zwIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABYIjQBALBEaAIAYInQBADAEqEJAIAlQhMAAEuEJgAAlghNAAAsEZoAAFgiNAEAsERoAgBgidAEAMASoQkAgCVCEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALBGaAABY6vChuXjxYv3TP/2TYmNjlZGRoW3btkW6JQDAReqySDdwIV577TUVFhZq6dKlysjI0DPPPKPc3FxVVFSoV69ekW4PX9u/f3+kW5Ak9ezZU3379o10GwA6sA4dmk8//bQmT56se+65R5K0dOlSrVu3Ti+++KJmzJjRor6xsVGNjY3O5draWknSsWPH1NTUFFIPfr9fsbGxkryS/CHNET4VktpLL5K0TVJn3XfffZFuRJLkdsdp2bKl7eIfVC6XS4FAINJtSGpfvUjtqx96Obf21EtSUtIF/z99/PhxSZIx5vzFpoNqbGw0nTp1MqtXrw4anzhxovn5z39+zus88cQTRhIbGxsbG1uL7fPPPz9v9nTYZ5pHjhzRmTNnlJSUFDSelJSkjz/++JzXmTlzpgoLC53LgUBAx44dU48ePRQVFRVSH36/X6mpqfr888/l8XhCmqM9uhjXxZo6jotxXayp/TLG6Pjx40pJSTlvbYcNzVC43W653e6gsYSEhLDM7fF4OvR/NN/lYlwXa+o4LsZ1sab2KT4+3qquw54927NnT3Xq1EnV1dVB49XV1UpOTo5QVwCAi1mHDc2YmBgNHz5cGzZscMYCgYA2bNigzMzMCHYGALhYdeiXZwsLCzVp0iSNGDFC119/vZ555hmdPHnSOZv2H8HtduuJJ55o8bJvR3cxros1dRwX47pY08Uhyhibc2zbr+eff14LFy6Uz+fT0KFD9eyzzyojIyPSbQEALkIdPjQBAPhH6bDvaQIA8I9GaAIAYInQBADAEqEJAIAlQvMCXUw/TTZnzhxFRUUFbQMGDIh0W61WUlKi2267TSkpKYqKitKaNWuC9htjNHv2bPXu3VtxcXHKzs7WgQMHItOspfOt6V//9V9bHLtRo0ZFpllL8+bN049+9CN169ZNvXr10pgxY1RRURFU09DQoIKCAvXo0UNdu3bVnXfe2eILTdoTmzX9+Mc/bnGs7r///gh1bGfJkiW69tprnW/+yczM1Ntvv+3s72jH6UIQmheg+afJnnjiCe3cuVPp6enKzc3V4cOHI91ayAYPHqwvv/zS2d57771It9RqJ0+eVHp6uhYvXnzO/UVFRXr22We1dOlSbd26VV26dFFubq4aGhr+wZ3aO9+aJGnUqFFBx27FihX/wA5bb8uWLSooKNCHH36o4uJiNTU1KScnRydPnnRqHnroIb355ptatWqVtmzZokOHDumOO+6IYNffz2ZNkjR58uSgY1VUVBShju1cfvnlmj9/vrxer3bs2KGf/vSnuv3227Vv3z5JHe84XZAL+62RS9v1119vCgoKnMtnzpwxKSkpZt68eRHsKnRPPPGESU9Pj3QbYSUp6JdwAoGASU5ONgsXLnTGampqjNvtNitWrIhAh6337TUZY8ykSZPM7bffHpF+wuXw4cNGktmyZYsx5uxxiY6ONqtWrXJq9u/fbySZ0tLSSLXZKt9ekzHG3HLLLWbatGmRaypMEhMTzR/+8IeL4ji1Bs80Q3Tq1Cl5vV5lZ2c7Yy6XS9nZ2SotLY1gZxfmwIEDSklJ0RVXXKG8vDxVVlZGuqWwOnjwoHw+X9Bxi4+PV0ZGRoc+bpK0efNm9erVS/3799cDDzygo0ePRrqlVmn+fdvu3btLkrxer5qamoKO1YABA9S3b98Oc6y+vaZmL7/8snr27KlrrrlGM2fOVF1dXSTaC8mZM2f06quv6uTJk8rMzLwojlNrdOiv0YukUH6arL3LyMjQ8uXL1b9/f3355ZeaO3eubr75Zu3du1fdunWLdHth4fP5JOmcx615X0c0atQo3XHHHUpLS9Onn36qX//617r11ltVWlqqTp06Rbq98woEApo+fbpuvPFGXXPNNZLOHquYmJgWv0TUUY7VudYkSRMmTFC/fv2UkpKi3bt367HHHlNFRYX+/Oc/R7Db89uzZ48yMzPV0NCgrl27avXq1Ro0aJDKyso69HFqLUITjltvvdX5+9prr1VGRob69eunlStXKj8/P4Kd4XzGjRvn/D1kyBBde+21uvLKK7V582aNHDkygp3ZKSgo0N69ezvke+jf5bvWNGXKFOfvIUOGqHfv3ho5cqQ+/fRTXXnllf/oNq31799fZWVlqq2t1f/93/9p0qRJ2rJlS6Tb+ofj5dkQXQo/TZaQkKCrr75an3zySaRbCZvmY3MxHzdJuuKKK9SzZ88OceymTp2qtWvXatOmTbr88sud8eTkZJ06dUo1NTVB9R3hWH3Xms6l+buy2/uxiomJ0VVXXaXhw4dr3rx5Sk9P16JFizr0cQoFoRmiS+GnyU6cOKFPP/1UvXv3jnQrYZOWlqbk5OSg4+b3+7V169aL5rhJ0hdffKGjR4+262NnjNHUqVO1evVqbdy4UWlpaUH7hw8frujo6KBjVVFRocrKynZ7rM63pnMpKyuTpHZ9rM4lEAiosbGxQx6nCxLpM5E6sldffdW43W6zfPly89FHH5kpU6aYhIQE4/P5It1aSB5++GGzefNmc/DgQfP++++b7Oxs07NnT3P48OFIt9Yqx48fN7t27TK7du0ykszTTz9tdu3aZT777DNjjDHz5883CQkJ5vXXXze7d+82t99+u0lLSzP19fUR7vy7fd+ajh8/bv7jP/7DlJaWmoMHD5q//OUvZtiwYeaHP/yhaWhoiHTr3+mBBx4w8fHxZvPmzebLL790trq6Oqfm/vvvN3379jUbN240O3bsMJmZmSYzMzOCXX+/863pk08+Mb/97W/Njh07zMGDB83rr79urrjiCpOVlRXhzr/fjBkzzJYtW8zBgwfN7t27zYwZM0xUVJRZv369MabjHacLQWheoOeee8707dvXxMTEmOuvv958+OGHkW4pZHfddZfp3bu3iYmJMX369DF33XWX+eSTTyLdVqtt2rTJSGqxTZo0yRhz9mMns2bNMklJScbtdpuRI0eaioqKyDZ9Ht+3prq6OpOTk2N+8IMfmOjoaNOvXz8zefLkdv+Pt3OtR5J56aWXnJr6+nrz4IMPmsTERNO5c2czduxY8+WXX0au6fM435oqKytNVlaW6d69u3G73eaqq64yjzzyiKmtrY1s4+dx7733mn79+pmYmBjzgx/8wIwcOdIJTGM63nG6EPw0GAAAlnhPEwAAS4QmAACWCE0AACwRmgAAWCI0AQCwRGgCAGCJ0AQAwBKhCQCAJUITAABLhCYAAJYITQAALP0/SisORHdTAvYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.draw_histogram_chart(df[\"bedrooms\"], 10, figure_height=5, figure_width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.removeOutliersByQuantile(df, \"bedrooms\", 0.01, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.draw_histogram_chart(df[\"bedrooms\"], 10, figure_height= 5, figure_width= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    9824\n",
       "4    6882\n",
       "2    2760\n",
       "5    1601\n",
       "6     272\n",
       "Name: bedrooms, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bedrooms\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.draw_histogram_chart(df[\"bathrooms\"], 10, figure_height= 5, figure_width= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.removeOutliersByQuantile(df, \"bathrooms\", 0.01, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.draw_histogram_chart(df[\"bathrooms\"], 10, figure_height= 5, figure_width= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.addColumnWithValue(df, \"age\", 2022-df[\"yr_built\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df[\"basement\"] = np.where(df[\"sqft_basement\"] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.updateColumnValuesBasedOnCondition(df, \"sqft_basement\", \"equals\", 0, 0, 1)\n",
    "df = preprocessor.renameOrTransformColumnNames(df, old_name=\"sqft_basement\", new_name=\"basement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2170</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>7936000429</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2600</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21607</th>\n",
       "      <td>2997800021</td>\n",
       "      <td>20150219T000000</td>\n",
       "      <td>475000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1310</td>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1180</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5773</td>\n",
       "      <td>-122.409</td>\n",
       "      <td>1330</td>\n",
       "      <td>1265</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20763 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date      price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000   221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000   538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000   180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000   604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000   510000.0         3       2.00   \n",
       "...           ...              ...        ...       ...        ...   \n",
       "21606  7936000429  20150326T000000  1007500.0         4       3.50   \n",
       "21607  2997800021  20150219T000000   475000.0         3       2.50   \n",
       "21608   263000018  20140521T000000   360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000   400000.0         4       2.50   \n",
       "21611   291310100  20150116T000000   400000.0         3       2.50   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  sqft_above  \\\n",
       "0             1180      5650     1.0           0     0  ...        1180   \n",
       "1             2570      7242     2.0           0     0  ...        2170   \n",
       "2              770     10000     1.0           0     0  ...         770   \n",
       "3             1960      5000     1.0           0     0  ...        1050   \n",
       "4             1680      8080     1.0           0     0  ...        1680   \n",
       "...            ...       ...     ...         ...   ...  ...         ...   \n",
       "21606         3510      7200     2.0           0     0  ...        2600   \n",
       "21607         1310      1294     2.0           0     0  ...        1180   \n",
       "21608         1530      1131     3.0           0     0  ...        1530   \n",
       "21609         2310      5813     2.0           0     0  ...        2310   \n",
       "21611         1600      2388     2.0           0     0  ...        1600   \n",
       "\n",
       "       basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0             0      1955             0    98178  47.5112 -122.257   \n",
       "1             1      1951          1991    98125  47.7210 -122.319   \n",
       "2             0      1933             0    98028  47.7379 -122.233   \n",
       "3             1      1965             0    98136  47.5208 -122.393   \n",
       "4             0      1987             0    98074  47.6168 -122.045   \n",
       "...         ...       ...           ...      ...      ...      ...   \n",
       "21606         1      2009             0    98136  47.5537 -122.398   \n",
       "21607         1      2008             0    98116  47.5773 -122.409   \n",
       "21608         0      2009             0    98103  47.6993 -122.346   \n",
       "21609         0      2014             0    98146  47.5107 -122.362   \n",
       "21611         0      2004             0    98027  47.5345 -122.069   \n",
       "\n",
       "       sqft_living15  sqft_lot15  age  \n",
       "0               1340        5650   67  \n",
       "1               1690        7639   71  \n",
       "2               2720        8062   89  \n",
       "3               1360        5000   57  \n",
       "4               1800        7503   35  \n",
       "...              ...         ...  ...  \n",
       "21606           2050        6200   13  \n",
       "21607           1330        1265   14  \n",
       "21608           1530        1509   13  \n",
       "21609           1830        7200    8  \n",
       "21611           1410        1287   18  \n",
       "\n",
       "[20763 rows x 22 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.updateColumnValuesBasedOnCondition(df, \"yr_renovated\", \"equals\", 0, 0, 1)\n",
    "df = preprocessor.renameOrTransformColumnNames(df, old_name=\"yr_renovated\", new_name=\"renovated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2170</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>1</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>7936000429</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2600</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21607</th>\n",
       "      <td>2997800021</td>\n",
       "      <td>20150219T000000</td>\n",
       "      <td>475000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1310</td>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1180</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5773</td>\n",
       "      <td>-122.409</td>\n",
       "      <td>1330</td>\n",
       "      <td>1265</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20763 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date      price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000   221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000   538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000   180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000   604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000   510000.0         3       2.00   \n",
       "...           ...              ...        ...       ...        ...   \n",
       "21606  7936000429  20150326T000000  1007500.0         4       3.50   \n",
       "21607  2997800021  20150219T000000   475000.0         3       2.50   \n",
       "21608   263000018  20140521T000000   360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000   400000.0         4       2.50   \n",
       "21611   291310100  20150116T000000   400000.0         3       2.50   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  sqft_above  \\\n",
       "0             1180      5650     1.0           0     0  ...        1180   \n",
       "1             2570      7242     2.0           0     0  ...        2170   \n",
       "2              770     10000     1.0           0     0  ...         770   \n",
       "3             1960      5000     1.0           0     0  ...        1050   \n",
       "4             1680      8080     1.0           0     0  ...        1680   \n",
       "...            ...       ...     ...         ...   ...  ...         ...   \n",
       "21606         3510      7200     2.0           0     0  ...        2600   \n",
       "21607         1310      1294     2.0           0     0  ...        1180   \n",
       "21608         1530      1131     3.0           0     0  ...        1530   \n",
       "21609         2310      5813     2.0           0     0  ...        2310   \n",
       "21611         1600      2388     2.0           0     0  ...        1600   \n",
       "\n",
       "       basement  yr_built  renovated  zipcode      lat     long  \\\n",
       "0             0      1955          0    98178  47.5112 -122.257   \n",
       "1             1      1951          1    98125  47.7210 -122.319   \n",
       "2             0      1933          0    98028  47.7379 -122.233   \n",
       "3             1      1965          0    98136  47.5208 -122.393   \n",
       "4             0      1987          0    98074  47.6168 -122.045   \n",
       "...         ...       ...        ...      ...      ...      ...   \n",
       "21606         1      2009          0    98136  47.5537 -122.398   \n",
       "21607         1      2008          0    98116  47.5773 -122.409   \n",
       "21608         0      2009          0    98103  47.6993 -122.346   \n",
       "21609         0      2014          0    98146  47.5107 -122.362   \n",
       "21611         0      2004          0    98027  47.5345 -122.069   \n",
       "\n",
       "       sqft_living15  sqft_lot15  age  \n",
       "0               1340        5650   67  \n",
       "1               1690        7639   71  \n",
       "2               2720        8062   89  \n",
       "3               1360        5000   57  \n",
       "4               1800        7503   35  \n",
       "...              ...         ...  ...  \n",
       "21606           2050        6200   13  \n",
       "21607           1330        1265   14  \n",
       "21608           1530        1509   13  \n",
       "21609           1830        7200    8  \n",
       "21611           1410        1287   18  \n",
       "\n",
       "[20763 rows x 22 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.draw_histogram_chart(df[\"price\"], 100, figure_height= 5, figure_width= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20763 entries, 0 to 21611\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   id             20763 non-null  int64   \n",
      " 1   date           20763 non-null  object  \n",
      " 2   price          20763 non-null  float64 \n",
      " 3   bedrooms       20763 non-null  int64   \n",
      " 4   bathrooms      20763 non-null  float64 \n",
      " 5   sqft_living    20763 non-null  int64   \n",
      " 6   sqft_lot       20763 non-null  int64   \n",
      " 7   floors         20763 non-null  float64 \n",
      " 8   waterfront     20763 non-null  int64   \n",
      " 9   view           20763 non-null  int64   \n",
      " 10  condition      20763 non-null  int64   \n",
      " 11  grade          20763 non-null  int64   \n",
      " 12  sqft_above     20763 non-null  int64   \n",
      " 13  basement       20763 non-null  int32   \n",
      " 14  yr_built       20763 non-null  int64   \n",
      " 15  renovated      20763 non-null  int32   \n",
      " 16  zipcode        20763 non-null  category\n",
      " 17  lat            20763 non-null  float64 \n",
      " 18  long           20763 non-null  float64 \n",
      " 19  sqft_living15  20763 non-null  int64   \n",
      " 20  sqft_lot15     20763 non-null  int64   \n",
      " 21  age            20763 non-null  int64   \n",
      "dtypes: category(1), float64(5), int32(2), int64(13), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.dropColumnsFromDataFrame(df, [\"id\", \"lat\", \"long\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.changeColumnDataType(df, \"price\", int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20763 entries, 0 to 21611\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   price          20763 non-null  int32   \n",
      " 1   bedrooms       20763 non-null  int64   \n",
      " 2   bathrooms      20763 non-null  float64 \n",
      " 3   sqft_living    20763 non-null  int64   \n",
      " 4   sqft_lot       20763 non-null  int64   \n",
      " 5   floors         20763 non-null  float64 \n",
      " 6   waterfront     20763 non-null  int64   \n",
      " 7   view           20763 non-null  int64   \n",
      " 8   condition      20763 non-null  int64   \n",
      " 9   grade          20763 non-null  int64   \n",
      " 10  sqft_above     20763 non-null  int64   \n",
      " 11  basement       20763 non-null  int32   \n",
      " 12  yr_built       20763 non-null  int64   \n",
      " 13  renovated      20763 non-null  int32   \n",
      " 14  zipcode        20763 non-null  category\n",
      " 15  sqft_living15  20763 non-null  int64   \n",
      " 16  sqft_lot15     20763 non-null  int64   \n",
      " 17  age            20763 non-null  int64   \n",
      "dtypes: category(1), float64(2), int32(3), int64(12)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18856\n",
       "2      886\n",
       "3      452\n",
       "1      311\n",
       "4      258\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.removeOutliersByQuantile(df, \"price\", 0.01, 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.removeOutliersByQuantile(df, \"sqft_living\", 0.01, 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>1</td>\n",
       "      <td>98125</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>1007500</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21607</th>\n",
       "      <td>475000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1310</td>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1180</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>1330</td>\n",
       "      <td>1265</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>360000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>400000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>400000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19149 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0       221900         3       1.00         1180      5650     1.0   \n",
       "1       538000         3       2.25         2570      7242     2.0   \n",
       "2       180000         2       1.00          770     10000     1.0   \n",
       "3       604000         4       3.00         1960      5000     1.0   \n",
       "4       510000         3       2.00         1680      8080     1.0   \n",
       "...        ...       ...        ...          ...       ...     ...   \n",
       "21606  1007500         4       3.50         3510      7200     2.0   \n",
       "21607   475000         3       2.50         1310      1294     2.0   \n",
       "21608   360000         3       2.50         1530      1131     3.0   \n",
       "21609   400000         4       2.50         2310      5813     2.0   \n",
       "21611   400000         3       2.50         1600      2388     2.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  basement  yr_built  \\\n",
       "0               0     0          3      7        1180         0      1955   \n",
       "1               0     0          3      7        2170         1      1951   \n",
       "2               0     0          3      6         770         0      1933   \n",
       "3               0     0          5      7        1050         1      1965   \n",
       "4               0     0          3      8        1680         0      1987   \n",
       "...           ...   ...        ...    ...         ...       ...       ...   \n",
       "21606           0     0          3      9        2600         1      2009   \n",
       "21607           0     0          3      8        1180         1      2008   \n",
       "21608           0     0          3      8        1530         0      2009   \n",
       "21609           0     0          3      8        2310         0      2014   \n",
       "21611           0     0          3      8        1600         0      2004   \n",
       "\n",
       "       renovated zipcode  sqft_living15  sqft_lot15  age  \n",
       "0              0   98178           1340        5650   67  \n",
       "1              1   98125           1690        7639   71  \n",
       "2              0   98028           2720        8062   89  \n",
       "3              0   98136           1360        5000   57  \n",
       "4              0   98074           1800        7503   35  \n",
       "...          ...     ...            ...         ...  ...  \n",
       "21606          0   98136           2050        6200   13  \n",
       "21607          0   98116           1330        1265   14  \n",
       "21608          0   98103           1530        1509   13  \n",
       "21609          0   98146           1830        7200    8  \n",
       "21611          0   98027           1410        1287   18  \n",
       "\n",
       "[19149 rows x 18 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19149 entries, 0 to 21611\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   price          19149 non-null  int32   \n",
      " 1   bedrooms       19149 non-null  int64   \n",
      " 2   bathrooms      19149 non-null  float64 \n",
      " 3   sqft_living    19149 non-null  int64   \n",
      " 4   sqft_lot       19149 non-null  int64   \n",
      " 5   floors         19149 non-null  float64 \n",
      " 6   waterfront     19149 non-null  int64   \n",
      " 7   view           19149 non-null  int64   \n",
      " 8   condition      19149 non-null  int64   \n",
      " 9   grade          19149 non-null  int64   \n",
      " 10  sqft_above     19149 non-null  int64   \n",
      " 11  basement       19149 non-null  int32   \n",
      " 12  yr_built       19149 non-null  int64   \n",
      " 13  renovated      19149 non-null  int32   \n",
      " 14  zipcode        19149 non-null  category\n",
      " 15  sqft_living15  19149 non-null  int64   \n",
      " 16  sqft_lot15     19149 non-null  int64   \n",
      " 17  age            19149 non-null  int64   \n",
      "dtypes: category(1), float64(2), int32(3), int64(12)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.000000\n",
       "grade            0.585814\n",
       "sqft_living      0.565185\n",
       "sqft_living15    0.512829\n",
       "sqft_above       0.451562\n",
       "bathrooms        0.376609\n",
       "view             0.255562\n",
       "bedrooms         0.238506\n",
       "floors           0.228472\n",
       "basement         0.152852\n",
       "renovated        0.100862\n",
       "waterfront       0.082365\n",
       "sqft_lot         0.064290\n",
       "condition        0.056752\n",
       "sqft_lot15       0.053074\n",
       "age              0.016708\n",
       "yr_built         0.016708\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.sortCorrelationsWithColumn(df, \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'basement',\n",
       "       'yr_built', 'renovated', 'zipcode', 'sqft_living15', 'sqft_lot15',\n",
       "       'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "       'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'basement',\n",
    "       'yr_built', 'renovated', 'zipcode', 'sqft_living15', 'sqft_lot15',\n",
    "       'age']]\n",
    "y = df[[\"price\"]]\n",
    "x = pd.get_dummies(x, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state= 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(19, activation= \"relu\"))\n",
    "model.add(Dense(19, activation= \"relu\"))\n",
    "model.add(Dense(19, activation= \"relu\"))\n",
    "model.add(Dense(19, activation= \"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer= \"Adam\", loss= \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 245602222080.0000 - val_loss: 191916097536.0000\n",
      "Epoch 2/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 154623524864.0000 - val_loss: 84257579008.0000\n",
      "Epoch 3/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 41686728704.0000 - val_loss: 30820945920.0000\n",
      "Epoch 4/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 29963186176.0000 - val_loss: 29617707008.0000\n",
      "Epoch 5/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 29228994560.0000 - val_loss: 29199843328.0000\n",
      "Epoch 6/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28762636288.0000 - val_loss: 28844724224.0000\n",
      "Epoch 7/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28561426432.0000 - val_loss: 28696512512.0000\n",
      "Epoch 8/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 28230371328.0000 - val_loss: 28476932096.0000\n",
      "Epoch 9/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27966871552.0000 - val_loss: 28228102144.0000\n",
      "Epoch 10/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27784916992.0000 - val_loss: 28077039616.0000\n",
      "Epoch 11/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27536365568.0000 - val_loss: 28015628288.0000\n",
      "Epoch 12/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 27420667904.0000 - val_loss: 27815280640.0000\n",
      "Epoch 13/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 27193387008.0000 - val_loss: 27451109376.0000\n",
      "Epoch 14/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26799470592.0000 - val_loss: 27170478080.0000\n",
      "Epoch 15/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26515501056.0000 - val_loss: 26877245440.0000\n",
      "Epoch 16/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 26559465472.0000 - val_loss: 26775791616.0000\n",
      "Epoch 17/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 26104580096.0000 - val_loss: 26980454400.0000\n",
      "Epoch 18/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25917188096.0000 - val_loss: 26588059648.0000\n",
      "Epoch 19/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25835466752.0000 - val_loss: 26225000448.0000\n",
      "Epoch 20/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25745977344.0000 - val_loss: 26054344704.0000\n",
      "Epoch 21/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25286250496.0000 - val_loss: 25860020224.0000\n",
      "Epoch 22/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 25118828544.0000 - val_loss: 25623480320.0000\n",
      "Epoch 23/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24932048896.0000 - val_loss: 25636315136.0000\n",
      "Epoch 24/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24896937984.0000 - val_loss: 25487179776.0000\n",
      "Epoch 25/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24754722816.0000 - val_loss: 25247555584.0000\n",
      "Epoch 26/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24434051072.0000 - val_loss: 25091151872.0000\n",
      "Epoch 27/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 24341123072.0000 - val_loss: 25109248000.0000\n",
      "Epoch 28/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24187852800.0000 - val_loss: 25358123008.0000\n",
      "Epoch 29/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 24215007232.0000 - val_loss: 24749924352.0000\n",
      "Epoch 30/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23952701440.0000 - val_loss: 24609165312.0000\n",
      "Epoch 31/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23894726656.0000 - val_loss: 24537243648.0000\n",
      "Epoch 32/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23782377472.0000 - val_loss: 24441800704.0000\n",
      "Epoch 33/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23636819968.0000 - val_loss: 24368535552.0000\n",
      "Epoch 34/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23767650304.0000 - val_loss: 24772327424.0000\n",
      "Epoch 35/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23388014592.0000 - val_loss: 24141606912.0000\n",
      "Epoch 36/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23369261056.0000 - val_loss: 24156098560.0000\n",
      "Epoch 37/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23306395648.0000 - val_loss: 23944050688.0000\n",
      "Epoch 38/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 23455514624.0000 - val_loss: 23967393792.0000\n",
      "Epoch 39/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23087548416.0000 - val_loss: 24821176320.0000\n",
      "Epoch 40/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 23084271616.0000 - val_loss: 24198219776.0000\n",
      "Epoch 41/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22940928000.0000 - val_loss: 23700910080.0000\n",
      "Epoch 42/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22868936704.0000 - val_loss: 23830841344.0000\n",
      "Epoch 43/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22944960512.0000 - val_loss: 23530831872.0000\n",
      "Epoch 44/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22857955328.0000 - val_loss: 23915317248.0000\n",
      "Epoch 45/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22682085376.0000 - val_loss: 23677419520.0000\n",
      "Epoch 46/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22892861440.0000 - val_loss: 23434196992.0000\n",
      "Epoch 47/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22600304640.0000 - val_loss: 23455174656.0000\n",
      "Epoch 48/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22573582336.0000 - val_loss: 23318861824.0000\n",
      "Epoch 49/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22524231680.0000 - val_loss: 23209816064.0000\n",
      "Epoch 50/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22871689216.0000 - val_loss: 23525265408.0000\n",
      "Epoch 51/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22791499776.0000 - val_loss: 23127787520.0000\n",
      "Epoch 52/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22374668288.0000 - val_loss: 23128662016.0000\n",
      "Epoch 53/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22316214272.0000 - val_loss: 23049281536.0000\n",
      "Epoch 54/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22403549184.0000 - val_loss: 23000725504.0000\n",
      "Epoch 55/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22233419776.0000 - val_loss: 22962909184.0000\n",
      "Epoch 56/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22163030016.0000 - val_loss: 23226413056.0000\n",
      "Epoch 57/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22181974016.0000 - val_loss: 22921476096.0000\n",
      "Epoch 58/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22237399040.0000 - val_loss: 23188772864.0000\n",
      "Epoch 59/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22023933952.0000 - val_loss: 22859061248.0000\n",
      "Epoch 60/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 22049128448.0000 - val_loss: 22949578752.0000\n",
      "Epoch 61/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21995884544.0000 - val_loss: 22753398784.0000\n",
      "Epoch 62/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21962473472.0000 - val_loss: 23000299520.0000\n",
      "Epoch 63/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22193805312.0000 - val_loss: 22671200256.0000\n",
      "Epoch 64/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 22016753664.0000 - val_loss: 22612314112.0000\n",
      "Epoch 65/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21951813632.0000 - val_loss: 23144857600.0000\n",
      "Epoch 66/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21970970624.0000 - val_loss: 22680969216.0000\n",
      "Epoch 67/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21907181568.0000 - val_loss: 23305293824.0000\n",
      "Epoch 68/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21845561344.0000 - val_loss: 22856464384.0000\n",
      "Epoch 69/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21830772736.0000 - val_loss: 22719029248.0000\n",
      "Epoch 70/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21715976192.0000 - val_loss: 22503507968.0000\n",
      "Epoch 71/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21783676928.0000 - val_loss: 22585974784.0000\n",
      "Epoch 72/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21858220032.0000 - val_loss: 22427574272.0000\n",
      "Epoch 73/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21704550400.0000 - val_loss: 23123929088.0000\n",
      "Epoch 74/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21578549248.0000 - val_loss: 22250975232.0000\n",
      "Epoch 75/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21566877696.0000 - val_loss: 22546327552.0000\n",
      "Epoch 76/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21522927616.0000 - val_loss: 22832134144.0000\n",
      "Epoch 77/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21563426816.0000 - val_loss: 22205024256.0000\n",
      "Epoch 78/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21578897408.0000 - val_loss: 22621140992.0000\n",
      "Epoch 79/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21462042624.0000 - val_loss: 22362513408.0000\n",
      "Epoch 80/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21605795840.0000 - val_loss: 23249432576.0000\n",
      "Epoch 81/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21536548864.0000 - val_loss: 22496864256.0000\n",
      "Epoch 82/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21725304832.0000 - val_loss: 22557057024.0000\n",
      "Epoch 83/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21759301632.0000 - val_loss: 22070439936.0000\n",
      "Epoch 84/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21501784064.0000 - val_loss: 22506790912.0000\n",
      "Epoch 85/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21381947392.0000 - val_loss: 22067318784.0000\n",
      "Epoch 86/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21380780032.0000 - val_loss: 22226749440.0000\n",
      "Epoch 87/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21362644992.0000 - val_loss: 22588155904.0000\n",
      "Epoch 88/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21353873408.0000 - val_loss: 21919199232.0000\n",
      "Epoch 89/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21239130112.0000 - val_loss: 22335674368.0000\n",
      "Epoch 90/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21554829312.0000 - val_loss: 22019065856.0000\n",
      "Epoch 91/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21190463488.0000 - val_loss: 22011152384.0000\n",
      "Epoch 92/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21161682944.0000 - val_loss: 22115651584.0000\n",
      "Epoch 93/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21453074432.0000 - val_loss: 21877547008.0000\n",
      "Epoch 94/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21091565568.0000 - val_loss: 21766918144.0000\n",
      "Epoch 95/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21471217664.0000 - val_loss: 21751891968.0000\n",
      "Epoch 96/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21099810816.0000 - val_loss: 21794725888.0000\n",
      "Epoch 97/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21168992256.0000 - val_loss: 21871142912.0000\n",
      "Epoch 98/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21250275328.0000 - val_loss: 22192941056.0000\n",
      "Epoch 99/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21124218880.0000 - val_loss: 21699289088.0000\n",
      "Epoch 100/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21107826688.0000 - val_loss: 22152841216.0000\n",
      "Epoch 101/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21030617088.0000 - val_loss: 21605785600.0000\n",
      "Epoch 102/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21034055680.0000 - val_loss: 21616267264.0000\n",
      "Epoch 103/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21038346240.0000 - val_loss: 21671583744.0000\n",
      "Epoch 104/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20918202368.0000 - val_loss: 21554784256.0000\n",
      "Epoch 105/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21011193856.0000 - val_loss: 21536479232.0000\n",
      "Epoch 106/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20902070272.0000 - val_loss: 21548218368.0000\n",
      "Epoch 107/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20839663616.0000 - val_loss: 21738899456.0000\n",
      "Epoch 108/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 21499181056.0000 - val_loss: 21741422592.0000\n",
      "Epoch 109/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20930220032.0000 - val_loss: 21677182976.0000\n",
      "Epoch 110/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20830533632.0000 - val_loss: 21679566848.0000\n",
      "Epoch 111/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20853983232.0000 - val_loss: 21976502272.0000\n",
      "Epoch 112/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20863832064.0000 - val_loss: 21423468544.0000\n",
      "Epoch 113/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20992000000.0000 - val_loss: 21372672000.0000\n",
      "Epoch 114/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 21178093568.0000 - val_loss: 21827979264.0000\n",
      "Epoch 115/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20728788992.0000 - val_loss: 21386125312.0000\n",
      "Epoch 116/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20958900224.0000 - val_loss: 21427709952.0000\n",
      "Epoch 117/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20744146944.0000 - val_loss: 21320634368.0000\n",
      "Epoch 118/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20729960448.0000 - val_loss: 21330495488.0000\n",
      "Epoch 119/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20807479296.0000 - val_loss: 21332893696.0000\n",
      "Epoch 120/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20647858176.0000 - val_loss: 21336332288.0000\n",
      "Epoch 121/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20599232512.0000 - val_loss: 21238396928.0000\n",
      "Epoch 122/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20948871168.0000 - val_loss: 21211813888.0000\n",
      "Epoch 123/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20543268864.0000 - val_loss: 21440200704.0000\n",
      "Epoch 124/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20706138112.0000 - val_loss: 21623494656.0000\n",
      "Epoch 125/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20699140096.0000 - val_loss: 21202382848.0000\n",
      "Epoch 126/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20433606656.0000 - val_loss: 21243924480.0000\n",
      "Epoch 127/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20668557312.0000 - val_loss: 21469065216.0000\n",
      "Epoch 128/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20516478976.0000 - val_loss: 21731069952.0000\n",
      "Epoch 129/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20533665792.0000 - val_loss: 21324431360.0000\n",
      "Epoch 130/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20381894656.0000 - val_loss: 21178939392.0000\n",
      "Epoch 131/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20376082432.0000 - val_loss: 21070649344.0000\n",
      "Epoch 132/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20528855040.0000 - val_loss: 21501171712.0000\n",
      "Epoch 133/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20519452672.0000 - val_loss: 21122316288.0000\n",
      "Epoch 134/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20514541568.0000 - val_loss: 21404672000.0000\n",
      "Epoch 135/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20707778560.0000 - val_loss: 20971974656.0000\n",
      "Epoch 136/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20553342976.0000 - val_loss: 21420920832.0000\n",
      "Epoch 137/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20482562048.0000 - val_loss: 22057461760.0000\n",
      "Epoch 138/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20265117696.0000 - val_loss: 20875173888.0000\n",
      "Epoch 139/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20214179840.0000 - val_loss: 21409953792.0000\n",
      "Epoch 140/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20296409088.0000 - val_loss: 20871655424.0000\n",
      "Epoch 141/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20282644480.0000 - val_loss: 20939962368.0000\n",
      "Epoch 142/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20562843648.0000 - val_loss: 20762191872.0000\n",
      "Epoch 143/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20085784576.0000 - val_loss: 20925200384.0000\n",
      "Epoch 144/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20271783936.0000 - val_loss: 20797296640.0000\n",
      "Epoch 145/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20278482944.0000 - val_loss: 20703631360.0000\n",
      "Epoch 146/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 20255318016.0000 - val_loss: 20718043136.0000\n",
      "Epoch 147/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20098691072.0000 - val_loss: 21529268224.0000\n",
      "Epoch 148/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20800970752.0000 - val_loss: 20622039040.0000\n",
      "Epoch 149/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19978866688.0000 - val_loss: 20861949952.0000\n",
      "Epoch 150/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20094816256.0000 - val_loss: 20671258624.0000\n",
      "Epoch 151/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20103655424.0000 - val_loss: 20875280384.0000\n",
      "Epoch 152/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19993456640.0000 - val_loss: 20614969344.0000\n",
      "Epoch 153/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19859869696.0000 - val_loss: 20525234176.0000\n",
      "Epoch 154/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20044576768.0000 - val_loss: 20557580288.0000\n",
      "Epoch 155/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19821875200.0000 - val_loss: 20652503040.0000\n",
      "Epoch 156/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19911163904.0000 - val_loss: 20529661952.0000\n",
      "Epoch 157/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 20230545408.0000 - val_loss: 21246525440.0000\n",
      "Epoch 158/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19995697152.0000 - val_loss: 20540860416.0000\n",
      "Epoch 159/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19729227776.0000 - val_loss: 20428617728.0000\n",
      "Epoch 160/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 19762345984.0000 - val_loss: 20272211968.0000\n",
      "Epoch 161/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19563235328.0000 - val_loss: 20179404800.0000\n",
      "Epoch 162/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19534727168.0000 - val_loss: 20959731712.0000\n",
      "Epoch 163/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19881773056.0000 - val_loss: 20184494080.0000\n",
      "Epoch 164/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 19867535360.0000 - val_loss: 20183156736.0000\n",
      "Epoch 165/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19561496576.0000 - val_loss: 20271323136.0000\n",
      "Epoch 166/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19922165760.0000 - val_loss: 22221314048.0000\n",
      "Epoch 167/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 20291956736.0000 - val_loss: 20468967424.0000\n",
      "Epoch 168/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19341907968.0000 - val_loss: 20041254912.0000\n",
      "Epoch 169/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19234285568.0000 - val_loss: 19879733248.0000\n",
      "Epoch 170/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19179010048.0000 - val_loss: 19870490624.0000\n",
      "Epoch 171/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19179880448.0000 - val_loss: 20226099200.0000\n",
      "Epoch 172/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19123986432.0000 - val_loss: 20309704704.0000\n",
      "Epoch 173/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19134795776.0000 - val_loss: 20073211904.0000\n",
      "Epoch 174/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18947948544.0000 - val_loss: 19517990912.0000\n",
      "Epoch 175/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18969649152.0000 - val_loss: 19719098368.0000\n",
      "Epoch 176/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 19077724160.0000 - val_loss: 19563118592.0000\n",
      "Epoch 177/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18870489088.0000 - val_loss: 19475050496.0000\n",
      "Epoch 178/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18782048256.0000 - val_loss: 20189286400.0000\n",
      "Epoch 179/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18912561152.0000 - val_loss: 19379169280.0000\n",
      "Epoch 180/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18888747008.0000 - val_loss: 19462512640.0000\n",
      "Epoch 181/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18572955648.0000 - val_loss: 19175135232.0000\n",
      "Epoch 182/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18418423808.0000 - val_loss: 19293896704.0000\n",
      "Epoch 183/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18486702080.0000 - val_loss: 18889320448.0000\n",
      "Epoch 184/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18336098304.0000 - val_loss: 18810593280.0000\n",
      "Epoch 185/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18184591360.0000 - val_loss: 18968668160.0000\n",
      "Epoch 186/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18171516928.0000 - val_loss: 18861352960.0000\n",
      "Epoch 187/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 19162896384.0000 - val_loss: 21244305408.0000\n",
      "Epoch 188/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18478909440.0000 - val_loss: 18581680128.0000\n",
      "Epoch 189/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 18079094784.0000 - val_loss: 18992553984.0000\n",
      "Epoch 190/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17852325888.0000 - val_loss: 18359040000.0000\n",
      "Epoch 191/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17759285248.0000 - val_loss: 18171686912.0000\n",
      "Epoch 192/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17642719232.0000 - val_loss: 18328659968.0000\n",
      "Epoch 193/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18070247424.0000 - val_loss: 18266206208.0000\n",
      "Epoch 194/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 18186424320.0000 - val_loss: 18269980672.0000\n",
      "Epoch 195/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17522059264.0000 - val_loss: 17748256768.0000\n",
      "Epoch 196/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17275002880.0000 - val_loss: 18007040000.0000\n",
      "Epoch 197/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 17200515072.0000 - val_loss: 17430996992.0000\n",
      "Epoch 198/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 17048203264.0000 - val_loss: 17431384064.0000\n",
      "Epoch 199/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16614810624.0000 - val_loss: 17038983168.0000\n",
      "Epoch 200/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 16469861376.0000 - val_loss: 16700244992.0000\n",
      "Epoch 201/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16211867648.0000 - val_loss: 16533227520.0000\n",
      "Epoch 202/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 16938842112.0000 - val_loss: 16987910144.0000\n",
      "Epoch 203/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15831927808.0000 - val_loss: 16267880448.0000\n",
      "Epoch 204/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15292190720.0000 - val_loss: 15682111488.0000\n",
      "Epoch 205/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15455177728.0000 - val_loss: 15599941632.0000\n",
      "Epoch 206/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14996281344.0000 - val_loss: 15216382976.0000\n",
      "Epoch 207/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 15077795840.0000 - val_loss: 17767950336.0000\n",
      "Epoch 208/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14788253696.0000 - val_loss: 15542721536.0000\n",
      "Epoch 209/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 15147527168.0000 - val_loss: 15909797888.0000\n",
      "Epoch 210/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14477434880.0000 - val_loss: 15157007360.0000\n",
      "Epoch 211/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 14468814848.0000 - val_loss: 16282001408.0000\n",
      "Epoch 212/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13998938112.0000 - val_loss: 15703270400.0000\n",
      "Epoch 213/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 14132230144.0000 - val_loss: 14071529472.0000\n",
      "Epoch 214/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13798414336.0000 - val_loss: 14451672064.0000\n",
      "Epoch 215/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13498816512.0000 - val_loss: 16164413440.0000\n",
      "Epoch 216/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13375683584.0000 - val_loss: 13796610048.0000\n",
      "Epoch 217/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13481230336.0000 - val_loss: 13825831936.0000\n",
      "Epoch 218/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13282667520.0000 - val_loss: 14254049280.0000\n",
      "Epoch 219/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13106714624.0000 - val_loss: 13499081728.0000\n",
      "Epoch 220/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12669633536.0000 - val_loss: 15706531840.0000\n",
      "Epoch 221/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 13018679296.0000 - val_loss: 15055721472.0000\n",
      "Epoch 222/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12697306112.0000 - val_loss: 13544075264.0000\n",
      "Epoch 223/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12462065664.0000 - val_loss: 14662786048.0000\n",
      "Epoch 224/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12366957568.0000 - val_loss: 14181336064.0000\n",
      "Epoch 225/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 13092179968.0000 - val_loss: 13812036608.0000\n",
      "Epoch 226/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12647106560.0000 - val_loss: 13077966848.0000\n",
      "Epoch 227/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12344599552.0000 - val_loss: 13059341312.0000\n",
      "Epoch 228/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12044459008.0000 - val_loss: 12383491072.0000\n",
      "Epoch 229/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12108077056.0000 - val_loss: 13386924032.0000\n",
      "Epoch 230/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11936677888.0000 - val_loss: 12259915776.0000\n",
      "Epoch 231/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11839827968.0000 - val_loss: 13826048000.0000\n",
      "Epoch 232/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11827003392.0000 - val_loss: 14348703744.0000\n",
      "Epoch 233/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11802326016.0000 - val_loss: 12144216064.0000\n",
      "Epoch 234/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11581009920.0000 - val_loss: 12056829952.0000\n",
      "Epoch 235/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11816740864.0000 - val_loss: 12232252416.0000\n",
      "Epoch 236/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11471363072.0000 - val_loss: 13107407872.0000\n",
      "Epoch 237/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11454055424.0000 - val_loss: 12035903488.0000\n",
      "Epoch 238/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11171764224.0000 - val_loss: 11669009408.0000\n",
      "Epoch 239/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11268520960.0000 - val_loss: 12182431744.0000\n",
      "Epoch 240/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11545502720.0000 - val_loss: 13225616384.0000\n",
      "Epoch 241/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11476057088.0000 - val_loss: 12273592320.0000\n",
      "Epoch 242/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11122582528.0000 - val_loss: 12878580736.0000\n",
      "Epoch 243/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11026317312.0000 - val_loss: 11799900160.0000\n",
      "Epoch 244/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11261161472.0000 - val_loss: 11872320512.0000\n",
      "Epoch 245/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11402326016.0000 - val_loss: 11416424448.0000\n",
      "Epoch 246/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 12445104128.0000 - val_loss: 11624737792.0000\n",
      "Epoch 247/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11100025856.0000 - val_loss: 13494344704.0000\n",
      "Epoch 248/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11327769600.0000 - val_loss: 14385782784.0000\n",
      "Epoch 249/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 11204495360.0000 - val_loss: 11498260480.0000\n",
      "Epoch 250/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 11032994816.0000 - val_loss: 11684817920.0000\n",
      "Epoch 251/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10840686592.0000 - val_loss: 13823163392.0000\n",
      "Epoch 252/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10719035392.0000 - val_loss: 11210098688.0000\n",
      "Epoch 253/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10694490112.0000 - val_loss: 11082551296.0000\n",
      "Epoch 254/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10732482560.0000 - val_loss: 11392763904.0000\n",
      "Epoch 255/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10798916608.0000 - val_loss: 10890891264.0000\n",
      "Epoch 256/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10512706560.0000 - val_loss: 12639706112.0000\n",
      "Epoch 257/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10684504064.0000 - val_loss: 10910776320.0000\n",
      "Epoch 258/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 12377656320.0000 - val_loss: 11089486848.0000\n",
      "Epoch 259/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10811854848.0000 - val_loss: 10848686080.0000\n",
      "Epoch 260/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10591640576.0000 - val_loss: 12879238144.0000\n",
      "Epoch 261/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10535153664.0000 - val_loss: 11178902528.0000\n",
      "Epoch 262/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10866462720.0000 - val_loss: 10935229440.0000\n",
      "Epoch 263/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10718129152.0000 - val_loss: 10703331328.0000\n",
      "Epoch 264/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10563197952.0000 - val_loss: 11511723008.0000\n",
      "Epoch 265/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10190516224.0000 - val_loss: 10879672320.0000\n",
      "Epoch 266/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10356983808.0000 - val_loss: 11159894016.0000\n",
      "Epoch 267/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10353389568.0000 - val_loss: 11239330816.0000\n",
      "Epoch 268/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10356837376.0000 - val_loss: 10778025984.0000\n",
      "Epoch 269/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10383730688.0000 - val_loss: 10719452160.0000\n",
      "Epoch 270/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10193013760.0000 - val_loss: 10604730368.0000\n",
      "Epoch 271/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10038218752.0000 - val_loss: 10527208448.0000\n",
      "Epoch 272/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10646974464.0000 - val_loss: 10365944832.0000\n",
      "Epoch 273/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10172986368.0000 - val_loss: 11403147264.0000\n",
      "Epoch 274/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10157227008.0000 - val_loss: 11537261568.0000\n",
      "Epoch 275/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10377163776.0000 - val_loss: 10957891584.0000\n",
      "Epoch 276/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10478295040.0000 - val_loss: 11071601664.0000\n",
      "Epoch 277/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10111454208.0000 - val_loss: 10414210048.0000\n",
      "Epoch 278/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10100026368.0000 - val_loss: 10591044608.0000\n",
      "Epoch 279/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10471312384.0000 - val_loss: 10379972608.0000\n",
      "Epoch 280/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9978707968.0000 - val_loss: 10495315968.0000\n",
      "Epoch 281/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9878181888.0000 - val_loss: 12648428544.0000\n",
      "Epoch 282/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10145858560.0000 - val_loss: 11895319552.0000\n",
      "Epoch 283/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9982046208.0000 - val_loss: 10193091584.0000\n",
      "Epoch 284/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9646774272.0000 - val_loss: 10187444224.0000\n",
      "Epoch 285/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9705953280.0000 - val_loss: 10198937600.0000\n",
      "Epoch 286/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10027819008.0000 - val_loss: 10028442624.0000\n",
      "Epoch 287/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10518145024.0000 - val_loss: 10577294336.0000\n",
      "Epoch 288/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9783785472.0000 - val_loss: 13142789120.0000\n",
      "Epoch 289/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9747017728.0000 - val_loss: 10433203200.0000\n",
      "Epoch 290/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 10107884544.0000 - val_loss: 10779524096.0000\n",
      "Epoch 291/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9999595520.0000 - val_loss: 10025917440.0000\n",
      "Epoch 292/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9458851840.0000 - val_loss: 11068621824.0000\n",
      "Epoch 293/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 10031166464.0000 - val_loss: 10555607040.0000\n",
      "Epoch 294/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9997535232.0000 - val_loss: 9953156096.0000\n",
      "Epoch 295/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9675539456.0000 - val_loss: 12314697728.0000\n",
      "Epoch 296/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9787592704.0000 - val_loss: 10213549056.0000\n",
      "Epoch 297/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9574902784.0000 - val_loss: 11691526144.0000\n",
      "Epoch 298/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9893817344.0000 - val_loss: 9886289920.0000\n",
      "Epoch 299/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9395352576.0000 - val_loss: 9911772160.0000\n",
      "Epoch 300/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9777540096.0000 - val_loss: 9887820800.0000\n",
      "Epoch 301/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9669028864.0000 - val_loss: 9974277120.0000\n",
      "Epoch 302/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9570487296.0000 - val_loss: 10345315328.0000\n",
      "Epoch 303/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9564886016.0000 - val_loss: 9942237184.0000\n",
      "Epoch 304/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9838613504.0000 - val_loss: 10043554816.0000\n",
      "Epoch 305/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9435790336.0000 - val_loss: 9615350784.0000\n",
      "Epoch 306/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9753879552.0000 - val_loss: 9985833984.0000\n",
      "Epoch 307/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9419650048.0000 - val_loss: 10028672000.0000\n",
      "Epoch 308/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9381929984.0000 - val_loss: 9819564032.0000\n",
      "Epoch 309/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9764708352.0000 - val_loss: 9675445248.0000\n",
      "Epoch 310/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9516593152.0000 - val_loss: 9542212608.0000\n",
      "Epoch 311/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9211498496.0000 - val_loss: 11171090432.0000\n",
      "Epoch 312/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9758186496.0000 - val_loss: 9622521856.0000\n",
      "Epoch 313/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9282844672.0000 - val_loss: 9802450944.0000\n",
      "Epoch 314/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9660275712.0000 - val_loss: 9485527040.0000\n",
      "Epoch 315/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9343588352.0000 - val_loss: 9979961344.0000\n",
      "Epoch 316/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9288586240.0000 - val_loss: 11301237760.0000\n",
      "Epoch 317/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9787314176.0000 - val_loss: 9594262528.0000\n",
      "Epoch 318/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9336590336.0000 - val_loss: 10124749824.0000\n",
      "Epoch 319/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9066342400.0000 - val_loss: 9414261760.0000\n",
      "Epoch 320/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9331406848.0000 - val_loss: 10802856960.0000\n",
      "Epoch 321/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9203922944.0000 - val_loss: 9657490432.0000\n",
      "Epoch 322/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9096190976.0000 - val_loss: 9635509248.0000\n",
      "Epoch 323/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9457236992.0000 - val_loss: 9515884544.0000\n",
      "Epoch 324/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9230258176.0000 - val_loss: 10176797696.0000\n",
      "Epoch 325/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9232883712.0000 - val_loss: 10191150080.0000\n",
      "Epoch 326/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9658164224.0000 - val_loss: 9468488704.0000\n",
      "Epoch 327/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9170704384.0000 - val_loss: 10350431232.0000\n",
      "Epoch 328/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9047229440.0000 - val_loss: 10088041472.0000\n",
      "Epoch 329/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9014463488.0000 - val_loss: 9220688896.0000\n",
      "Epoch 330/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9093952512.0000 - val_loss: 10576309248.0000\n",
      "Epoch 331/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9170765824.0000 - val_loss: 9837279232.0000\n",
      "Epoch 332/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9274756096.0000 - val_loss: 10060949504.0000\n",
      "Epoch 333/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9174411264.0000 - val_loss: 9233006592.0000\n",
      "Epoch 334/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9313396736.0000 - val_loss: 9763347456.0000\n",
      "Epoch 335/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8992425984.0000 - val_loss: 9289274368.0000\n",
      "Epoch 336/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8975031296.0000 - val_loss: 9474035712.0000\n",
      "Epoch 337/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8824598528.0000 - val_loss: 9291682816.0000\n",
      "Epoch 338/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8896438272.0000 - val_loss: 9459185664.0000\n",
      "Epoch 339/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9011229696.0000 - val_loss: 9567607808.0000\n",
      "Epoch 340/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9069318144.0000 - val_loss: 9321106432.0000\n",
      "Epoch 341/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8829232128.0000 - val_loss: 9328841728.0000\n",
      "Epoch 342/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8754366464.0000 - val_loss: 9036208128.0000\n",
      "Epoch 343/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8838951936.0000 - val_loss: 9081707520.0000\n",
      "Epoch 344/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9319611392.0000 - val_loss: 10227393536.0000\n",
      "Epoch 345/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8888226816.0000 - val_loss: 11097228288.0000\n",
      "Epoch 346/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8769442816.0000 - val_loss: 11261323264.0000\n",
      "Epoch 347/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9031725056.0000 - val_loss: 10030533632.0000\n",
      "Epoch 348/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8780774400.0000 - val_loss: 10525799424.0000\n",
      "Epoch 349/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9835418624.0000 - val_loss: 11903563776.0000\n",
      "Epoch 350/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9211160576.0000 - val_loss: 9456122880.0000\n",
      "Epoch 351/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9077343232.0000 - val_loss: 10800798720.0000\n",
      "Epoch 352/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8980038656.0000 - val_loss: 9072351232.0000\n",
      "Epoch 353/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9131816960.0000 - val_loss: 9116213248.0000\n",
      "Epoch 354/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8884589568.0000 - val_loss: 9427403776.0000\n",
      "Epoch 355/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9639075840.0000 - val_loss: 9996900352.0000\n",
      "Epoch 356/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9024826368.0000 - val_loss: 9195002880.0000\n",
      "Epoch 357/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9368555520.0000 - val_loss: 10852771840.0000\n",
      "Epoch 358/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8865611776.0000 - val_loss: 10329606144.0000\n",
      "Epoch 359/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9049706496.0000 - val_loss: 9404654592.0000\n",
      "Epoch 360/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8771127296.0000 - val_loss: 8906428416.0000\n",
      "Epoch 361/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8737111040.0000 - val_loss: 10143182848.0000\n",
      "Epoch 362/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9021447168.0000 - val_loss: 9004956672.0000\n",
      "Epoch 363/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8526352384.0000 - val_loss: 9077595136.0000\n",
      "Epoch 364/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8514818560.0000 - val_loss: 8834849792.0000\n",
      "Epoch 365/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8804036608.0000 - val_loss: 8722938880.0000\n",
      "Epoch 366/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8681600000.0000 - val_loss: 10934885376.0000\n",
      "Epoch 367/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9005878272.0000 - val_loss: 8917794816.0000\n",
      "Epoch 368/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8835815424.0000 - val_loss: 9017905152.0000\n",
      "Epoch 369/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8610899968.0000 - val_loss: 9201950720.0000\n",
      "Epoch 370/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8657808384.0000 - val_loss: 9287890944.0000\n",
      "Epoch 371/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8700300288.0000 - val_loss: 8795984896.0000\n",
      "Epoch 372/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8477327872.0000 - val_loss: 8690423808.0000\n",
      "Epoch 373/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8813074432.0000 - val_loss: 8683949056.0000\n",
      "Epoch 374/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8516097024.0000 - val_loss: 8752231424.0000\n",
      "Epoch 375/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8940613632.0000 - val_loss: 9103630336.0000\n",
      "Epoch 376/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8516012544.0000 - val_loss: 8963089408.0000\n",
      "Epoch 377/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8547999744.0000 - val_loss: 10214707200.0000\n",
      "Epoch 378/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8920094720.0000 - val_loss: 8742123520.0000\n",
      "Epoch 379/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8550910464.0000 - val_loss: 9790777344.0000\n",
      "Epoch 380/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8405895168.0000 - val_loss: 8729156608.0000\n",
      "Epoch 381/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8615318528.0000 - val_loss: 10600169472.0000\n",
      "Epoch 382/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8355121664.0000 - val_loss: 8882502656.0000\n",
      "Epoch 383/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8901023744.0000 - val_loss: 8995380224.0000\n",
      "Epoch 384/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9151865856.0000 - val_loss: 8639988736.0000\n",
      "Epoch 385/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8694598656.0000 - val_loss: 9272939520.0000\n",
      "Epoch 386/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8319997440.0000 - val_loss: 8776639488.0000\n",
      "Epoch 387/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8349413888.0000 - val_loss: 8605655040.0000\n",
      "Epoch 388/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8243561472.0000 - val_loss: 9324824576.0000\n",
      "Epoch 389/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8485508608.0000 - val_loss: 8583226368.0000\n",
      "Epoch 390/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8254680064.0000 - val_loss: 10124446720.0000\n",
      "Epoch 391/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8386886656.0000 - val_loss: 8531938304.0000\n",
      "Epoch 392/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9030744064.0000 - val_loss: 8621940736.0000\n",
      "Epoch 393/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8599132160.0000 - val_loss: 10005607424.0000\n",
      "Epoch 394/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8629997568.0000 - val_loss: 8612804608.0000\n",
      "Epoch 395/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8377933312.0000 - val_loss: 8511459328.0000\n",
      "Epoch 396/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8811506688.0000 - val_loss: 9322896384.0000\n",
      "Epoch 397/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8384782336.0000 - val_loss: 8568458240.0000\n",
      "Epoch 398/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8333775872.0000 - val_loss: 10133861376.0000\n",
      "Epoch 399/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8350565888.0000 - val_loss: 8656474112.0000\n",
      "Epoch 400/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8269542912.0000 - val_loss: 9096979456.0000\n",
      "Epoch 401/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9030390784.0000 - val_loss: 10655456256.0000\n",
      "Epoch 402/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8719625216.0000 - val_loss: 9533721600.0000\n",
      "Epoch 403/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9010177024.0000 - val_loss: 8864308224.0000\n",
      "Epoch 404/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8263099904.0000 - val_loss: 8412640256.0000\n",
      "Epoch 405/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8527710720.0000 - val_loss: 8620303360.0000\n",
      "Epoch 406/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8571192832.0000 - val_loss: 8704320512.0000\n",
      "Epoch 407/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8366155264.0000 - val_loss: 9508568064.0000\n",
      "Epoch 408/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8388736000.0000 - val_loss: 9287090176.0000\n",
      "Epoch 409/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8453948928.0000 - val_loss: 8616316928.0000\n",
      "Epoch 410/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8736317440.0000 - val_loss: 9383015424.0000\n",
      "Epoch 411/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8931467264.0000 - val_loss: 9192315904.0000\n",
      "Epoch 412/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8545806336.0000 - val_loss: 9060620288.0000\n",
      "Epoch 413/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8748312576.0000 - val_loss: 8481475584.0000\n",
      "Epoch 414/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8983377920.0000 - val_loss: 8443717632.0000\n",
      "Epoch 415/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8080198144.0000 - val_loss: 11895291904.0000\n",
      "Epoch 416/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8671604736.0000 - val_loss: 9164161024.0000\n",
      "Epoch 417/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8453963264.0000 - val_loss: 8518658048.0000\n",
      "Epoch 418/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8292222976.0000 - val_loss: 8982623232.0000\n",
      "Epoch 419/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8603241472.0000 - val_loss: 9975455744.0000\n",
      "Epoch 420/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8328037888.0000 - val_loss: 8853148672.0000\n",
      "Epoch 421/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8316803584.0000 - val_loss: 8430879232.0000\n",
      "Epoch 422/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8409704448.0000 - val_loss: 11406019584.0000\n",
      "Epoch 423/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8269824000.0000 - val_loss: 8744820736.0000\n",
      "Epoch 424/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8127451648.0000 - val_loss: 9147738112.0000\n",
      "Epoch 425/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8330284032.0000 - val_loss: 9404525568.0000\n",
      "Epoch 426/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8300759552.0000 - val_loss: 8459645440.0000\n",
      "Epoch 427/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9031647232.0000 - val_loss: 8855245824.0000\n",
      "Epoch 428/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8803650560.0000 - val_loss: 8444674560.0000\n",
      "Epoch 429/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8302407680.0000 - val_loss: 9505197056.0000\n",
      "Epoch 430/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8391290880.0000 - val_loss: 8496920576.0000\n",
      "Epoch 431/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8257494016.0000 - val_loss: 8531148800.0000\n",
      "Epoch 432/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7961732608.0000 - val_loss: 10086152192.0000\n",
      "Epoch 433/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8244301824.0000 - val_loss: 8716285952.0000\n",
      "Epoch 434/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8253595136.0000 - val_loss: 8958668800.0000\n",
      "Epoch 435/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8172566528.0000 - val_loss: 11154142208.0000\n",
      "Epoch 436/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8428494336.0000 - val_loss: 8567207936.0000\n",
      "Epoch 437/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8865890304.0000 - val_loss: 8275244544.0000\n",
      "Epoch 438/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8102240256.0000 - val_loss: 8413267968.0000\n",
      "Epoch 439/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8357712896.0000 - val_loss: 8603911168.0000\n",
      "Epoch 440/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8602301440.0000 - val_loss: 8944945152.0000\n",
      "Epoch 441/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8821699584.0000 - val_loss: 8532141056.0000\n",
      "Epoch 442/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8056705024.0000 - val_loss: 8346367488.0000\n",
      "Epoch 443/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8195189760.0000 - val_loss: 8143865344.0000\n",
      "Epoch 444/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8196114432.0000 - val_loss: 8554414080.0000\n",
      "Epoch 445/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8152862208.0000 - val_loss: 8428840448.0000\n",
      "Epoch 446/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8027140096.0000 - val_loss: 8346113024.0000\n",
      "Epoch 447/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8015982080.0000 - val_loss: 8524096000.0000\n",
      "Epoch 448/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8024512000.0000 - val_loss: 8147037696.0000\n",
      "Epoch 449/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8168640512.0000 - val_loss: 8103421952.0000\n",
      "Epoch 450/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8081464320.0000 - val_loss: 9659193344.0000\n",
      "Epoch 451/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9537954816.0000 - val_loss: 8474493952.0000\n",
      "Epoch 452/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8464838144.0000 - val_loss: 8822054912.0000\n",
      "Epoch 453/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8230316032.0000 - val_loss: 8501814272.0000\n",
      "Epoch 454/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7939713536.0000 - val_loss: 9573805056.0000\n",
      "Epoch 455/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8669597696.0000 - val_loss: 9984534528.0000\n",
      "Epoch 456/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8492274688.0000 - val_loss: 8429618688.0000\n",
      "Epoch 457/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7930828288.0000 - val_loss: 8994591744.0000\n",
      "Epoch 458/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8144160256.0000 - val_loss: 8232966656.0000\n",
      "Epoch 459/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8167008256.0000 - val_loss: 8263241216.0000\n",
      "Epoch 460/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8165918208.0000 - val_loss: 11444598784.0000\n",
      "Epoch 461/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8637579264.0000 - val_loss: 8196738560.0000\n",
      "Epoch 462/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8057479680.0000 - val_loss: 8368647168.0000\n",
      "Epoch 463/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7984451584.0000 - val_loss: 9865683968.0000\n",
      "Epoch 464/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8360192000.0000 - val_loss: 9229959168.0000\n",
      "Epoch 465/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8078861824.0000 - val_loss: 8350079488.0000\n",
      "Epoch 466/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7914222592.0000 - val_loss: 8646900736.0000\n",
      "Epoch 467/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8139200000.0000 - val_loss: 8051209728.0000\n",
      "Epoch 468/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8147653632.0000 - val_loss: 8440967168.0000\n",
      "Epoch 469/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8027702784.0000 - val_loss: 8134137856.0000\n",
      "Epoch 470/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8154655232.0000 - val_loss: 9202299904.0000\n",
      "Epoch 471/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8318417408.0000 - val_loss: 10007910400.0000\n",
      "Epoch 472/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8072106496.0000 - val_loss: 8371717120.0000\n",
      "Epoch 473/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8086476800.0000 - val_loss: 8633781248.0000\n",
      "Epoch 474/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8396771328.0000 - val_loss: 8899779584.0000\n",
      "Epoch 475/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8657514496.0000 - val_loss: 10139157504.0000\n",
      "Epoch 476/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8138261504.0000 - val_loss: 9493630976.0000\n",
      "Epoch 477/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8117949440.0000 - val_loss: 8348628992.0000\n",
      "Epoch 478/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7948774912.0000 - val_loss: 9076269056.0000\n",
      "Epoch 479/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8359298048.0000 - val_loss: 8404092416.0000\n",
      "Epoch 480/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8237645312.0000 - val_loss: 8293213696.0000\n",
      "Epoch 481/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8065360384.0000 - val_loss: 9516204032.0000\n",
      "Epoch 482/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7951208960.0000 - val_loss: 8249629184.0000\n",
      "Epoch 483/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8120645632.0000 - val_loss: 9181080576.0000\n",
      "Epoch 484/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7854464512.0000 - val_loss: 8544409088.0000\n",
      "Epoch 485/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8178533888.0000 - val_loss: 8087462400.0000\n",
      "Epoch 486/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7931854848.0000 - val_loss: 8316636160.0000\n",
      "Epoch 487/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8080514560.0000 - val_loss: 9057660928.0000\n",
      "Epoch 488/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9696828416.0000 - val_loss: 9905421312.0000\n",
      "Epoch 489/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8382836224.0000 - val_loss: 8353415680.0000\n",
      "Epoch 490/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7915401728.0000 - val_loss: 8204963840.0000\n",
      "Epoch 491/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7987994112.0000 - val_loss: 9332877312.0000\n",
      "Epoch 492/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7830375936.0000 - val_loss: 8814868480.0000\n",
      "Epoch 493/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7974190592.0000 - val_loss: 8626711552.0000\n",
      "Epoch 494/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8562517504.0000 - val_loss: 9320511488.0000\n",
      "Epoch 495/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8172812288.0000 - val_loss: 8979982336.0000\n",
      "Epoch 496/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8212131840.0000 - val_loss: 11603590144.0000\n",
      "Epoch 497/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8040481280.0000 - val_loss: 8005602304.0000\n",
      "Epoch 498/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7851203584.0000 - val_loss: 7898184704.0000\n",
      "Epoch 499/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8036541440.0000 - val_loss: 8168937984.0000\n",
      "Epoch 500/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7988576256.0000 - val_loss: 8033029120.0000\n",
      "Epoch 501/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7836496384.0000 - val_loss: 8069645312.0000\n",
      "Epoch 502/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8197083136.0000 - val_loss: 8604886016.0000\n",
      "Epoch 503/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8393073152.0000 - val_loss: 8090198016.0000\n",
      "Epoch 504/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8304559104.0000 - val_loss: 10148327424.0000\n",
      "Epoch 505/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8226780672.0000 - val_loss: 8177544704.0000\n",
      "Epoch 506/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8069220864.0000 - val_loss: 8267054592.0000\n",
      "Epoch 507/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7915448320.0000 - val_loss: 8527353856.0000\n",
      "Epoch 508/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8058804736.0000 - val_loss: 9188579328.0000\n",
      "Epoch 509/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8197129216.0000 - val_loss: 8552222208.0000\n",
      "Epoch 510/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7798386176.0000 - val_loss: 8000220672.0000\n",
      "Epoch 511/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8132147200.0000 - val_loss: 8075246080.0000\n",
      "Epoch 512/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7683351552.0000 - val_loss: 8150937600.0000\n",
      "Epoch 513/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8361196544.0000 - val_loss: 8168514048.0000\n",
      "Epoch 514/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7804247040.0000 - val_loss: 8277856768.0000\n",
      "Epoch 515/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9113128960.0000 - val_loss: 8127250432.0000\n",
      "Epoch 516/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7803536384.0000 - val_loss: 8028248064.0000\n",
      "Epoch 517/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7881586688.0000 - val_loss: 8087156224.0000\n",
      "Epoch 518/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7898190848.0000 - val_loss: 8037192704.0000\n",
      "Epoch 519/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8066920448.0000 - val_loss: 7937181696.0000\n",
      "Epoch 520/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7823884800.0000 - val_loss: 8146744832.0000\n",
      "Epoch 521/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7739195904.0000 - val_loss: 7966135296.0000\n",
      "Epoch 522/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7814883840.0000 - val_loss: 7900924928.0000\n",
      "Epoch 523/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7831109120.0000 - val_loss: 9586819072.0000\n",
      "Epoch 524/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7998198272.0000 - val_loss: 8076019200.0000\n",
      "Epoch 525/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7888849408.0000 - val_loss: 8174914048.0000\n",
      "Epoch 526/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7818130944.0000 - val_loss: 7981002240.0000\n",
      "Epoch 527/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8029451264.0000 - val_loss: 9615755264.0000\n",
      "Epoch 528/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7769271296.0000 - val_loss: 9022391296.0000\n",
      "Epoch 529/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8096957440.0000 - val_loss: 8154997248.0000\n",
      "Epoch 530/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7976351744.0000 - val_loss: 7976754688.0000\n",
      "Epoch 531/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7949742592.0000 - val_loss: 8037333504.0000\n",
      "Epoch 532/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8352668672.0000 - val_loss: 9300376576.0000\n",
      "Epoch 533/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7710135808.0000 - val_loss: 7868670464.0000\n",
      "Epoch 534/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7734680064.0000 - val_loss: 8043892224.0000\n",
      "Epoch 535/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7833789440.0000 - val_loss: 9033601024.0000\n",
      "Epoch 536/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7902869504.0000 - val_loss: 7837009920.0000\n",
      "Epoch 537/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7714572288.0000 - val_loss: 7907190272.0000\n",
      "Epoch 538/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8063053312.0000 - val_loss: 8461715456.0000\n",
      "Epoch 539/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8144983040.0000 - val_loss: 7856097792.0000\n",
      "Epoch 540/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7694175232.0000 - val_loss: 7886558720.0000\n",
      "Epoch 541/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7772617728.0000 - val_loss: 8271390720.0000\n",
      "Epoch 542/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8087839744.0000 - val_loss: 7929610752.0000\n",
      "Epoch 543/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8019752960.0000 - val_loss: 7979598848.0000\n",
      "Epoch 544/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7853611520.0000 - val_loss: 9109832704.0000\n",
      "Epoch 545/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8697656320.0000 - val_loss: 8162358784.0000\n",
      "Epoch 546/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7711565312.0000 - val_loss: 8376354304.0000\n",
      "Epoch 547/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8027031040.0000 - val_loss: 8223990784.0000\n",
      "Epoch 548/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7654472704.0000 - val_loss: 8108118528.0000\n",
      "Epoch 549/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9158868992.0000 - val_loss: 9929738240.0000\n",
      "Epoch 550/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8200324096.0000 - val_loss: 8442936832.0000\n",
      "Epoch 551/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7776515584.0000 - val_loss: 9519904768.0000\n",
      "Epoch 552/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 9997757440.0000 - val_loss: 7963160576.0000\n",
      "Epoch 553/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8000872960.0000 - val_loss: 9236011008.0000\n",
      "Epoch 554/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7840836608.0000 - val_loss: 9527145472.0000\n",
      "Epoch 555/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7887979008.0000 - val_loss: 7998495744.0000\n",
      "Epoch 556/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7873334272.0000 - val_loss: 7754677248.0000\n",
      "Epoch 557/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7600881664.0000 - val_loss: 9094636544.0000\n",
      "Epoch 558/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7843017728.0000 - val_loss: 10590501888.0000\n",
      "Epoch 559/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7899336192.0000 - val_loss: 8363945472.0000\n",
      "Epoch 560/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7701901824.0000 - val_loss: 8641825792.0000\n",
      "Epoch 561/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8133620736.0000 - val_loss: 8869567488.0000\n",
      "Epoch 562/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7958387712.0000 - val_loss: 11994022912.0000\n",
      "Epoch 563/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7953547776.0000 - val_loss: 8028833280.0000\n",
      "Epoch 564/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7931675648.0000 - val_loss: 8297467904.0000\n",
      "Epoch 565/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7938840064.0000 - val_loss: 8083195392.0000\n",
      "Epoch 566/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7784375808.0000 - val_loss: 7944676352.0000\n",
      "Epoch 567/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7665344512.0000 - val_loss: 8799825920.0000\n",
      "Epoch 568/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7993075712.0000 - val_loss: 8007368192.0000\n",
      "Epoch 569/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7857872896.0000 - val_loss: 8149242368.0000\n",
      "Epoch 570/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7748708352.0000 - val_loss: 8695458816.0000\n",
      "Epoch 571/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7948155904.0000 - val_loss: 8159579136.0000\n",
      "Epoch 572/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7713237504.0000 - val_loss: 9328377856.0000\n",
      "Epoch 573/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8306566656.0000 - val_loss: 9535693824.0000\n",
      "Epoch 574/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7905928704.0000 - val_loss: 8066991616.0000\n",
      "Epoch 575/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7829548032.0000 - val_loss: 7939864576.0000\n",
      "Epoch 576/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8028880384.0000 - val_loss: 8123594240.0000\n",
      "Epoch 577/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7703262720.0000 - val_loss: 8086625280.0000\n",
      "Epoch 578/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7721821696.0000 - val_loss: 8576951808.0000\n",
      "Epoch 579/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7772403712.0000 - val_loss: 8791538688.0000\n",
      "Epoch 580/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8019430400.0000 - val_loss: 11869638656.0000\n",
      "Epoch 581/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8219721728.0000 - val_loss: 7754106880.0000\n",
      "Epoch 582/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7913448448.0000 - val_loss: 7908382208.0000\n",
      "Epoch 583/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7932254208.0000 - val_loss: 11759896576.0000\n",
      "Epoch 584/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7940356608.0000 - val_loss: 7914298880.0000\n",
      "Epoch 585/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8271474688.0000 - val_loss: 8414452736.0000\n",
      "Epoch 586/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7837209088.0000 - val_loss: 8750879744.0000\n",
      "Epoch 587/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7915920896.0000 - val_loss: 8194054656.0000\n",
      "Epoch 588/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 8082219520.0000 - val_loss: 7813216256.0000\n",
      "Epoch 589/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7700759552.0000 - val_loss: 7838607872.0000\n",
      "Epoch 590/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7702894080.0000 - val_loss: 7956825088.0000\n",
      "Epoch 591/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7751789056.0000 - val_loss: 7830481408.0000\n",
      "Epoch 592/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7594196992.0000 - val_loss: 7828059648.0000\n",
      "Epoch 593/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7858945024.0000 - val_loss: 7891834368.0000\n",
      "Epoch 594/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7722749440.0000 - val_loss: 8852277248.0000\n",
      "Epoch 595/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8253655552.0000 - val_loss: 8706922496.0000\n",
      "Epoch 596/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8197429760.0000 - val_loss: 9148254208.0000\n",
      "Epoch 597/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7801912320.0000 - val_loss: 9660422144.0000\n",
      "Epoch 598/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7673646080.0000 - val_loss: 7851016704.0000\n",
      "Epoch 599/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7535500800.0000 - val_loss: 7818359296.0000\n",
      "Epoch 600/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7629025280.0000 - val_loss: 7803444224.0000\n",
      "Epoch 601/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7831181824.0000 - val_loss: 9985099776.0000\n",
      "Epoch 602/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7715597824.0000 - val_loss: 7882957824.0000\n",
      "Epoch 603/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8081267712.0000 - val_loss: 8175431168.0000\n",
      "Epoch 604/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7837820416.0000 - val_loss: 8938275840.0000\n",
      "Epoch 605/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7591493120.0000 - val_loss: 7741740032.0000\n",
      "Epoch 606/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7572557824.0000 - val_loss: 7787950592.0000\n",
      "Epoch 607/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7833108992.0000 - val_loss: 10060860416.0000\n",
      "Epoch 608/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7644918272.0000 - val_loss: 7955198976.0000\n",
      "Epoch 609/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8109801984.0000 - val_loss: 8051104768.0000\n",
      "Epoch 610/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7859102720.0000 - val_loss: 7914187264.0000\n",
      "Epoch 611/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7853805568.0000 - val_loss: 9182090240.0000\n",
      "Epoch 612/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7476721664.0000 - val_loss: 9006627840.0000\n",
      "Epoch 613/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7810124288.0000 - val_loss: 8155900416.0000\n",
      "Epoch 614/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7826049536.0000 - val_loss: 7678117376.0000\n",
      "Epoch 615/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7681913344.0000 - val_loss: 8614609920.0000\n",
      "Epoch 616/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7980953088.0000 - val_loss: 7686411264.0000\n",
      "Epoch 617/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 9289142272.0000 - val_loss: 11758562304.0000\n",
      "Epoch 618/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7907950080.0000 - val_loss: 7661830144.0000\n",
      "Epoch 619/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7903660032.0000 - val_loss: 7876840448.0000\n",
      "Epoch 620/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8232684032.0000 - val_loss: 8361310208.0000\n",
      "Epoch 621/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7974856704.0000 - val_loss: 7717275648.0000\n",
      "Epoch 622/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7909731840.0000 - val_loss: 8279301120.0000\n",
      "Epoch 623/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7530652160.0000 - val_loss: 8622039040.0000\n",
      "Epoch 624/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7624023552.0000 - val_loss: 10238944256.0000\n",
      "Epoch 625/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7656184320.0000 - val_loss: 8542558208.0000\n",
      "Epoch 626/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8051627008.0000 - val_loss: 7921842176.0000\n",
      "Epoch 627/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7587284992.0000 - val_loss: 7759181824.0000\n",
      "Epoch 628/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7550491136.0000 - val_loss: 8351800320.0000\n",
      "Epoch 629/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7652411392.0000 - val_loss: 7619998208.0000\n",
      "Epoch 630/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7997019648.0000 - val_loss: 7808080896.0000\n",
      "Epoch 631/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7423327232.0000 - val_loss: 8160273920.0000\n",
      "Epoch 632/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7707656704.0000 - val_loss: 7669475328.0000\n",
      "Epoch 633/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7560238080.0000 - val_loss: 8170707456.0000\n",
      "Epoch 634/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7980029952.0000 - val_loss: 9223790592.0000\n",
      "Epoch 635/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7876476928.0000 - val_loss: 7883523072.0000\n",
      "Epoch 636/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8003004416.0000 - val_loss: 8109003776.0000\n",
      "Epoch 637/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7935757312.0000 - val_loss: 7999355392.0000\n",
      "Epoch 638/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7815391744.0000 - val_loss: 7756373504.0000\n",
      "Epoch 639/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8019155456.0000 - val_loss: 7931995648.0000\n",
      "Epoch 640/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7795359232.0000 - val_loss: 7629275136.0000\n",
      "Epoch 641/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7680157184.0000 - val_loss: 8057509376.0000\n",
      "Epoch 642/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7694180864.0000 - val_loss: 9887839232.0000\n",
      "Epoch 643/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7774795264.0000 - val_loss: 7679769600.0000\n",
      "Epoch 644/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7670282752.0000 - val_loss: 8508325376.0000\n",
      "Epoch 645/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7647843840.0000 - val_loss: 9078093824.0000\n",
      "Epoch 646/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7705521152.0000 - val_loss: 8011907072.0000\n",
      "Epoch 647/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8041220608.0000 - val_loss: 7665797120.0000\n",
      "Epoch 648/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7728812544.0000 - val_loss: 7828730880.0000\n",
      "Epoch 649/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7429320704.0000 - val_loss: 7843601920.0000\n",
      "Epoch 650/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7634540032.0000 - val_loss: 8156566016.0000\n",
      "Epoch 651/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7702449152.0000 - val_loss: 7668486656.0000\n",
      "Epoch 652/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7611537408.0000 - val_loss: 7885624320.0000\n",
      "Epoch 653/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7513049600.0000 - val_loss: 8041004032.0000\n",
      "Epoch 654/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8167041536.0000 - val_loss: 8150222848.0000\n",
      "Epoch 655/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7727133696.0000 - val_loss: 8672112640.0000\n",
      "Epoch 656/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8369640960.0000 - val_loss: 7737986560.0000\n",
      "Epoch 657/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7655045632.0000 - val_loss: 7564014080.0000\n",
      "Epoch 658/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7638779392.0000 - val_loss: 7664352768.0000\n",
      "Epoch 659/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8035954688.0000 - val_loss: 7935521792.0000\n",
      "Epoch 660/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7643001344.0000 - val_loss: 7694801920.0000\n",
      "Epoch 661/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7503077376.0000 - val_loss: 7812646400.0000\n",
      "Epoch 662/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8033788928.0000 - val_loss: 8869505024.0000\n",
      "Epoch 663/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7879954432.0000 - val_loss: 8132005376.0000\n",
      "Epoch 664/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7899048960.0000 - val_loss: 8106428928.0000\n",
      "Epoch 665/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7648652288.0000 - val_loss: 8598001664.0000\n",
      "Epoch 666/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7930667008.0000 - val_loss: 7806341632.0000\n",
      "Epoch 667/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7689432064.0000 - val_loss: 7899209728.0000\n",
      "Epoch 668/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7535315456.0000 - val_loss: 7929705472.0000\n",
      "Epoch 669/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7643354112.0000 - val_loss: 8458569728.0000\n",
      "Epoch 670/3000\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 7727014912.0000 - val_loss: 7577198592.0000\n",
      "Epoch 671/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7656881664.0000 - val_loss: 7808208896.0000\n",
      "Epoch 672/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7688563712.0000 - val_loss: 7972537344.0000\n",
      "Epoch 673/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7659450368.0000 - val_loss: 8023166464.0000\n",
      "Epoch 674/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7467191296.0000 - val_loss: 7686721536.0000\n",
      "Epoch 675/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7561580544.0000 - val_loss: 8129184256.0000\n",
      "Epoch 676/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7788448768.0000 - val_loss: 7610034688.0000\n",
      "Epoch 677/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7645005824.0000 - val_loss: 7556203008.0000\n",
      "Epoch 678/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7631387136.0000 - val_loss: 7895941632.0000\n",
      "Epoch 679/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7976331264.0000 - val_loss: 9261469696.0000\n",
      "Epoch 680/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7705488384.0000 - val_loss: 8649975808.0000\n",
      "Epoch 681/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7644049408.0000 - val_loss: 7664532992.0000\n",
      "Epoch 682/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7608570880.0000 - val_loss: 8368375296.0000\n",
      "Epoch 683/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7908600320.0000 - val_loss: 8247001088.0000\n",
      "Epoch 684/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7679872512.0000 - val_loss: 7984973824.0000\n",
      "Epoch 685/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7391996416.0000 - val_loss: 7772429312.0000\n",
      "Epoch 686/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7803716608.0000 - val_loss: 8490404864.0000\n",
      "Epoch 687/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7484244992.0000 - val_loss: 7615963648.0000\n",
      "Epoch 688/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7736104960.0000 - val_loss: 7792060416.0000\n",
      "Epoch 689/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7714840576.0000 - val_loss: 7546284544.0000\n",
      "Epoch 690/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8225469952.0000 - val_loss: 7991398400.0000\n",
      "Epoch 691/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7764289024.0000 - val_loss: 8850916352.0000\n",
      "Epoch 692/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7799745024.0000 - val_loss: 7622495232.0000\n",
      "Epoch 693/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7774803968.0000 - val_loss: 7592151040.0000\n",
      "Epoch 694/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7547397632.0000 - val_loss: 8612876288.0000\n",
      "Epoch 695/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7593211392.0000 - val_loss: 8140519936.0000\n",
      "Epoch 696/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8228134912.0000 - val_loss: 7572497920.0000\n",
      "Epoch 697/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7979124224.0000 - val_loss: 7778057216.0000\n",
      "Epoch 698/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7827680768.0000 - val_loss: 7690543104.0000\n",
      "Epoch 699/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7512582656.0000 - val_loss: 8462406144.0000\n",
      "Epoch 700/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7720689152.0000 - val_loss: 8605696000.0000\n",
      "Epoch 701/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7768062464.0000 - val_loss: 7883501056.0000\n",
      "Epoch 702/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7941777408.0000 - val_loss: 7775720960.0000\n",
      "Epoch 703/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7539481088.0000 - val_loss: 8031797248.0000\n",
      "Epoch 704/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7987804160.0000 - val_loss: 9137033216.0000\n",
      "Epoch 705/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7794231296.0000 - val_loss: 7673858048.0000\n",
      "Epoch 706/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7934542848.0000 - val_loss: 8433782272.0000\n",
      "Epoch 707/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7909615104.0000 - val_loss: 11349043200.0000\n",
      "Epoch 708/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8129345536.0000 - val_loss: 8077277696.0000\n",
      "Epoch 709/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7512641024.0000 - val_loss: 7565016064.0000\n",
      "Epoch 710/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7486160384.0000 - val_loss: 8423973888.0000\n",
      "Epoch 711/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7656436736.0000 - val_loss: 8283384320.0000\n",
      "Epoch 712/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7700042240.0000 - val_loss: 8074660864.0000\n",
      "Epoch 713/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7511747072.0000 - val_loss: 7635978240.0000\n",
      "Epoch 714/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7830707200.0000 - val_loss: 8563610112.0000\n",
      "Epoch 715/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7856202240.0000 - val_loss: 8314212864.0000\n",
      "Epoch 716/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7736755712.0000 - val_loss: 7654040064.0000\n",
      "Epoch 717/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7417451008.0000 - val_loss: 7818131968.0000\n",
      "Epoch 718/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7482108416.0000 - val_loss: 7605854720.0000\n",
      "Epoch 719/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7450758656.0000 - val_loss: 9032541184.0000\n",
      "Epoch 720/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7463094784.0000 - val_loss: 7660141568.0000\n",
      "Epoch 721/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7494747648.0000 - val_loss: 8193169408.0000\n",
      "Epoch 722/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7582696448.0000 - val_loss: 8343526400.0000\n",
      "Epoch 723/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8302667264.0000 - val_loss: 8737717248.0000\n",
      "Epoch 724/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7420435968.0000 - val_loss: 7680889344.0000\n",
      "Epoch 725/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7478221312.0000 - val_loss: 7854213632.0000\n",
      "Epoch 726/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7485246464.0000 - val_loss: 7976229376.0000\n",
      "Epoch 727/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7593325568.0000 - val_loss: 7680562688.0000\n",
      "Epoch 728/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8135454208.0000 - val_loss: 7907747840.0000\n",
      "Epoch 729/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7648321024.0000 - val_loss: 7967294976.0000\n",
      "Epoch 730/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7746050560.0000 - val_loss: 10758191104.0000\n",
      "Epoch 731/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7754467328.0000 - val_loss: 7673870336.0000\n",
      "Epoch 732/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7582259200.0000 - val_loss: 7596548608.0000\n",
      "Epoch 733/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7675889152.0000 - val_loss: 11046522880.0000\n",
      "Epoch 734/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7849785856.0000 - val_loss: 7807835648.0000\n",
      "Epoch 735/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7419664896.0000 - val_loss: 8867411968.0000\n",
      "Epoch 736/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7902784000.0000 - val_loss: 7869027840.0000\n",
      "Epoch 737/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7702026240.0000 - val_loss: 9179267072.0000\n",
      "Epoch 738/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7623042560.0000 - val_loss: 7794725376.0000\n",
      "Epoch 739/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7555431424.0000 - val_loss: 7684866048.0000\n",
      "Epoch 740/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7733859840.0000 - val_loss: 8199344640.0000\n",
      "Epoch 741/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8039602688.0000 - val_loss: 7596104704.0000\n",
      "Epoch 742/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7324617728.0000 - val_loss: 8079870976.0000\n",
      "Epoch 743/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7599480832.0000 - val_loss: 7615626240.0000\n",
      "Epoch 744/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7482867712.0000 - val_loss: 7614877184.0000\n",
      "Epoch 745/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7558450176.0000 - val_loss: 7826943488.0000\n",
      "Epoch 746/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7613993984.0000 - val_loss: 7847628288.0000\n",
      "Epoch 747/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7487706112.0000 - val_loss: 7590458368.0000\n",
      "Epoch 748/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7503961600.0000 - val_loss: 9717512192.0000\n",
      "Epoch 749/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7655859200.0000 - val_loss: 8955137024.0000\n",
      "Epoch 750/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8133038080.0000 - val_loss: 7587522048.0000\n",
      "Epoch 751/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7419854848.0000 - val_loss: 7702018560.0000\n",
      "Epoch 752/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7402066944.0000 - val_loss: 7867935744.0000\n",
      "Epoch 753/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7788561408.0000 - val_loss: 9075460096.0000\n",
      "Epoch 754/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8074808832.0000 - val_loss: 8050992128.0000\n",
      "Epoch 755/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7913664512.0000 - val_loss: 7518713856.0000\n",
      "Epoch 756/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7564967936.0000 - val_loss: 8156619264.0000\n",
      "Epoch 757/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7477741568.0000 - val_loss: 7759365120.0000\n",
      "Epoch 758/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7489930752.0000 - val_loss: 7617158656.0000\n",
      "Epoch 759/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7473455616.0000 - val_loss: 9026846720.0000\n",
      "Epoch 760/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8199788544.0000 - val_loss: 9554011136.0000\n",
      "Epoch 761/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7587895296.0000 - val_loss: 8607566848.0000\n",
      "Epoch 762/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7548634112.0000 - val_loss: 8039683072.0000\n",
      "Epoch 763/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7828589568.0000 - val_loss: 7606802432.0000\n",
      "Epoch 764/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7430515712.0000 - val_loss: 7474626560.0000\n",
      "Epoch 765/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7530056704.0000 - val_loss: 7728796672.0000\n",
      "Epoch 766/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7569611264.0000 - val_loss: 8147048960.0000\n",
      "Epoch 767/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7471511040.0000 - val_loss: 7714606592.0000\n",
      "Epoch 768/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7928205312.0000 - val_loss: 8006036480.0000\n",
      "Epoch 769/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7956221440.0000 - val_loss: 8354007552.0000\n",
      "Epoch 770/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7648680448.0000 - val_loss: 7498881024.0000\n",
      "Epoch 771/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7665838592.0000 - val_loss: 7499234304.0000\n",
      "Epoch 772/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7730995712.0000 - val_loss: 7973647872.0000\n",
      "Epoch 773/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7361315840.0000 - val_loss: 8110673920.0000\n",
      "Epoch 774/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7739161088.0000 - val_loss: 9734535168.0000\n",
      "Epoch 775/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7665470976.0000 - val_loss: 8322910208.0000\n",
      "Epoch 776/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7665696768.0000 - val_loss: 7519562240.0000\n",
      "Epoch 777/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7448655360.0000 - val_loss: 7898692608.0000\n",
      "Epoch 778/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7596771328.0000 - val_loss: 7867781632.0000\n",
      "Epoch 779/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7911961600.0000 - val_loss: 7544455680.0000\n",
      "Epoch 780/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7606755328.0000 - val_loss: 7616686080.0000\n",
      "Epoch 781/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7487186432.0000 - val_loss: 8577756160.0000\n",
      "Epoch 782/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7601995776.0000 - val_loss: 7666860032.0000\n",
      "Epoch 783/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7422262784.0000 - val_loss: 7547633152.0000\n",
      "Epoch 784/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7396349440.0000 - val_loss: 7823567872.0000\n",
      "Epoch 785/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7640958464.0000 - val_loss: 7925533184.0000\n",
      "Epoch 786/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7429350912.0000 - val_loss: 7748536832.0000\n",
      "Epoch 787/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7414604800.0000 - val_loss: 7579807232.0000\n",
      "Epoch 788/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7685981696.0000 - val_loss: 8030391808.0000\n",
      "Epoch 789/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7768862720.0000 - val_loss: 8120730624.0000\n",
      "Epoch 790/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7789043712.0000 - val_loss: 8907825152.0000\n",
      "Epoch 791/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7941406208.0000 - val_loss: 7769659904.0000\n",
      "Epoch 792/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7473247232.0000 - val_loss: 7537852416.0000\n",
      "Epoch 793/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7335623680.0000 - val_loss: 8054386688.0000\n",
      "Epoch 794/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7568659968.0000 - val_loss: 7556783104.0000\n",
      "Epoch 795/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7747292672.0000 - val_loss: 7540648448.0000\n",
      "Epoch 796/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7494211584.0000 - val_loss: 7857719808.0000\n",
      "Epoch 797/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7488843776.0000 - val_loss: 7570905600.0000\n",
      "Epoch 798/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7419296768.0000 - val_loss: 8823027712.0000\n",
      "Epoch 799/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8052617728.0000 - val_loss: 7618611200.0000\n",
      "Epoch 800/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7395186688.0000 - val_loss: 7533408768.0000\n",
      "Epoch 801/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7464161280.0000 - val_loss: 7952733696.0000\n",
      "Epoch 802/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7696460288.0000 - val_loss: 7857049600.0000\n",
      "Epoch 803/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7708785664.0000 - val_loss: 7529219072.0000\n",
      "Epoch 804/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7601759744.0000 - val_loss: 9063484416.0000\n",
      "Epoch 805/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7638433280.0000 - val_loss: 8405634048.0000\n",
      "Epoch 806/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8176960512.0000 - val_loss: 7604201472.0000\n",
      "Epoch 807/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7696825856.0000 - val_loss: 8187935744.0000\n",
      "Epoch 808/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7734802432.0000 - val_loss: 7848358400.0000\n",
      "Epoch 809/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7577247232.0000 - val_loss: 9476253696.0000\n",
      "Epoch 810/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7922957824.0000 - val_loss: 7871737344.0000\n",
      "Epoch 811/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7444127232.0000 - val_loss: 8210344960.0000\n",
      "Epoch 812/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7538982912.0000 - val_loss: 7630839808.0000\n",
      "Epoch 813/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7537712128.0000 - val_loss: 7482468352.0000\n",
      "Epoch 814/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7507550208.0000 - val_loss: 7479769600.0000\n",
      "Epoch 815/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7561404928.0000 - val_loss: 7722053120.0000\n",
      "Epoch 816/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8048688640.0000 - val_loss: 7769128960.0000\n",
      "Epoch 817/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7376120320.0000 - val_loss: 9020910592.0000\n",
      "Epoch 818/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7494306304.0000 - val_loss: 7423317504.0000\n",
      "Epoch 819/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7348419584.0000 - val_loss: 7550221824.0000\n",
      "Epoch 820/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7495781376.0000 - val_loss: 9143544832.0000\n",
      "Epoch 821/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7430083072.0000 - val_loss: 7459316224.0000\n",
      "Epoch 822/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8151187968.0000 - val_loss: 8811274240.0000\n",
      "Epoch 823/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7557885440.0000 - val_loss: 7948904960.0000\n",
      "Epoch 824/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7456357376.0000 - val_loss: 8453858304.0000\n",
      "Epoch 825/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7437147136.0000 - val_loss: 7680910848.0000\n",
      "Epoch 826/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7256527360.0000 - val_loss: 7544168448.0000\n",
      "Epoch 827/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7471453184.0000 - val_loss: 8427226112.0000\n",
      "Epoch 828/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7528765952.0000 - val_loss: 8097088000.0000\n",
      "Epoch 829/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7563156480.0000 - val_loss: 8882803712.0000\n",
      "Epoch 830/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7663418368.0000 - val_loss: 7772802048.0000\n",
      "Epoch 831/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7502458368.0000 - val_loss: 7507827712.0000\n",
      "Epoch 832/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7394453504.0000 - val_loss: 8390949888.0000\n",
      "Epoch 833/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7491128320.0000 - val_loss: 7822979584.0000\n",
      "Epoch 834/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8294183936.0000 - val_loss: 7942345728.0000\n",
      "Epoch 835/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7520538112.0000 - val_loss: 8132478976.0000\n",
      "Epoch 836/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7516904960.0000 - val_loss: 7512518144.0000\n",
      "Epoch 837/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7373140480.0000 - val_loss: 7443989504.0000\n",
      "Epoch 838/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7368933888.0000 - val_loss: 7909707264.0000\n",
      "Epoch 839/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7480527872.0000 - val_loss: 8966993920.0000\n",
      "Epoch 840/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7583113728.0000 - val_loss: 7448999424.0000\n",
      "Epoch 841/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7448889856.0000 - val_loss: 8594612224.0000\n",
      "Epoch 842/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7637177344.0000 - val_loss: 7467201536.0000\n",
      "Epoch 843/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7305098752.0000 - val_loss: 7500785152.0000\n",
      "Epoch 844/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7712467968.0000 - val_loss: 9897564160.0000\n",
      "Epoch 845/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7602090496.0000 - val_loss: 7429409792.0000\n",
      "Epoch 846/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7258785280.0000 - val_loss: 8247035392.0000\n",
      "Epoch 847/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7687298048.0000 - val_loss: 8496846336.0000\n",
      "Epoch 848/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7928788480.0000 - val_loss: 8462561280.0000\n",
      "Epoch 849/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7744507904.0000 - val_loss: 7937345536.0000\n",
      "Epoch 850/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7504320512.0000 - val_loss: 7445927936.0000\n",
      "Epoch 851/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7592073216.0000 - val_loss: 7865269248.0000\n",
      "Epoch 852/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7396805120.0000 - val_loss: 7618246144.0000\n",
      "Epoch 853/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7506616832.0000 - val_loss: 7864502784.0000\n",
      "Epoch 854/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7761855488.0000 - val_loss: 7684705280.0000\n",
      "Epoch 855/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7238892544.0000 - val_loss: 7583239168.0000\n",
      "Epoch 856/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7969724416.0000 - val_loss: 7575688192.0000\n",
      "Epoch 857/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7526513664.0000 - val_loss: 7796764160.0000\n",
      "Epoch 858/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7512615936.0000 - val_loss: 8144066048.0000\n",
      "Epoch 859/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7706061312.0000 - val_loss: 7640708608.0000\n",
      "Epoch 860/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7687708672.0000 - val_loss: 7447685120.0000\n",
      "Epoch 861/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7537083392.0000 - val_loss: 7460150784.0000\n",
      "Epoch 862/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7890400768.0000 - val_loss: 8092730368.0000\n",
      "Epoch 863/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7641023488.0000 - val_loss: 7472632320.0000\n",
      "Epoch 864/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7267679232.0000 - val_loss: 7503321600.0000\n",
      "Epoch 865/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7293395968.0000 - val_loss: 7680714240.0000\n",
      "Epoch 866/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7518820352.0000 - val_loss: 8128676864.0000\n",
      "Epoch 867/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7386589184.0000 - val_loss: 7684989952.0000\n",
      "Epoch 868/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7753000448.0000 - val_loss: 10618499072.0000\n",
      "Epoch 869/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7646155264.0000 - val_loss: 7629239808.0000\n",
      "Epoch 870/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7672963584.0000 - val_loss: 7502579200.0000\n",
      "Epoch 871/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7850635776.0000 - val_loss: 7587719168.0000\n",
      "Epoch 872/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7323949056.0000 - val_loss: 7545181696.0000\n",
      "Epoch 873/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7327325184.0000 - val_loss: 8302708224.0000\n",
      "Epoch 874/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7629877760.0000 - val_loss: 9679931392.0000\n",
      "Epoch 875/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7448863744.0000 - val_loss: 9885337600.0000\n",
      "Epoch 876/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7782797312.0000 - val_loss: 8149028352.0000\n",
      "Epoch 877/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7486628864.0000 - val_loss: 7507063296.0000\n",
      "Epoch 878/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7548981248.0000 - val_loss: 7522248192.0000\n",
      "Epoch 879/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7680800768.0000 - val_loss: 8362432000.0000\n",
      "Epoch 880/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7549240320.0000 - val_loss: 7923112960.0000\n",
      "Epoch 881/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7432614912.0000 - val_loss: 7406612992.0000\n",
      "Epoch 882/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7511971328.0000 - val_loss: 7543595520.0000\n",
      "Epoch 883/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7352801792.0000 - val_loss: 8761953280.0000\n",
      "Epoch 884/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7345130496.0000 - val_loss: 7547500544.0000\n",
      "Epoch 885/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7430872576.0000 - val_loss: 7530248704.0000\n",
      "Epoch 886/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7441719808.0000 - val_loss: 9986297856.0000\n",
      "Epoch 887/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7694097920.0000 - val_loss: 8015613952.0000\n",
      "Epoch 888/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7463465472.0000 - val_loss: 8179188736.0000\n",
      "Epoch 889/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7912803328.0000 - val_loss: 7627249664.0000\n",
      "Epoch 890/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7654063104.0000 - val_loss: 8141361152.0000\n",
      "Epoch 891/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7577892864.0000 - val_loss: 7458960896.0000\n",
      "Epoch 892/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7330275328.0000 - val_loss: 7863100416.0000\n",
      "Epoch 893/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8227921920.0000 - val_loss: 9923751936.0000\n",
      "Epoch 894/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7649740288.0000 - val_loss: 7498014720.0000\n",
      "Epoch 895/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7314384896.0000 - val_loss: 7989355008.0000\n",
      "Epoch 896/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7417277440.0000 - val_loss: 7408323584.0000\n",
      "Epoch 897/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7446262272.0000 - val_loss: 7455427584.0000\n",
      "Epoch 898/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7508491776.0000 - val_loss: 7474787328.0000\n",
      "Epoch 899/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8389763584.0000 - val_loss: 7790683648.0000\n",
      "Epoch 900/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7484033536.0000 - val_loss: 8985207808.0000\n",
      "Epoch 901/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7464729088.0000 - val_loss: 7936161792.0000\n",
      "Epoch 902/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7769313280.0000 - val_loss: 8385124352.0000\n",
      "Epoch 903/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7262024704.0000 - val_loss: 7487327744.0000\n",
      "Epoch 904/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7388794368.0000 - val_loss: 7778110976.0000\n",
      "Epoch 905/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7427020288.0000 - val_loss: 9130620928.0000\n",
      "Epoch 906/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7533814272.0000 - val_loss: 7411616768.0000\n",
      "Epoch 907/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7482549248.0000 - val_loss: 7534175232.0000\n",
      "Epoch 908/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7405181952.0000 - val_loss: 8388487168.0000\n",
      "Epoch 909/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7738616320.0000 - val_loss: 7788691968.0000\n",
      "Epoch 910/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7441034240.0000 - val_loss: 7466039808.0000\n",
      "Epoch 911/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7405502464.0000 - val_loss: 8534950400.0000\n",
      "Epoch 912/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7815726592.0000 - val_loss: 11266411520.0000\n",
      "Epoch 913/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7656406016.0000 - val_loss: 7697945088.0000\n",
      "Epoch 914/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7425197056.0000 - val_loss: 8677727232.0000\n",
      "Epoch 915/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7457000448.0000 - val_loss: 7684166656.0000\n",
      "Epoch 916/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7325726720.0000 - val_loss: 7560383488.0000\n",
      "Epoch 917/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7592894976.0000 - val_loss: 7414496256.0000\n",
      "Epoch 918/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7598834688.0000 - val_loss: 10320684032.0000\n",
      "Epoch 919/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7568478720.0000 - val_loss: 7537261568.0000\n",
      "Epoch 920/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7486693888.0000 - val_loss: 9225231360.0000\n",
      "Epoch 921/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7630908928.0000 - val_loss: 7790051840.0000\n",
      "Epoch 922/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7538340352.0000 - val_loss: 7497538560.0000\n",
      "Epoch 923/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7293403136.0000 - val_loss: 7454742016.0000\n",
      "Epoch 924/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7483619840.0000 - val_loss: 7491557376.0000\n",
      "Epoch 925/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7496359936.0000 - val_loss: 8015945728.0000\n",
      "Epoch 926/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7611003904.0000 - val_loss: 8769773568.0000\n",
      "Epoch 927/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7203874816.0000 - val_loss: 7534489600.0000\n",
      "Epoch 928/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7338237440.0000 - val_loss: 8317574656.0000\n",
      "Epoch 929/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7878283776.0000 - val_loss: 7887460864.0000\n",
      "Epoch 930/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7840273920.0000 - val_loss: 7485889024.0000\n",
      "Epoch 931/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7651188224.0000 - val_loss: 7526039552.0000\n",
      "Epoch 932/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7456821760.0000 - val_loss: 7543257600.0000\n",
      "Epoch 933/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7392339456.0000 - val_loss: 7513356288.0000\n",
      "Epoch 934/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7794835968.0000 - val_loss: 11904871424.0000\n",
      "Epoch 935/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7906818048.0000 - val_loss: 7718180352.0000\n",
      "Epoch 936/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7173336064.0000 - val_loss: 8513935360.0000\n",
      "Epoch 937/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7580662272.0000 - val_loss: 7615981056.0000\n",
      "Epoch 938/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7307644928.0000 - val_loss: 8429844480.0000\n",
      "Epoch 939/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7340065280.0000 - val_loss: 7587022848.0000\n",
      "Epoch 940/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7500479488.0000 - val_loss: 12849933312.0000\n",
      "Epoch 941/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7964832768.0000 - val_loss: 7879779840.0000\n",
      "Epoch 942/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7556401152.0000 - val_loss: 8053104128.0000\n",
      "Epoch 943/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7457396224.0000 - val_loss: 7648625152.0000\n",
      "Epoch 944/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7710109696.0000 - val_loss: 8510669824.0000\n",
      "Epoch 945/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7385546240.0000 - val_loss: 7915741696.0000\n",
      "Epoch 946/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7446507008.0000 - val_loss: 7699806208.0000\n",
      "Epoch 947/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7545693696.0000 - val_loss: 7521932288.0000\n",
      "Epoch 948/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7396884992.0000 - val_loss: 7968002048.0000\n",
      "Epoch 949/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7525026816.0000 - val_loss: 7549566464.0000\n",
      "Epoch 950/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7456545792.0000 - val_loss: 7609300480.0000\n",
      "Epoch 951/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7210318336.0000 - val_loss: 7465678336.0000\n",
      "Epoch 952/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7537425408.0000 - val_loss: 7984992768.0000\n",
      "Epoch 953/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7887660544.0000 - val_loss: 7540783616.0000\n",
      "Epoch 954/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7302912000.0000 - val_loss: 7410754560.0000\n",
      "Epoch 955/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7443288576.0000 - val_loss: 7823401472.0000\n",
      "Epoch 956/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7448832512.0000 - val_loss: 9365216256.0000\n",
      "Epoch 957/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7547690496.0000 - val_loss: 8922407936.0000\n",
      "Epoch 958/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7579804672.0000 - val_loss: 7540914688.0000\n",
      "Epoch 959/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7400280064.0000 - val_loss: 7429426176.0000\n",
      "Epoch 960/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7729596416.0000 - val_loss: 7448464384.0000\n",
      "Epoch 961/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7523670016.0000 - val_loss: 7678952448.0000\n",
      "Epoch 962/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7437491712.0000 - val_loss: 7958526464.0000\n",
      "Epoch 963/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7583985152.0000 - val_loss: 7438873088.0000\n",
      "Epoch 964/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7300236288.0000 - val_loss: 7568379904.0000\n",
      "Epoch 965/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7394554368.0000 - val_loss: 8477927936.0000\n",
      "Epoch 966/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7549565952.0000 - val_loss: 7749234688.0000\n",
      "Epoch 967/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7828308992.0000 - val_loss: 7446772224.0000\n",
      "Epoch 968/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7611079168.0000 - val_loss: 8101352448.0000\n",
      "Epoch 969/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7550433280.0000 - val_loss: 8146712064.0000\n",
      "Epoch 970/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7344290816.0000 - val_loss: 7616199680.0000\n",
      "Epoch 971/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7681730560.0000 - val_loss: 7399807488.0000\n",
      "Epoch 972/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7502389248.0000 - val_loss: 8275796480.0000\n",
      "Epoch 973/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7756716032.0000 - val_loss: 7407008768.0000\n",
      "Epoch 974/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7216269824.0000 - val_loss: 9628831744.0000\n",
      "Epoch 975/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7604980736.0000 - val_loss: 7696406528.0000\n",
      "Epoch 976/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7597673984.0000 - val_loss: 7636267520.0000\n",
      "Epoch 977/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7443595776.0000 - val_loss: 7708263936.0000\n",
      "Epoch 978/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7507482112.0000 - val_loss: 8598933504.0000\n",
      "Epoch 979/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7488765440.0000 - val_loss: 7496625152.0000\n",
      "Epoch 980/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7227038208.0000 - val_loss: 7410188800.0000\n",
      "Epoch 981/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7395475456.0000 - val_loss: 9184718848.0000\n",
      "Epoch 982/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7330880000.0000 - val_loss: 7502694912.0000\n",
      "Epoch 983/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7295867904.0000 - val_loss: 8913180672.0000\n",
      "Epoch 984/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7722023936.0000 - val_loss: 7723255808.0000\n",
      "Epoch 985/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7542231552.0000 - val_loss: 7961640448.0000\n",
      "Epoch 986/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7308619776.0000 - val_loss: 7431768576.0000\n",
      "Epoch 987/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7565694464.0000 - val_loss: 8430609408.0000\n",
      "Epoch 988/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7308194816.0000 - val_loss: 7323718656.0000\n",
      "Epoch 989/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7675588608.0000 - val_loss: 8251268096.0000\n",
      "Epoch 990/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7245501440.0000 - val_loss: 7889885696.0000\n",
      "Epoch 991/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7487291392.0000 - val_loss: 7511351808.0000\n",
      "Epoch 992/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7527505408.0000 - val_loss: 8755397632.0000\n",
      "Epoch 993/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7664638464.0000 - val_loss: 7682964480.0000\n",
      "Epoch 994/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7239930368.0000 - val_loss: 7462490112.0000\n",
      "Epoch 995/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7322490880.0000 - val_loss: 7685305856.0000\n",
      "Epoch 996/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7773741568.0000 - val_loss: 7437067776.0000\n",
      "Epoch 997/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7588192768.0000 - val_loss: 10278025216.0000\n",
      "Epoch 998/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7750485504.0000 - val_loss: 7640685056.0000\n",
      "Epoch 999/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7660721152.0000 - val_loss: 7401480192.0000\n",
      "Epoch 1000/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8131555840.0000 - val_loss: 7457124352.0000\n",
      "Epoch 1001/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7564766208.0000 - val_loss: 7575602176.0000\n",
      "Epoch 1002/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7412135424.0000 - val_loss: 8829105152.0000\n",
      "Epoch 1003/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7234727424.0000 - val_loss: 8033724416.0000\n",
      "Epoch 1004/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7206055936.0000 - val_loss: 7331569152.0000\n",
      "Epoch 1005/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7230024704.0000 - val_loss: 7932803072.0000\n",
      "Epoch 1006/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7426260480.0000 - val_loss: 7867271680.0000\n",
      "Epoch 1007/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7742730240.0000 - val_loss: 7615582208.0000\n",
      "Epoch 1008/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7441680896.0000 - val_loss: 8151071744.0000\n",
      "Epoch 1009/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7692792320.0000 - val_loss: 8630918144.0000\n",
      "Epoch 1010/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7369690112.0000 - val_loss: 7606545920.0000\n",
      "Epoch 1011/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8105050624.0000 - val_loss: 7655315968.0000\n",
      "Epoch 1012/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7377819136.0000 - val_loss: 7655117312.0000\n",
      "Epoch 1013/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7190355456.0000 - val_loss: 7360962048.0000\n",
      "Epoch 1014/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8026309632.0000 - val_loss: 7607719936.0000\n",
      "Epoch 1015/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7410593792.0000 - val_loss: 7438432256.0000\n",
      "Epoch 1016/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7336388608.0000 - val_loss: 7335376896.0000\n",
      "Epoch 1017/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7645855744.0000 - val_loss: 7486633472.0000\n",
      "Epoch 1018/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131619328.0000 - val_loss: 7379441152.0000\n",
      "Epoch 1019/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7326975488.0000 - val_loss: 7484390400.0000\n",
      "Epoch 1020/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7767339520.0000 - val_loss: 9566389248.0000\n",
      "Epoch 1021/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7803053568.0000 - val_loss: 7963752448.0000\n",
      "Epoch 1022/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7270058496.0000 - val_loss: 7957697024.0000\n",
      "Epoch 1023/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7312829440.0000 - val_loss: 7882548224.0000\n",
      "Epoch 1024/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7552210944.0000 - val_loss: 7644609024.0000\n",
      "Epoch 1025/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7237429248.0000 - val_loss: 7540728832.0000\n",
      "Epoch 1026/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7215579648.0000 - val_loss: 7363686912.0000\n",
      "Epoch 1027/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7903318528.0000 - val_loss: 7883918336.0000\n",
      "Epoch 1028/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7388896256.0000 - val_loss: 8103895552.0000\n",
      "Epoch 1029/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7666658304.0000 - val_loss: 7393432064.0000\n",
      "Epoch 1030/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7362355200.0000 - val_loss: 7971533824.0000\n",
      "Epoch 1031/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7559857664.0000 - val_loss: 8494798848.0000\n",
      "Epoch 1032/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7668793344.0000 - val_loss: 8706881536.0000\n",
      "Epoch 1033/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7733691904.0000 - val_loss: 7882099712.0000\n",
      "Epoch 1034/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7234287104.0000 - val_loss: 7413602304.0000\n",
      "Epoch 1035/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7356519424.0000 - val_loss: 7502618112.0000\n",
      "Epoch 1036/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7398576128.0000 - val_loss: 7715791360.0000\n",
      "Epoch 1037/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7589886464.0000 - val_loss: 7618100224.0000\n",
      "Epoch 1038/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7376067072.0000 - val_loss: 7665059840.0000\n",
      "Epoch 1039/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7338803200.0000 - val_loss: 7485136896.0000\n",
      "Epoch 1040/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7472718848.0000 - val_loss: 7668428288.0000\n",
      "Epoch 1041/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7367770112.0000 - val_loss: 7610825216.0000\n",
      "Epoch 1042/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7404091392.0000 - val_loss: 7500984320.0000\n",
      "Epoch 1043/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7656205312.0000 - val_loss: 7810354688.0000\n",
      "Epoch 1044/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7404251648.0000 - val_loss: 7554696704.0000\n",
      "Epoch 1045/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7438835200.0000 - val_loss: 7549000192.0000\n",
      "Epoch 1046/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7572311552.0000 - val_loss: 8151475712.0000\n",
      "Epoch 1047/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7830811648.0000 - val_loss: 7868055040.0000\n",
      "Epoch 1048/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7464879616.0000 - val_loss: 9250888704.0000\n",
      "Epoch 1049/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7361182208.0000 - val_loss: 7346618368.0000\n",
      "Epoch 1050/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8245305344.0000 - val_loss: 8070952448.0000\n",
      "Epoch 1051/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7346196480.0000 - val_loss: 7625087488.0000\n",
      "Epoch 1052/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7231792128.0000 - val_loss: 7400583680.0000\n",
      "Epoch 1053/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7485889536.0000 - val_loss: 7482759168.0000\n",
      "Epoch 1054/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7300280320.0000 - val_loss: 7567057408.0000\n",
      "Epoch 1055/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7218894848.0000 - val_loss: 7583686656.0000\n",
      "Epoch 1056/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7385458176.0000 - val_loss: 9242807296.0000\n",
      "Epoch 1057/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7347049984.0000 - val_loss: 7925949952.0000\n",
      "Epoch 1058/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7289062400.0000 - val_loss: 8271552000.0000\n",
      "Epoch 1059/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7610777600.0000 - val_loss: 7671008256.0000\n",
      "Epoch 1060/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7381679104.0000 - val_loss: 7676178944.0000\n",
      "Epoch 1061/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8009607168.0000 - val_loss: 7482473984.0000\n",
      "Epoch 1062/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7449828864.0000 - val_loss: 7416259584.0000\n",
      "Epoch 1063/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7320453632.0000 - val_loss: 8581761024.0000\n",
      "Epoch 1064/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7613264896.0000 - val_loss: 7404177920.0000\n",
      "Epoch 1065/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7205576704.0000 - val_loss: 7407903744.0000\n",
      "Epoch 1066/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7586021376.0000 - val_loss: 7632231936.0000\n",
      "Epoch 1067/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7915318784.0000 - val_loss: 7451235328.0000\n",
      "Epoch 1068/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7311840256.0000 - val_loss: 7375201280.0000\n",
      "Epoch 1069/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7328705024.0000 - val_loss: 7338927104.0000\n",
      "Epoch 1070/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7289705984.0000 - val_loss: 9182276608.0000\n",
      "Epoch 1071/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7739108352.0000 - val_loss: 7522312192.0000\n",
      "Epoch 1072/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7339623424.0000 - val_loss: 8589831680.0000\n",
      "Epoch 1073/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7599510528.0000 - val_loss: 9468615680.0000\n",
      "Epoch 1074/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7616114176.0000 - val_loss: 9045037056.0000\n",
      "Epoch 1075/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7462703616.0000 - val_loss: 7481269760.0000\n",
      "Epoch 1076/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7238653440.0000 - val_loss: 7747718656.0000\n",
      "Epoch 1077/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7516794368.0000 - val_loss: 7472796160.0000\n",
      "Epoch 1078/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7746751488.0000 - val_loss: 7822571008.0000\n",
      "Epoch 1079/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7335891456.0000 - val_loss: 8022683648.0000\n",
      "Epoch 1080/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7558563840.0000 - val_loss: 7470145024.0000\n",
      "Epoch 1081/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7588411904.0000 - val_loss: 7566188032.0000\n",
      "Epoch 1082/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7333190656.0000 - val_loss: 7461463040.0000\n",
      "Epoch 1083/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7192676352.0000 - val_loss: 7416311296.0000\n",
      "Epoch 1084/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7242095104.0000 - val_loss: 7339831808.0000\n",
      "Epoch 1085/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7205356032.0000 - val_loss: 7319740928.0000\n",
      "Epoch 1086/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7444729344.0000 - val_loss: 7338972672.0000\n",
      "Epoch 1087/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7196373504.0000 - val_loss: 7520432128.0000\n",
      "Epoch 1088/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7234086912.0000 - val_loss: 7348671488.0000\n",
      "Epoch 1089/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7277175296.0000 - val_loss: 8005782016.0000\n",
      "Epoch 1090/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7717916160.0000 - val_loss: 7904095232.0000\n",
      "Epoch 1091/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7593840640.0000 - val_loss: 9038080000.0000\n",
      "Epoch 1092/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7656221184.0000 - val_loss: 7442332160.0000\n",
      "Epoch 1093/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7204572672.0000 - val_loss: 8012695040.0000\n",
      "Epoch 1094/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7274252800.0000 - val_loss: 7769846272.0000\n",
      "Epoch 1095/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7335345152.0000 - val_loss: 7441508864.0000\n",
      "Epoch 1096/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7455754752.0000 - val_loss: 8795674624.0000\n",
      "Epoch 1097/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7409828352.0000 - val_loss: 8169476608.0000\n",
      "Epoch 1098/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7489608192.0000 - val_loss: 7335484928.0000\n",
      "Epoch 1099/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7493747712.0000 - val_loss: 8352465408.0000\n",
      "Epoch 1100/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7407309824.0000 - val_loss: 7389267456.0000\n",
      "Epoch 1101/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8352848896.0000 - val_loss: 7509700608.0000\n",
      "Epoch 1102/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7279520768.0000 - val_loss: 7469107200.0000\n",
      "Epoch 1103/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7420465152.0000 - val_loss: 8248964608.0000\n",
      "Epoch 1104/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7373273088.0000 - val_loss: 7374534656.0000\n",
      "Epoch 1105/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7233130496.0000 - val_loss: 9273702400.0000\n",
      "Epoch 1106/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7246265344.0000 - val_loss: 7757651968.0000\n",
      "Epoch 1107/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7504469504.0000 - val_loss: 10421792768.0000\n",
      "Epoch 1108/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7448018432.0000 - val_loss: 7450577408.0000\n",
      "Epoch 1109/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278523904.0000 - val_loss: 8653863936.0000\n",
      "Epoch 1110/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7443275776.0000 - val_loss: 8293576192.0000\n",
      "Epoch 1111/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7544026112.0000 - val_loss: 7403185664.0000\n",
      "Epoch 1112/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7331780096.0000 - val_loss: 7812075520.0000\n",
      "Epoch 1113/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7731674112.0000 - val_loss: 8905775104.0000\n",
      "Epoch 1114/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7604804096.0000 - val_loss: 7546070528.0000\n",
      "Epoch 1115/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7366866432.0000 - val_loss: 8194949632.0000\n",
      "Epoch 1116/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7418178560.0000 - val_loss: 7662057472.0000\n",
      "Epoch 1117/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7314850304.0000 - val_loss: 7566845440.0000\n",
      "Epoch 1118/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7397946368.0000 - val_loss: 7394027520.0000\n",
      "Epoch 1119/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7261836288.0000 - val_loss: 7575490048.0000\n",
      "Epoch 1120/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7579678208.0000 - val_loss: 7359577088.0000\n",
      "Epoch 1121/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7623250432.0000 - val_loss: 7678752768.0000\n",
      "Epoch 1122/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7525890560.0000 - val_loss: 7968246784.0000\n",
      "Epoch 1123/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7556542464.0000 - val_loss: 7326385152.0000\n",
      "Epoch 1124/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7297444864.0000 - val_loss: 7648436224.0000\n",
      "Epoch 1125/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7186998784.0000 - val_loss: 7734385152.0000\n",
      "Epoch 1126/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7398406656.0000 - val_loss: 7383054336.0000\n",
      "Epoch 1127/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7453877248.0000 - val_loss: 7585809408.0000\n",
      "Epoch 1128/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7496598528.0000 - val_loss: 8236891136.0000\n",
      "Epoch 1129/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7301933568.0000 - val_loss: 7438048256.0000\n",
      "Epoch 1130/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7392302592.0000 - val_loss: 7924846592.0000\n",
      "Epoch 1131/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7322301952.0000 - val_loss: 7365647360.0000\n",
      "Epoch 1132/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7227048448.0000 - val_loss: 7535726080.0000\n",
      "Epoch 1133/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7332176896.0000 - val_loss: 7634016256.0000\n",
      "Epoch 1134/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7624978944.0000 - val_loss: 7374359040.0000\n",
      "Epoch 1135/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7387613184.0000 - val_loss: 7600137216.0000\n",
      "Epoch 1136/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131884544.0000 - val_loss: 8020954624.0000\n",
      "Epoch 1137/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7499021824.0000 - val_loss: 7465859072.0000\n",
      "Epoch 1138/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7641432576.0000 - val_loss: 7884724736.0000\n",
      "Epoch 1139/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7594954240.0000 - val_loss: 7403516416.0000\n",
      "Epoch 1140/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7338673664.0000 - val_loss: 7454037504.0000\n",
      "Epoch 1141/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157221888.0000 - val_loss: 7807249920.0000\n",
      "Epoch 1142/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7243839488.0000 - val_loss: 7279512576.0000\n",
      "Epoch 1143/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7289155072.0000 - val_loss: 7941170688.0000\n",
      "Epoch 1144/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7329689088.0000 - val_loss: 7422527488.0000\n",
      "Epoch 1145/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7329686528.0000 - val_loss: 9080456192.0000\n",
      "Epoch 1146/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7303223296.0000 - val_loss: 7449007616.0000\n",
      "Epoch 1147/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7404011008.0000 - val_loss: 7624043520.0000\n",
      "Epoch 1148/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7442885632.0000 - val_loss: 9361790976.0000\n",
      "Epoch 1149/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7485525504.0000 - val_loss: 7445575168.0000\n",
      "Epoch 1150/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7296563712.0000 - val_loss: 7448139776.0000\n",
      "Epoch 1151/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7425417216.0000 - val_loss: 7607736320.0000\n",
      "Epoch 1152/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7456363520.0000 - val_loss: 7614836736.0000\n",
      "Epoch 1153/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7566934016.0000 - val_loss: 7480184832.0000\n",
      "Epoch 1154/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7691503104.0000 - val_loss: 7485152256.0000\n",
      "Epoch 1155/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7399277056.0000 - val_loss: 7572178432.0000\n",
      "Epoch 1156/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7345830912.0000 - val_loss: 8085964288.0000\n",
      "Epoch 1157/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7549628928.0000 - val_loss: 7913067008.0000\n",
      "Epoch 1158/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7505250304.0000 - val_loss: 7617382912.0000\n",
      "Epoch 1159/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7354574336.0000 - val_loss: 7333007872.0000\n",
      "Epoch 1160/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7424641024.0000 - val_loss: 7787791360.0000\n",
      "Epoch 1161/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7253603328.0000 - val_loss: 7449307648.0000\n",
      "Epoch 1162/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7620461056.0000 - val_loss: 7654968832.0000\n",
      "Epoch 1163/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7419349504.0000 - val_loss: 8321598976.0000\n",
      "Epoch 1164/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7695619584.0000 - val_loss: 8176573952.0000\n",
      "Epoch 1165/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7530609664.0000 - val_loss: 7775163904.0000\n",
      "Epoch 1166/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7422245888.0000 - val_loss: 7729282048.0000\n",
      "Epoch 1167/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7504795648.0000 - val_loss: 7699557376.0000\n",
      "Epoch 1168/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7158523904.0000 - val_loss: 7479620608.0000\n",
      "Epoch 1169/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7471348736.0000 - val_loss: 7418585088.0000\n",
      "Epoch 1170/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7249763840.0000 - val_loss: 7340044288.0000\n",
      "Epoch 1171/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7299517952.0000 - val_loss: 8030553088.0000\n",
      "Epoch 1172/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7240464384.0000 - val_loss: 7350642688.0000\n",
      "Epoch 1173/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147172352.0000 - val_loss: 7364638208.0000\n",
      "Epoch 1174/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8308681728.0000 - val_loss: 7584404992.0000\n",
      "Epoch 1175/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7376631808.0000 - val_loss: 8843940864.0000\n",
      "Epoch 1176/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7430027264.0000 - val_loss: 7391990784.0000\n",
      "Epoch 1177/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7752749568.0000 - val_loss: 9199965184.0000\n",
      "Epoch 1178/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7245788160.0000 - val_loss: 7542970368.0000\n",
      "Epoch 1179/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7227156992.0000 - val_loss: 7487377920.0000\n",
      "Epoch 1180/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7276681216.0000 - val_loss: 7334019072.0000\n",
      "Epoch 1181/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7366815744.0000 - val_loss: 7435962880.0000\n",
      "Epoch 1182/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7259311104.0000 - val_loss: 7443928064.0000\n",
      "Epoch 1183/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7827452416.0000 - val_loss: 8154981376.0000\n",
      "Epoch 1184/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7208886784.0000 - val_loss: 7331803648.0000\n",
      "Epoch 1185/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7268285440.0000 - val_loss: 7946647552.0000\n",
      "Epoch 1186/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7364846592.0000 - val_loss: 8016093696.0000\n",
      "Epoch 1187/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7495650304.0000 - val_loss: 7654334976.0000\n",
      "Epoch 1188/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7390097408.0000 - val_loss: 7433977344.0000\n",
      "Epoch 1189/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7553616384.0000 - val_loss: 7786940416.0000\n",
      "Epoch 1190/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7387104768.0000 - val_loss: 7356172288.0000\n",
      "Epoch 1191/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7491162112.0000 - val_loss: 7616297472.0000\n",
      "Epoch 1192/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7299656704.0000 - val_loss: 7597866496.0000\n",
      "Epoch 1193/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7335403008.0000 - val_loss: 7422542848.0000\n",
      "Epoch 1194/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147826688.0000 - val_loss: 7331672064.0000\n",
      "Epoch 1195/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7395168256.0000 - val_loss: 8065961984.0000\n",
      "Epoch 1196/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7537540096.0000 - val_loss: 7471205888.0000\n",
      "Epoch 1197/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7210973184.0000 - val_loss: 7350806016.0000\n",
      "Epoch 1198/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7168112128.0000 - val_loss: 7738249216.0000\n",
      "Epoch 1199/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7437849088.0000 - val_loss: 7423853568.0000\n",
      "Epoch 1200/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7651621888.0000 - val_loss: 8861241344.0000\n",
      "Epoch 1201/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7396762112.0000 - val_loss: 7331712512.0000\n",
      "Epoch 1202/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7397922304.0000 - val_loss: 7403306496.0000\n",
      "Epoch 1203/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7388044800.0000 - val_loss: 7908543488.0000\n",
      "Epoch 1204/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7321981952.0000 - val_loss: 7390261760.0000\n",
      "Epoch 1205/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7239271424.0000 - val_loss: 7406058496.0000\n",
      "Epoch 1206/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7157252096.0000 - val_loss: 7344851968.0000\n",
      "Epoch 1207/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7418649088.0000 - val_loss: 7446439936.0000\n",
      "Epoch 1208/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7157276160.0000 - val_loss: 7930204160.0000\n",
      "Epoch 1209/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7824425472.0000 - val_loss: 8486510592.0000\n",
      "Epoch 1210/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7299647488.0000 - val_loss: 7836315648.0000\n",
      "Epoch 1211/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7269954560.0000 - val_loss: 9822167040.0000\n",
      "Epoch 1212/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7648926720.0000 - val_loss: 8867602432.0000\n",
      "Epoch 1213/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7320801792.0000 - val_loss: 7499422720.0000\n",
      "Epoch 1214/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7798277632.0000 - val_loss: 8641092608.0000\n",
      "Epoch 1215/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7863015936.0000 - val_loss: 8840624128.0000\n",
      "Epoch 1216/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7175087104.0000 - val_loss: 7366915072.0000\n",
      "Epoch 1217/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7308270592.0000 - val_loss: 7586954240.0000\n",
      "Epoch 1218/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7683213824.0000 - val_loss: 8438582784.0000\n",
      "Epoch 1219/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7187767808.0000 - val_loss: 7850292224.0000\n",
      "Epoch 1220/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7260490752.0000 - val_loss: 7670576128.0000\n",
      "Epoch 1221/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7312587776.0000 - val_loss: 7517690368.0000\n",
      "Epoch 1222/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7343042048.0000 - val_loss: 7436044288.0000\n",
      "Epoch 1223/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7080694784.0000 - val_loss: 7279024640.0000\n",
      "Epoch 1224/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7475013632.0000 - val_loss: 7436165632.0000\n",
      "Epoch 1225/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7268401152.0000 - val_loss: 7647428096.0000\n",
      "Epoch 1226/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7487554560.0000 - val_loss: 8291531264.0000\n",
      "Epoch 1227/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7746652160.0000 - val_loss: 8177356800.0000\n",
      "Epoch 1228/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7346144768.0000 - val_loss: 7821761024.0000\n",
      "Epoch 1229/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7566816256.0000 - val_loss: 7402982400.0000\n",
      "Epoch 1230/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7154101760.0000 - val_loss: 7957858304.0000\n",
      "Epoch 1231/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7284560384.0000 - val_loss: 7376265728.0000\n",
      "Epoch 1232/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7510688256.0000 - val_loss: 7917578240.0000\n",
      "Epoch 1233/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7506589184.0000 - val_loss: 7805664256.0000\n",
      "Epoch 1234/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7506001920.0000 - val_loss: 7813699072.0000\n",
      "Epoch 1235/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7315843072.0000 - val_loss: 7309303296.0000\n",
      "Epoch 1236/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7353348096.0000 - val_loss: 7389099520.0000\n",
      "Epoch 1237/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7495789568.0000 - val_loss: 8036948992.0000\n",
      "Epoch 1238/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7669122560.0000 - val_loss: 10508041216.0000\n",
      "Epoch 1239/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7471303168.0000 - val_loss: 7612751360.0000\n",
      "Epoch 1240/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7342791168.0000 - val_loss: 7672444416.0000\n",
      "Epoch 1241/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7217176576.0000 - val_loss: 8698769408.0000\n",
      "Epoch 1242/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7284084224.0000 - val_loss: 7459212800.0000\n",
      "Epoch 1243/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7233180672.0000 - val_loss: 7303802880.0000\n",
      "Epoch 1244/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7215092224.0000 - val_loss: 7282988544.0000\n",
      "Epoch 1245/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7269441536.0000 - val_loss: 7859643904.0000\n",
      "Epoch 1246/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7472139776.0000 - val_loss: 8276831744.0000\n",
      "Epoch 1247/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7427372544.0000 - val_loss: 7391085568.0000\n",
      "Epoch 1248/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7451552256.0000 - val_loss: 7830222848.0000\n",
      "Epoch 1249/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7437308928.0000 - val_loss: 8028550656.0000\n",
      "Epoch 1250/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7273921536.0000 - val_loss: 8130544640.0000\n",
      "Epoch 1251/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278442496.0000 - val_loss: 7345861632.0000\n",
      "Epoch 1252/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7495488000.0000 - val_loss: 7508115968.0000\n",
      "Epoch 1253/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7359874560.0000 - val_loss: 8040236544.0000\n",
      "Epoch 1254/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7186294272.0000 - val_loss: 7775444480.0000\n",
      "Epoch 1255/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7402437632.0000 - val_loss: 8276261376.0000\n",
      "Epoch 1256/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7497936896.0000 - val_loss: 7316242944.0000\n",
      "Epoch 1257/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7294228992.0000 - val_loss: 9402115072.0000\n",
      "Epoch 1258/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7192940544.0000 - val_loss: 7335894528.0000\n",
      "Epoch 1259/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207109632.0000 - val_loss: 7882019840.0000\n",
      "Epoch 1260/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7607077888.0000 - val_loss: 7690384896.0000\n",
      "Epoch 1261/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7251304448.0000 - val_loss: 7976183296.0000\n",
      "Epoch 1262/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7386748928.0000 - val_loss: 8156681728.0000\n",
      "Epoch 1263/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7256761344.0000 - val_loss: 7335377920.0000\n",
      "Epoch 1264/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7282090496.0000 - val_loss: 8103539712.0000\n",
      "Epoch 1265/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7467698688.0000 - val_loss: 8102296064.0000\n",
      "Epoch 1266/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7200007680.0000 - val_loss: 7725039104.0000\n",
      "Epoch 1267/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7380063744.0000 - val_loss: 7482990080.0000\n",
      "Epoch 1268/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7350777856.0000 - val_loss: 7305103872.0000\n",
      "Epoch 1269/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7799946752.0000 - val_loss: 11102048256.0000\n",
      "Epoch 1270/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7617441792.0000 - val_loss: 7321597440.0000\n",
      "Epoch 1271/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7246767616.0000 - val_loss: 7442937856.0000\n",
      "Epoch 1272/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7746278912.0000 - val_loss: 9850641408.0000\n",
      "Epoch 1273/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7930886656.0000 - val_loss: 7997668352.0000\n",
      "Epoch 1274/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7175867392.0000 - val_loss: 7325693440.0000\n",
      "Epoch 1275/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7304161792.0000 - val_loss: 7454980608.0000\n",
      "Epoch 1276/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7188396544.0000 - val_loss: 7362532352.0000\n",
      "Epoch 1277/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7274878464.0000 - val_loss: 9777975296.0000\n",
      "Epoch 1278/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7732096512.0000 - val_loss: 7299231744.0000\n",
      "Epoch 1279/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7279597056.0000 - val_loss: 7467813888.0000\n",
      "Epoch 1280/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7465062400.0000 - val_loss: 7570497536.0000\n",
      "Epoch 1281/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7130054656.0000 - val_loss: 7528634368.0000\n",
      "Epoch 1282/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7155039232.0000 - val_loss: 7429752832.0000\n",
      "Epoch 1283/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7572567552.0000 - val_loss: 7788590592.0000\n",
      "Epoch 1284/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7195843584.0000 - val_loss: 7538550272.0000\n",
      "Epoch 1285/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7189279232.0000 - val_loss: 7473824768.0000\n",
      "Epoch 1286/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7431155712.0000 - val_loss: 11075129344.0000\n",
      "Epoch 1287/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7539273728.0000 - val_loss: 7330275840.0000\n",
      "Epoch 1288/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7274824192.0000 - val_loss: 7309996032.0000\n",
      "Epoch 1289/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7265673216.0000 - val_loss: 7980941824.0000\n",
      "Epoch 1290/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7601208320.0000 - val_loss: 7401342464.0000\n",
      "Epoch 1291/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7150485504.0000 - val_loss: 7251607552.0000\n",
      "Epoch 1292/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7490115584.0000 - val_loss: 7287176192.0000\n",
      "Epoch 1293/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7091552768.0000 - val_loss: 7288370176.0000\n",
      "Epoch 1294/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7647657984.0000 - val_loss: 7704882176.0000\n",
      "Epoch 1295/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7353234432.0000 - val_loss: 8520432640.0000\n",
      "Epoch 1296/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7355457536.0000 - val_loss: 7412996096.0000\n",
      "Epoch 1297/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7326852096.0000 - val_loss: 7572729856.0000\n",
      "Epoch 1298/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7316321792.0000 - val_loss: 7814351360.0000\n",
      "Epoch 1299/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7464137728.0000 - val_loss: 9346674688.0000\n",
      "Epoch 1300/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7221363712.0000 - val_loss: 7858711040.0000\n",
      "Epoch 1301/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7297124864.0000 - val_loss: 8205426176.0000\n",
      "Epoch 1302/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7140912128.0000 - val_loss: 10006384640.0000\n",
      "Epoch 1303/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7461211648.0000 - val_loss: 7328236032.0000\n",
      "Epoch 1304/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7303951360.0000 - val_loss: 7513323008.0000\n",
      "Epoch 1305/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7527629824.0000 - val_loss: 8035381760.0000\n",
      "Epoch 1306/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7231747584.0000 - val_loss: 8780193792.0000\n",
      "Epoch 1307/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7515607040.0000 - val_loss: 7348971520.0000\n",
      "Epoch 1308/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7300783104.0000 - val_loss: 7298547712.0000\n",
      "Epoch 1309/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7240355328.0000 - val_loss: 7437899264.0000\n",
      "Epoch 1310/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7265756672.0000 - val_loss: 11391764480.0000\n",
      "Epoch 1311/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7643918336.0000 - val_loss: 7904173056.0000\n",
      "Epoch 1312/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7509547008.0000 - val_loss: 7363503104.0000\n",
      "Epoch 1313/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7352306688.0000 - val_loss: 7734321152.0000\n",
      "Epoch 1314/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7414900224.0000 - val_loss: 7547055616.0000\n",
      "Epoch 1315/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7104239616.0000 - val_loss: 8267759616.0000\n",
      "Epoch 1316/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7289797632.0000 - val_loss: 7931321856.0000\n",
      "Epoch 1317/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7144902144.0000 - val_loss: 7261947392.0000\n",
      "Epoch 1318/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7372375040.0000 - val_loss: 7794551808.0000\n",
      "Epoch 1319/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7180858880.0000 - val_loss: 7674400256.0000\n",
      "Epoch 1320/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7320200192.0000 - val_loss: 8274502656.0000\n",
      "Epoch 1321/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7248954880.0000 - val_loss: 8611998720.0000\n",
      "Epoch 1322/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7466191872.0000 - val_loss: 7844733952.0000\n",
      "Epoch 1323/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7445462016.0000 - val_loss: 8006176768.0000\n",
      "Epoch 1324/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7333073920.0000 - val_loss: 7297636352.0000\n",
      "Epoch 1325/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7256677888.0000 - val_loss: 7456199680.0000\n",
      "Epoch 1326/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7252140032.0000 - val_loss: 7426438144.0000\n",
      "Epoch 1327/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7447790592.0000 - val_loss: 8996568064.0000\n",
      "Epoch 1328/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7630290432.0000 - val_loss: 7315207168.0000\n",
      "Epoch 1329/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7107312128.0000 - val_loss: 7324920832.0000\n",
      "Epoch 1330/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7231640576.0000 - val_loss: 7422816768.0000\n",
      "Epoch 1331/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7270690816.0000 - val_loss: 7537561600.0000\n",
      "Epoch 1332/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7121529344.0000 - val_loss: 7420982272.0000\n",
      "Epoch 1333/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7215903744.0000 - val_loss: 7483287552.0000\n",
      "Epoch 1334/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7316060160.0000 - val_loss: 12088823808.0000\n",
      "Epoch 1335/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7480300032.0000 - val_loss: 7435036672.0000\n",
      "Epoch 1336/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7497503744.0000 - val_loss: 7864297984.0000\n",
      "Epoch 1337/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7415500800.0000 - val_loss: 7902487552.0000\n",
      "Epoch 1338/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7145312768.0000 - val_loss: 7359480320.0000\n",
      "Epoch 1339/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7236981760.0000 - val_loss: 8314441728.0000\n",
      "Epoch 1340/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7414376960.0000 - val_loss: 7365175808.0000\n",
      "Epoch 1341/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7429150720.0000 - val_loss: 7685181440.0000\n",
      "Epoch 1342/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7543787520.0000 - val_loss: 7402246656.0000\n",
      "Epoch 1343/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7375235584.0000 - val_loss: 7681846272.0000\n",
      "Epoch 1344/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7492770304.0000 - val_loss: 7541225472.0000\n",
      "Epoch 1345/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7483670528.0000 - val_loss: 7435517952.0000\n",
      "Epoch 1346/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7368397312.0000 - val_loss: 7593771520.0000\n",
      "Epoch 1347/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7740109824.0000 - val_loss: 7588239872.0000\n",
      "Epoch 1348/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7418063360.0000 - val_loss: 7338373120.0000\n",
      "Epoch 1349/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7558790144.0000 - val_loss: 7482557440.0000\n",
      "Epoch 1350/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7177558016.0000 - val_loss: 7614988800.0000\n",
      "Epoch 1351/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8037001216.0000 - val_loss: 7452914176.0000\n",
      "Epoch 1352/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7131006976.0000 - val_loss: 7946632192.0000\n",
      "Epoch 1353/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7178581504.0000 - val_loss: 7788425216.0000\n",
      "Epoch 1354/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7395543552.0000 - val_loss: 7617633280.0000\n",
      "Epoch 1355/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7751229952.0000 - val_loss: 7864503296.0000\n",
      "Epoch 1356/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7702503936.0000 - val_loss: 7315448320.0000\n",
      "Epoch 1357/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7311778816.0000 - val_loss: 7979428864.0000\n",
      "Epoch 1358/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7400379904.0000 - val_loss: 7781551104.0000\n",
      "Epoch 1359/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7342132736.0000 - val_loss: 7850449920.0000\n",
      "Epoch 1360/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7286598144.0000 - val_loss: 7450929664.0000\n",
      "Epoch 1361/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7299012608.0000 - val_loss: 7439315968.0000\n",
      "Epoch 1362/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7159342080.0000 - val_loss: 7648158720.0000\n",
      "Epoch 1363/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7072809472.0000 - val_loss: 7830766080.0000\n",
      "Epoch 1364/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7249414144.0000 - val_loss: 7532379136.0000\n",
      "Epoch 1365/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7185732096.0000 - val_loss: 7294629888.0000\n",
      "Epoch 1366/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7262307840.0000 - val_loss: 7566993920.0000\n",
      "Epoch 1367/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7691298816.0000 - val_loss: 7414574080.0000\n",
      "Epoch 1368/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7333864448.0000 - val_loss: 9087744000.0000\n",
      "Epoch 1369/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7108118016.0000 - val_loss: 7815803392.0000\n",
      "Epoch 1370/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7283477504.0000 - val_loss: 7342796288.0000\n",
      "Epoch 1371/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7137884160.0000 - val_loss: 7459321856.0000\n",
      "Epoch 1372/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7257956352.0000 - val_loss: 8126938624.0000\n",
      "Epoch 1373/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7471751168.0000 - val_loss: 7522701312.0000\n",
      "Epoch 1374/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7269005824.0000 - val_loss: 7794592256.0000\n",
      "Epoch 1375/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7145691136.0000 - val_loss: 7553704960.0000\n",
      "Epoch 1376/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7235819520.0000 - val_loss: 8412142080.0000\n",
      "Epoch 1377/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7604781568.0000 - val_loss: 7383945728.0000\n",
      "Epoch 1378/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7316151808.0000 - val_loss: 7903106048.0000\n",
      "Epoch 1379/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7229116416.0000 - val_loss: 8735353856.0000\n",
      "Epoch 1380/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7515789312.0000 - val_loss: 7337880064.0000\n",
      "Epoch 1381/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7434070016.0000 - val_loss: 9096417280.0000\n",
      "Epoch 1382/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7120858624.0000 - val_loss: 7474066432.0000\n",
      "Epoch 1383/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7418491392.0000 - val_loss: 7874917376.0000\n",
      "Epoch 1384/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7429019648.0000 - val_loss: 7362028544.0000\n",
      "Epoch 1385/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7187127808.0000 - val_loss: 7760536576.0000\n",
      "Epoch 1386/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7355322880.0000 - val_loss: 9751975936.0000\n",
      "Epoch 1387/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7319095296.0000 - val_loss: 7387443200.0000\n",
      "Epoch 1388/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7432740864.0000 - val_loss: 8255824896.0000\n",
      "Epoch 1389/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7061437952.0000 - val_loss: 7973156864.0000\n",
      "Epoch 1390/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7302528000.0000 - val_loss: 8210933248.0000\n",
      "Epoch 1391/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7226074624.0000 - val_loss: 8029588480.0000\n",
      "Epoch 1392/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7353586176.0000 - val_loss: 7606217728.0000\n",
      "Epoch 1393/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7467549184.0000 - val_loss: 7508960256.0000\n",
      "Epoch 1394/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7270238208.0000 - val_loss: 7317230592.0000\n",
      "Epoch 1395/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7376256000.0000 - val_loss: 7816351232.0000\n",
      "Epoch 1396/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7192720384.0000 - val_loss: 7552367104.0000\n",
      "Epoch 1397/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7336271360.0000 - val_loss: 7728260608.0000\n",
      "Epoch 1398/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7344743936.0000 - val_loss: 7878368768.0000\n",
      "Epoch 1399/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7244813312.0000 - val_loss: 8608184320.0000\n",
      "Epoch 1400/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7165196800.0000 - val_loss: 7554514432.0000\n",
      "Epoch 1401/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7050465792.0000 - val_loss: 7253373440.0000\n",
      "Epoch 1402/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7058369536.0000 - val_loss: 8069014016.0000\n",
      "Epoch 1403/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7521277952.0000 - val_loss: 7507543552.0000\n",
      "Epoch 1404/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7304455168.0000 - val_loss: 7597106688.0000\n",
      "Epoch 1405/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7371053056.0000 - val_loss: 9009703936.0000\n",
      "Epoch 1406/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7681122816.0000 - val_loss: 7667717120.0000\n",
      "Epoch 1407/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7519099392.0000 - val_loss: 8204101632.0000\n",
      "Epoch 1408/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7191576064.0000 - val_loss: 7944399360.0000\n",
      "Epoch 1409/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7432876032.0000 - val_loss: 7975422976.0000\n",
      "Epoch 1410/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7117648896.0000 - val_loss: 8177889280.0000\n",
      "Epoch 1411/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7425141248.0000 - val_loss: 8527414784.0000\n",
      "Epoch 1412/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7587100672.0000 - val_loss: 7269147648.0000\n",
      "Epoch 1413/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7535127040.0000 - val_loss: 7809288192.0000\n",
      "Epoch 1414/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7327435264.0000 - val_loss: 7785165824.0000\n",
      "Epoch 1415/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7573344768.0000 - val_loss: 7412199424.0000\n",
      "Epoch 1416/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128289792.0000 - val_loss: 7918113280.0000\n",
      "Epoch 1417/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7244997632.0000 - val_loss: 7216909824.0000\n",
      "Epoch 1418/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7206537728.0000 - val_loss: 7286499328.0000\n",
      "Epoch 1419/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7559019520.0000 - val_loss: 7270084608.0000\n",
      "Epoch 1420/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7340916736.0000 - val_loss: 7447316992.0000\n",
      "Epoch 1421/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7915994112.0000 - val_loss: 7278241280.0000\n",
      "Epoch 1422/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7182895616.0000 - val_loss: 7297779200.0000\n",
      "Epoch 1423/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7234618880.0000 - val_loss: 7572721152.0000\n",
      "Epoch 1424/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7344400896.0000 - val_loss: 9706791936.0000\n",
      "Epoch 1425/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7443088384.0000 - val_loss: 7516900352.0000\n",
      "Epoch 1426/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7513466368.0000 - val_loss: 7495456256.0000\n",
      "Epoch 1427/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7217207296.0000 - val_loss: 7276860416.0000\n",
      "Epoch 1428/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7375753728.0000 - val_loss: 7542643712.0000\n",
      "Epoch 1429/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7176500736.0000 - val_loss: 7923886592.0000\n",
      "Epoch 1430/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7513811968.0000 - val_loss: 7503498240.0000\n",
      "Epoch 1431/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7322755584.0000 - val_loss: 7520949248.0000\n",
      "Epoch 1432/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7632681984.0000 - val_loss: 7844852736.0000\n",
      "Epoch 1433/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7282243072.0000 - val_loss: 7275921408.0000\n",
      "Epoch 1434/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7071008768.0000 - val_loss: 7348414976.0000\n",
      "Epoch 1435/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165528064.0000 - val_loss: 7942776320.0000\n",
      "Epoch 1436/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7469368320.0000 - val_loss: 7356561408.0000\n",
      "Epoch 1437/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7258155520.0000 - val_loss: 8014193152.0000\n",
      "Epoch 1438/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7326959104.0000 - val_loss: 7341287936.0000\n",
      "Epoch 1439/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7146890240.0000 - val_loss: 7275209728.0000\n",
      "Epoch 1440/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7319329280.0000 - val_loss: 7311907328.0000\n",
      "Epoch 1441/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049499136.0000 - val_loss: 7457451008.0000\n",
      "Epoch 1442/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7207507968.0000 - val_loss: 8075959296.0000\n",
      "Epoch 1443/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7054116352.0000 - val_loss: 7782899200.0000\n",
      "Epoch 1444/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7916780544.0000 - val_loss: 7620077568.0000\n",
      "Epoch 1445/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7318440960.0000 - val_loss: 7278986752.0000\n",
      "Epoch 1446/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7606526976.0000 - val_loss: 7341104640.0000\n",
      "Epoch 1447/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7202337792.0000 - val_loss: 7549815296.0000\n",
      "Epoch 1448/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7361692672.0000 - val_loss: 7293540352.0000\n",
      "Epoch 1449/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278789120.0000 - val_loss: 7832734720.0000\n",
      "Epoch 1450/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7232695296.0000 - val_loss: 7436679168.0000\n",
      "Epoch 1451/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7290896896.0000 - val_loss: 7443043328.0000\n",
      "Epoch 1452/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7169886208.0000 - val_loss: 7271605760.0000\n",
      "Epoch 1453/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7141680128.0000 - val_loss: 7508366336.0000\n",
      "Epoch 1454/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7420977664.0000 - val_loss: 7361222144.0000\n",
      "Epoch 1455/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7334931456.0000 - val_loss: 7841844224.0000\n",
      "Epoch 1456/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7871923200.0000 - val_loss: 7303145984.0000\n",
      "Epoch 1457/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7390488576.0000 - val_loss: 7381962240.0000\n",
      "Epoch 1458/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7021800960.0000 - val_loss: 7575608320.0000\n",
      "Epoch 1459/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7013143552.0000 - val_loss: 7265662976.0000\n",
      "Epoch 1460/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7065788928.0000 - val_loss: 7245356032.0000\n",
      "Epoch 1461/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7185337344.0000 - val_loss: 8398065152.0000\n",
      "Epoch 1462/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 8167866368.0000 - val_loss: 8557564416.0000\n",
      "Epoch 1463/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7584015872.0000 - val_loss: 8117905408.0000\n",
      "Epoch 1464/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7130818560.0000 - val_loss: 7569818112.0000\n",
      "Epoch 1465/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7509110784.0000 - val_loss: 9637490688.0000\n",
      "Epoch 1466/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7274001408.0000 - val_loss: 7748076032.0000\n",
      "Epoch 1467/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7654596096.0000 - val_loss: 8387440640.0000\n",
      "Epoch 1468/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7626070016.0000 - val_loss: 7482398208.0000\n",
      "Epoch 1469/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7243933696.0000 - val_loss: 9261484032.0000\n",
      "Epoch 1470/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7365087232.0000 - val_loss: 7330149888.0000\n",
      "Epoch 1471/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7316063232.0000 - val_loss: 8611708928.0000\n",
      "Epoch 1472/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7473580544.0000 - val_loss: 8000342528.0000\n",
      "Epoch 1473/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7309352960.0000 - val_loss: 8140255232.0000\n",
      "Epoch 1474/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7304675840.0000 - val_loss: 7339212800.0000\n",
      "Epoch 1475/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7435191296.0000 - val_loss: 7469776896.0000\n",
      "Epoch 1476/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7397491200.0000 - val_loss: 8045204480.0000\n",
      "Epoch 1477/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7534768640.0000 - val_loss: 7531496448.0000\n",
      "Epoch 1478/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7427500544.0000 - val_loss: 7476803072.0000\n",
      "Epoch 1479/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7152656896.0000 - val_loss: 7387553792.0000\n",
      "Epoch 1480/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7268832256.0000 - val_loss: 7690878464.0000\n",
      "Epoch 1481/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7141827072.0000 - val_loss: 7517661696.0000\n",
      "Epoch 1482/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7521146368.0000 - val_loss: 8013848064.0000\n",
      "Epoch 1483/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138183168.0000 - val_loss: 7239093760.0000\n",
      "Epoch 1484/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7309476864.0000 - val_loss: 7345634816.0000\n",
      "Epoch 1485/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7951134720.0000 - val_loss: 7476424704.0000\n",
      "Epoch 1486/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7006435328.0000 - val_loss: 7400670208.0000\n",
      "Epoch 1487/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7195755008.0000 - val_loss: 7259403776.0000\n",
      "Epoch 1488/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7356271104.0000 - val_loss: 7428270080.0000\n",
      "Epoch 1489/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7224940544.0000 - val_loss: 8433526272.0000\n",
      "Epoch 1490/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7274710528.0000 - val_loss: 7528775680.0000\n",
      "Epoch 1491/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7230284288.0000 - val_loss: 7674152448.0000\n",
      "Epoch 1492/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7543077376.0000 - val_loss: 7267357696.0000\n",
      "Epoch 1493/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7337303040.0000 - val_loss: 7858157056.0000\n",
      "Epoch 1494/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7254612992.0000 - val_loss: 7594892800.0000\n",
      "Epoch 1495/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7294601728.0000 - val_loss: 7456990720.0000\n",
      "Epoch 1496/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7559751680.0000 - val_loss: 7420985856.0000\n",
      "Epoch 1497/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7167595008.0000 - val_loss: 7391257600.0000\n",
      "Epoch 1498/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7363479552.0000 - val_loss: 7591871488.0000\n",
      "Epoch 1499/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7542773248.0000 - val_loss: 7331167744.0000\n",
      "Epoch 1500/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7127366656.0000 - val_loss: 8149459456.0000\n",
      "Epoch 1501/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7161119744.0000 - val_loss: 7276992512.0000\n",
      "Epoch 1502/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 6981118464.0000 - val_loss: 7392294400.0000\n",
      "Epoch 1503/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7182985728.0000 - val_loss: 8634135552.0000\n",
      "Epoch 1504/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7348184064.0000 - val_loss: 7227573760.0000\n",
      "Epoch 1505/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049570816.0000 - val_loss: 7956610048.0000\n",
      "Epoch 1506/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7273437696.0000 - val_loss: 8566062080.0000\n",
      "Epoch 1507/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7224544256.0000 - val_loss: 7538872320.0000\n",
      "Epoch 1508/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7325836800.0000 - val_loss: 7448760832.0000\n",
      "Epoch 1509/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7291189248.0000 - val_loss: 7837270016.0000\n",
      "Epoch 1510/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7210848768.0000 - val_loss: 7429793280.0000\n",
      "Epoch 1511/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7123478016.0000 - val_loss: 7290206208.0000\n",
      "Epoch 1512/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7252781056.0000 - val_loss: 8296721408.0000\n",
      "Epoch 1513/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7065296896.0000 - val_loss: 7251909120.0000\n",
      "Epoch 1514/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7531618816.0000 - val_loss: 7260993024.0000\n",
      "Epoch 1515/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7164336640.0000 - val_loss: 7254269440.0000\n",
      "Epoch 1516/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7127159808.0000 - val_loss: 7381697536.0000\n",
      "Epoch 1517/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7216313856.0000 - val_loss: 7864572928.0000\n",
      "Epoch 1518/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7369516544.0000 - val_loss: 7315063808.0000\n",
      "Epoch 1519/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7133068288.0000 - val_loss: 7379167232.0000\n",
      "Epoch 1520/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7117094400.0000 - val_loss: 7496612352.0000\n",
      "Epoch 1521/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7136398848.0000 - val_loss: 7447940608.0000\n",
      "Epoch 1522/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7220608000.0000 - val_loss: 7616709632.0000\n",
      "Epoch 1523/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7343614976.0000 - val_loss: 8059673600.0000\n",
      "Epoch 1524/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7363304448.0000 - val_loss: 8291592192.0000\n",
      "Epoch 1525/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7115001344.0000 - val_loss: 7604255744.0000\n",
      "Epoch 1526/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7314391040.0000 - val_loss: 7398130688.0000\n",
      "Epoch 1527/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7351602688.0000 - val_loss: 7293740544.0000\n",
      "Epoch 1528/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7214258176.0000 - val_loss: 7292436992.0000\n",
      "Epoch 1529/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7009367552.0000 - val_loss: 7317496832.0000\n",
      "Epoch 1530/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7300249088.0000 - val_loss: 7437030912.0000\n",
      "Epoch 1531/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7396570112.0000 - val_loss: 7332000256.0000\n",
      "Epoch 1532/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7492431872.0000 - val_loss: 7319650816.0000\n",
      "Epoch 1533/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7208364544.0000 - val_loss: 7280783360.0000\n",
      "Epoch 1534/3000\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 7447078912.0000 - val_loss: 7373892096.0000\n",
      "Epoch 1535/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7150892544.0000 - val_loss: 10000198656.0000\n",
      "Epoch 1536/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7759029760.0000 - val_loss: 7612347904.0000\n",
      "Epoch 1537/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7299044864.0000 - val_loss: 7517128192.0000\n",
      "Epoch 1538/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7439193600.0000 - val_loss: 7522788352.0000\n",
      "Epoch 1539/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7272601600.0000 - val_loss: 7331036160.0000\n",
      "Epoch 1540/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7444336128.0000 - val_loss: 7288132096.0000\n",
      "Epoch 1541/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7350449664.0000 - val_loss: 7458165248.0000\n",
      "Epoch 1542/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7253063680.0000 - val_loss: 7295848448.0000\n",
      "Epoch 1543/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7103197696.0000 - val_loss: 7245273088.0000\n",
      "Epoch 1544/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7302387712.0000 - val_loss: 7330617856.0000\n",
      "Epoch 1545/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118733312.0000 - val_loss: 7882054656.0000\n",
      "Epoch 1546/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7495511552.0000 - val_loss: 7825244160.0000\n",
      "Epoch 1547/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7046222336.0000 - val_loss: 7258000384.0000\n",
      "Epoch 1548/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7159473152.0000 - val_loss: 7289412096.0000\n",
      "Epoch 1549/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7059055104.0000 - val_loss: 7439809024.0000\n",
      "Epoch 1550/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207830016.0000 - val_loss: 8432102912.0000\n",
      "Epoch 1551/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7150538752.0000 - val_loss: 8383888384.0000\n",
      "Epoch 1552/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7242908672.0000 - val_loss: 7394547712.0000\n",
      "Epoch 1553/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128392704.0000 - val_loss: 7425031680.0000\n",
      "Epoch 1554/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8041123840.0000 - val_loss: 8028269568.0000\n",
      "Epoch 1555/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7453054976.0000 - val_loss: 7205422592.0000\n",
      "Epoch 1556/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7174082048.0000 - val_loss: 7688492032.0000\n",
      "Epoch 1557/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7259500544.0000 - val_loss: 9355524096.0000\n",
      "Epoch 1558/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165429760.0000 - val_loss: 7394801152.0000\n",
      "Epoch 1559/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7133760512.0000 - val_loss: 8352399360.0000\n",
      "Epoch 1560/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7193631744.0000 - val_loss: 7795476480.0000\n",
      "Epoch 1561/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7002427392.0000 - val_loss: 7374318592.0000\n",
      "Epoch 1562/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7150027776.0000 - val_loss: 7473116672.0000\n",
      "Epoch 1563/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7757289472.0000 - val_loss: 10661893120.0000\n",
      "Epoch 1564/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7269433344.0000 - val_loss: 7259213824.0000\n",
      "Epoch 1565/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7262533120.0000 - val_loss: 7577236992.0000\n",
      "Epoch 1566/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7274090496.0000 - val_loss: 7577814528.0000\n",
      "Epoch 1567/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7091586048.0000 - val_loss: 7721677824.0000\n",
      "Epoch 1568/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7090022400.0000 - val_loss: 7563768320.0000\n",
      "Epoch 1569/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7283046400.0000 - val_loss: 7726808064.0000\n",
      "Epoch 1570/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7480890880.0000 - val_loss: 7483944960.0000\n",
      "Epoch 1571/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7951611904.0000 - val_loss: 7564379648.0000\n",
      "Epoch 1572/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7054566912.0000 - val_loss: 7447744000.0000\n",
      "Epoch 1573/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8870038528.0000 - val_loss: 13082236928.0000\n",
      "Epoch 1574/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 8176367104.0000 - val_loss: 7615411200.0000\n",
      "Epoch 1575/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7123549184.0000 - val_loss: 7446384128.0000\n",
      "Epoch 1576/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7087005696.0000 - val_loss: 7558216192.0000\n",
      "Epoch 1577/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7291379712.0000 - val_loss: 7337007104.0000\n",
      "Epoch 1578/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7170205184.0000 - val_loss: 8392279552.0000\n",
      "Epoch 1579/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7139831808.0000 - val_loss: 7480919552.0000\n",
      "Epoch 1580/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7218072576.0000 - val_loss: 8712689664.0000\n",
      "Epoch 1581/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7455075328.0000 - val_loss: 7395102720.0000\n",
      "Epoch 1582/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7236166144.0000 - val_loss: 8709465088.0000\n",
      "Epoch 1583/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7074416640.0000 - val_loss: 7369794048.0000\n",
      "Epoch 1584/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7134966272.0000 - val_loss: 7364653568.0000\n",
      "Epoch 1585/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7380086784.0000 - val_loss: 7292718592.0000\n",
      "Epoch 1586/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7539856896.0000 - val_loss: 7323027456.0000\n",
      "Epoch 1587/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7330261504.0000 - val_loss: 7262934528.0000\n",
      "Epoch 1588/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7252393984.0000 - val_loss: 7380193280.0000\n",
      "Epoch 1589/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7200559616.0000 - val_loss: 9938350080.0000\n",
      "Epoch 1590/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7301588480.0000 - val_loss: 7412676096.0000\n",
      "Epoch 1591/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7042733568.0000 - val_loss: 7412476416.0000\n",
      "Epoch 1592/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7087468032.0000 - val_loss: 7490902016.0000\n",
      "Epoch 1593/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7619067392.0000 - val_loss: 10127215616.0000\n",
      "Epoch 1594/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7090971136.0000 - val_loss: 7615618048.0000\n",
      "Epoch 1595/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7559855104.0000 - val_loss: 9499937792.0000\n",
      "Epoch 1596/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7503795712.0000 - val_loss: 7255518208.0000\n",
      "Epoch 1597/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7116708864.0000 - val_loss: 7789136896.0000\n",
      "Epoch 1598/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7185482240.0000 - val_loss: 7546706432.0000\n",
      "Epoch 1599/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7359004672.0000 - val_loss: 7271331328.0000\n",
      "Epoch 1600/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7080540160.0000 - val_loss: 11713981440.0000\n",
      "Epoch 1601/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7365030912.0000 - val_loss: 8477628928.0000\n",
      "Epoch 1602/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7385239040.0000 - val_loss: 7252573184.0000\n",
      "Epoch 1603/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7097987584.0000 - val_loss: 7331003904.0000\n",
      "Epoch 1604/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7160347136.0000 - val_loss: 7207747584.0000\n",
      "Epoch 1605/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157529088.0000 - val_loss: 7474693120.0000\n",
      "Epoch 1606/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7402118656.0000 - val_loss: 7322146816.0000\n",
      "Epoch 1607/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7248601088.0000 - val_loss: 8190177792.0000\n",
      "Epoch 1608/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7360506880.0000 - val_loss: 7198437376.0000\n",
      "Epoch 1609/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7072532480.0000 - val_loss: 7223043584.0000\n",
      "Epoch 1610/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7073794560.0000 - val_loss: 7799600128.0000\n",
      "Epoch 1611/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7226766336.0000 - val_loss: 7346694144.0000\n",
      "Epoch 1612/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7148175872.0000 - val_loss: 7532531712.0000\n",
      "Epoch 1613/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7251830272.0000 - val_loss: 7623319552.0000\n",
      "Epoch 1614/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7129058816.0000 - val_loss: 9945071616.0000\n",
      "Epoch 1615/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7763351552.0000 - val_loss: 7237871104.0000\n",
      "Epoch 1616/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7229328384.0000 - val_loss: 7446325248.0000\n",
      "Epoch 1617/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7214344192.0000 - val_loss: 8613033984.0000\n",
      "Epoch 1618/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7178798592.0000 - val_loss: 8759445504.0000\n",
      "Epoch 1619/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147359744.0000 - val_loss: 7241188864.0000\n",
      "Epoch 1620/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7459137024.0000 - val_loss: 8824281088.0000\n",
      "Epoch 1621/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7254284288.0000 - val_loss: 7968830976.0000\n",
      "Epoch 1622/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7247315968.0000 - val_loss: 7228748800.0000\n",
      "Epoch 1623/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138466304.0000 - val_loss: 7544879616.0000\n",
      "Epoch 1624/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7014700544.0000 - val_loss: 7319041536.0000\n",
      "Epoch 1625/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7170872832.0000 - val_loss: 7553182208.0000\n",
      "Epoch 1626/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7194653696.0000 - val_loss: 7685982208.0000\n",
      "Epoch 1627/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207602176.0000 - val_loss: 8529631232.0000\n",
      "Epoch 1628/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7120452096.0000 - val_loss: 7529147392.0000\n",
      "Epoch 1629/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7286012416.0000 - val_loss: 9589219328.0000\n",
      "Epoch 1630/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7314627584.0000 - val_loss: 7416087040.0000\n",
      "Epoch 1631/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7345713664.0000 - val_loss: 7866377728.0000\n",
      "Epoch 1632/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7568618496.0000 - val_loss: 8057525248.0000\n",
      "Epoch 1633/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7413250560.0000 - val_loss: 7360671744.0000\n",
      "Epoch 1634/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7226618880.0000 - val_loss: 7831674368.0000\n",
      "Epoch 1635/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7611791872.0000 - val_loss: 8708830208.0000\n",
      "Epoch 1636/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7178760192.0000 - val_loss: 7200947712.0000\n",
      "Epoch 1637/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023163904.0000 - val_loss: 8102676992.0000\n",
      "Epoch 1638/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7120219136.0000 - val_loss: 7392113152.0000\n",
      "Epoch 1639/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7260839936.0000 - val_loss: 7444630016.0000\n",
      "Epoch 1640/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7281784832.0000 - val_loss: 8085461504.0000\n",
      "Epoch 1641/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118735360.0000 - val_loss: 7388780544.0000\n",
      "Epoch 1642/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7622734336.0000 - val_loss: 8120543744.0000\n",
      "Epoch 1643/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7246697472.0000 - val_loss: 7437568512.0000\n",
      "Epoch 1644/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7352556544.0000 - val_loss: 7981514752.0000\n",
      "Epoch 1645/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7138093568.0000 - val_loss: 7495733760.0000\n",
      "Epoch 1646/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7124647424.0000 - val_loss: 7771204608.0000\n",
      "Epoch 1647/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7419787264.0000 - val_loss: 7722031616.0000\n",
      "Epoch 1648/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7014940160.0000 - val_loss: 7342449152.0000\n",
      "Epoch 1649/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7154108928.0000 - val_loss: 8219852288.0000\n",
      "Epoch 1650/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278912512.0000 - val_loss: 8930967552.0000\n",
      "Epoch 1651/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7235844608.0000 - val_loss: 7439762432.0000\n",
      "Epoch 1652/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7151246336.0000 - val_loss: 7855544832.0000\n",
      "Epoch 1653/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7256437760.0000 - val_loss: 7398190080.0000\n",
      "Epoch 1654/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7217178112.0000 - val_loss: 7223104000.0000\n",
      "Epoch 1655/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7202954752.0000 - val_loss: 7317452800.0000\n",
      "Epoch 1656/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6989479424.0000 - val_loss: 7286918144.0000\n",
      "Epoch 1657/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7070564864.0000 - val_loss: 8090528256.0000\n",
      "Epoch 1658/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7281527808.0000 - val_loss: 7185792000.0000\n",
      "Epoch 1659/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7092196352.0000 - val_loss: 7448925184.0000\n",
      "Epoch 1660/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7239917056.0000 - val_loss: 7680799232.0000\n",
      "Epoch 1661/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069435392.0000 - val_loss: 7607544832.0000\n",
      "Epoch 1662/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7139563520.0000 - val_loss: 7488079360.0000\n",
      "Epoch 1663/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207460864.0000 - val_loss: 7418364416.0000\n",
      "Epoch 1664/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7393082880.0000 - val_loss: 7304225280.0000\n",
      "Epoch 1665/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7425314304.0000 - val_loss: 9229860864.0000\n",
      "Epoch 1666/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7325804032.0000 - val_loss: 7232578560.0000\n",
      "Epoch 1667/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7121201664.0000 - val_loss: 7928448000.0000\n",
      "Epoch 1668/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7163386368.0000 - val_loss: 7729326080.0000\n",
      "Epoch 1669/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7213533696.0000 - val_loss: 7674152448.0000\n",
      "Epoch 1670/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165998592.0000 - val_loss: 8157526016.0000\n",
      "Epoch 1671/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7413557248.0000 - val_loss: 7405751296.0000\n",
      "Epoch 1672/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7274437120.0000 - val_loss: 7406431232.0000\n",
      "Epoch 1673/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162445312.0000 - val_loss: 7662472704.0000\n",
      "Epoch 1674/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7107702784.0000 - val_loss: 8038721536.0000\n",
      "Epoch 1675/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7304326144.0000 - val_loss: 7258162176.0000\n",
      "Epoch 1676/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7073753600.0000 - val_loss: 7863525888.0000\n",
      "Epoch 1677/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152936960.0000 - val_loss: 7253251584.0000\n",
      "Epoch 1678/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7223346176.0000 - val_loss: 7243010560.0000\n",
      "Epoch 1679/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7185318400.0000 - val_loss: 7369251328.0000\n",
      "Epoch 1680/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7095753216.0000 - val_loss: 7289006080.0000\n",
      "Epoch 1681/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7354186240.0000 - val_loss: 8818448384.0000\n",
      "Epoch 1682/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7400224256.0000 - val_loss: 9011096576.0000\n",
      "Epoch 1683/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7069920256.0000 - val_loss: 8133443072.0000\n",
      "Epoch 1684/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7095999488.0000 - val_loss: 7329016320.0000\n",
      "Epoch 1685/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7188305920.0000 - val_loss: 7619608064.0000\n",
      "Epoch 1686/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7085442560.0000 - val_loss: 7251087360.0000\n",
      "Epoch 1687/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7367534080.0000 - val_loss: 7308764160.0000\n",
      "Epoch 1688/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7340331008.0000 - val_loss: 7262842368.0000\n",
      "Epoch 1689/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7335922176.0000 - val_loss: 8107780608.0000\n",
      "Epoch 1690/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7260236800.0000 - val_loss: 7256587776.0000\n",
      "Epoch 1691/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7311202304.0000 - val_loss: 7680044032.0000\n",
      "Epoch 1692/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7267686912.0000 - val_loss: 7732614144.0000\n",
      "Epoch 1693/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7091419136.0000 - val_loss: 7347267072.0000\n",
      "Epoch 1694/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7032107520.0000 - val_loss: 7343664640.0000\n",
      "Epoch 1695/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7113778176.0000 - val_loss: 7340928512.0000\n",
      "Epoch 1696/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7099427840.0000 - val_loss: 8095685632.0000\n",
      "Epoch 1697/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7537358336.0000 - val_loss: 7430948352.0000\n",
      "Epoch 1698/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6988824064.0000 - val_loss: 7211532800.0000\n",
      "Epoch 1699/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6943454208.0000 - val_loss: 7462642176.0000\n",
      "Epoch 1700/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7218947072.0000 - val_loss: 7231086080.0000\n",
      "Epoch 1701/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7425555456.0000 - val_loss: 7401052160.0000\n",
      "Epoch 1702/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7235736064.0000 - val_loss: 7344267264.0000\n",
      "Epoch 1703/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7288331264.0000 - val_loss: 7185782272.0000\n",
      "Epoch 1704/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7237764096.0000 - val_loss: 7718020608.0000\n",
      "Epoch 1705/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7583890944.0000 - val_loss: 7306246144.0000\n",
      "Epoch 1706/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7187912704.0000 - val_loss: 7304269824.0000\n",
      "Epoch 1707/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7107172864.0000 - val_loss: 7413412352.0000\n",
      "Epoch 1708/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7070891008.0000 - val_loss: 7196848128.0000\n",
      "Epoch 1709/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7412557824.0000 - val_loss: 7632829440.0000\n",
      "Epoch 1710/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7246726656.0000 - val_loss: 7378117120.0000\n",
      "Epoch 1711/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7322623488.0000 - val_loss: 9760164864.0000\n",
      "Epoch 1712/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7233255936.0000 - val_loss: 7403243008.0000\n",
      "Epoch 1713/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7593779712.0000 - val_loss: 7381712384.0000\n",
      "Epoch 1714/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7184868352.0000 - val_loss: 7252015616.0000\n",
      "Epoch 1715/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7254578688.0000 - val_loss: 7610379776.0000\n",
      "Epoch 1716/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7296341504.0000 - val_loss: 9441626112.0000\n",
      "Epoch 1717/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7240921600.0000 - val_loss: 7309927424.0000\n",
      "Epoch 1718/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7029366784.0000 - val_loss: 7278239232.0000\n",
      "Epoch 1719/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7054257664.0000 - val_loss: 7998893056.0000\n",
      "Epoch 1720/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7077148160.0000 - val_loss: 7473572352.0000\n",
      "Epoch 1721/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6970848256.0000 - val_loss: 7441958912.0000\n",
      "Epoch 1722/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7081051136.0000 - val_loss: 7265219072.0000\n",
      "Epoch 1723/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7399112704.0000 - val_loss: 7345140736.0000\n",
      "Epoch 1724/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7325186560.0000 - val_loss: 8133645824.0000\n",
      "Epoch 1725/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7171218432.0000 - val_loss: 7267396608.0000\n",
      "Epoch 1726/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7027912192.0000 - val_loss: 7385649664.0000\n",
      "Epoch 1727/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7078929920.0000 - val_loss: 7817912832.0000\n",
      "Epoch 1728/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7087444992.0000 - val_loss: 7342780928.0000\n",
      "Epoch 1729/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7061473792.0000 - val_loss: 7367667200.0000\n",
      "Epoch 1730/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7103293440.0000 - val_loss: 7605560320.0000\n",
      "Epoch 1731/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7322685952.0000 - val_loss: 7345520640.0000\n",
      "Epoch 1732/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7399168000.0000 - val_loss: 8919599104.0000\n",
      "Epoch 1733/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7431514624.0000 - val_loss: 7448340480.0000\n",
      "Epoch 1734/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7105134592.0000 - val_loss: 7595968000.0000\n",
      "Epoch 1735/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7186731008.0000 - val_loss: 8233640960.0000\n",
      "Epoch 1736/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7289208320.0000 - val_loss: 7241602560.0000\n",
      "Epoch 1737/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7024094208.0000 - val_loss: 7926854656.0000\n",
      "Epoch 1738/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7342888960.0000 - val_loss: 7274006016.0000\n",
      "Epoch 1739/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7143148544.0000 - val_loss: 8937554944.0000\n",
      "Epoch 1740/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7289772544.0000 - val_loss: 7326253056.0000\n",
      "Epoch 1741/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7289966592.0000 - val_loss: 9588845568.0000\n",
      "Epoch 1742/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7158080000.0000 - val_loss: 7178905088.0000\n",
      "Epoch 1743/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7303079936.0000 - val_loss: 7668742144.0000\n",
      "Epoch 1744/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7264182272.0000 - val_loss: 7235282944.0000\n",
      "Epoch 1745/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7392221696.0000 - val_loss: 7361834496.0000\n",
      "Epoch 1746/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7514443264.0000 - val_loss: 7290977792.0000\n",
      "Epoch 1747/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7156379648.0000 - val_loss: 7711146496.0000\n",
      "Epoch 1748/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7211982336.0000 - val_loss: 7386696704.0000\n",
      "Epoch 1749/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7344409600.0000 - val_loss: 7191850496.0000\n",
      "Epoch 1750/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7313265152.0000 - val_loss: 7320617984.0000\n",
      "Epoch 1751/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7013843968.0000 - val_loss: 7368678912.0000\n",
      "Epoch 1752/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7132921344.0000 - val_loss: 7864905216.0000\n",
      "Epoch 1753/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7322316288.0000 - val_loss: 7553482752.0000\n",
      "Epoch 1754/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7013795840.0000 - val_loss: 8740609024.0000\n",
      "Epoch 1755/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7327665152.0000 - val_loss: 7269618688.0000\n",
      "Epoch 1756/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7069425664.0000 - val_loss: 7434224128.0000\n",
      "Epoch 1757/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7067815936.0000 - val_loss: 7264462336.0000\n",
      "Epoch 1758/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7018770944.0000 - val_loss: 8534379008.0000\n",
      "Epoch 1759/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7660234240.0000 - val_loss: 7849080320.0000\n",
      "Epoch 1760/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7147652096.0000 - val_loss: 7837857792.0000\n",
      "Epoch 1761/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7317017600.0000 - val_loss: 7266176512.0000\n",
      "Epoch 1762/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7090997248.0000 - val_loss: 7399301120.0000\n",
      "Epoch 1763/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7255522304.0000 - val_loss: 7581847552.0000\n",
      "Epoch 1764/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049558528.0000 - val_loss: 8074953216.0000\n",
      "Epoch 1765/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942161920.0000 - val_loss: 7175710720.0000\n",
      "Epoch 1766/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6948880384.0000 - val_loss: 7285211136.0000\n",
      "Epoch 1767/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7495147008.0000 - val_loss: 7657192960.0000\n",
      "Epoch 1768/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7355692032.0000 - val_loss: 10082927616.0000\n",
      "Epoch 1769/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7255964672.0000 - val_loss: 7297030144.0000\n",
      "Epoch 1770/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157541888.0000 - val_loss: 7193097728.0000\n",
      "Epoch 1771/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7454591488.0000 - val_loss: 8472250368.0000\n",
      "Epoch 1772/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7271360512.0000 - val_loss: 7248095744.0000\n",
      "Epoch 1773/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7088991744.0000 - val_loss: 7345409024.0000\n",
      "Epoch 1774/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7589159936.0000 - val_loss: 7226636800.0000\n",
      "Epoch 1775/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7176076800.0000 - val_loss: 7849388544.0000\n",
      "Epoch 1776/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128807936.0000 - val_loss: 7242188288.0000\n",
      "Epoch 1777/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7112635392.0000 - val_loss: 7239802368.0000\n",
      "Epoch 1778/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7492441088.0000 - val_loss: 7629639680.0000\n",
      "Epoch 1779/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162239488.0000 - val_loss: 7428989440.0000\n",
      "Epoch 1780/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7289262592.0000 - val_loss: 7511789056.0000\n",
      "Epoch 1781/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7236705792.0000 - val_loss: 7575417856.0000\n",
      "Epoch 1782/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7045504000.0000 - val_loss: 7344710656.0000\n",
      "Epoch 1783/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7221922816.0000 - val_loss: 7340844544.0000\n",
      "Epoch 1784/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7532357632.0000 - val_loss: 7591642624.0000\n",
      "Epoch 1785/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7472909312.0000 - val_loss: 7630280192.0000\n",
      "Epoch 1786/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7027224064.0000 - val_loss: 7191449600.0000\n",
      "Epoch 1787/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7224036352.0000 - val_loss: 8093998592.0000\n",
      "Epoch 1788/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157620736.0000 - val_loss: 7642183168.0000\n",
      "Epoch 1789/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7027528704.0000 - val_loss: 8104870912.0000\n",
      "Epoch 1790/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7211731968.0000 - val_loss: 7194846208.0000\n",
      "Epoch 1791/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7085618688.0000 - val_loss: 7773677056.0000\n",
      "Epoch 1792/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7550531584.0000 - val_loss: 7685302272.0000\n",
      "Epoch 1793/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7236086272.0000 - val_loss: 7235463168.0000\n",
      "Epoch 1794/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6986415616.0000 - val_loss: 8297436672.0000\n",
      "Epoch 1795/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7667762176.0000 - val_loss: 7331805696.0000\n",
      "Epoch 1796/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7458344448.0000 - val_loss: 7546604544.0000\n",
      "Epoch 1797/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6952743936.0000 - val_loss: 7490918400.0000\n",
      "Epoch 1798/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7346546176.0000 - val_loss: 8392961024.0000\n",
      "Epoch 1799/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7195072512.0000 - val_loss: 7462726656.0000\n",
      "Epoch 1800/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7220852736.0000 - val_loss: 8355098624.0000\n",
      "Epoch 1801/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7204246528.0000 - val_loss: 8534356480.0000\n",
      "Epoch 1802/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7082941440.0000 - val_loss: 7380577280.0000\n",
      "Epoch 1803/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7145760768.0000 - val_loss: 8472694784.0000\n",
      "Epoch 1804/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7184656384.0000 - val_loss: 7324523008.0000\n",
      "Epoch 1805/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7170706944.0000 - val_loss: 7278528512.0000\n",
      "Epoch 1806/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7053349888.0000 - val_loss: 7920684544.0000\n",
      "Epoch 1807/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7239014912.0000 - val_loss: 7371451904.0000\n",
      "Epoch 1808/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7153242624.0000 - val_loss: 7723795968.0000\n",
      "Epoch 1809/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7044728320.0000 - val_loss: 7611564544.0000\n",
      "Epoch 1810/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7223667200.0000 - val_loss: 7675787264.0000\n",
      "Epoch 1811/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7357576704.0000 - val_loss: 7887631872.0000\n",
      "Epoch 1812/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7145600512.0000 - val_loss: 8525050880.0000\n",
      "Epoch 1813/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7263473152.0000 - val_loss: 8198383104.0000\n",
      "Epoch 1814/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7168418304.0000 - val_loss: 8346894336.0000\n",
      "Epoch 1815/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128565248.0000 - val_loss: 7500589056.0000\n",
      "Epoch 1816/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7802301952.0000 - val_loss: 7277419520.0000\n",
      "Epoch 1817/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7298846720.0000 - val_loss: 7484115456.0000\n",
      "Epoch 1818/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278223360.0000 - val_loss: 7650542592.0000\n",
      "Epoch 1819/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7142587392.0000 - val_loss: 7788860928.0000\n",
      "Epoch 1820/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7038217216.0000 - val_loss: 7964166144.0000\n",
      "Epoch 1821/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118693888.0000 - val_loss: 7561249792.0000\n",
      "Epoch 1822/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7199817216.0000 - val_loss: 7416922624.0000\n",
      "Epoch 1823/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7074826240.0000 - val_loss: 7594027008.0000\n",
      "Epoch 1824/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7456812032.0000 - val_loss: 7692280832.0000\n",
      "Epoch 1825/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7214737920.0000 - val_loss: 7409724928.0000\n",
      "Epoch 1826/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7164424704.0000 - val_loss: 7245857280.0000\n",
      "Epoch 1827/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6965527040.0000 - val_loss: 7288914944.0000\n",
      "Epoch 1828/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7535595520.0000 - val_loss: 8168049664.0000\n",
      "Epoch 1829/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7411613184.0000 - val_loss: 7268164608.0000\n",
      "Epoch 1830/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7262905856.0000 - val_loss: 7211060224.0000\n",
      "Epoch 1831/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7193689088.0000 - val_loss: 8762498048.0000\n",
      "Epoch 1832/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7072110592.0000 - val_loss: 7209916416.0000\n",
      "Epoch 1833/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6943097856.0000 - val_loss: 7559839744.0000\n",
      "Epoch 1834/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023889408.0000 - val_loss: 8383150592.0000\n",
      "Epoch 1835/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7568133120.0000 - val_loss: 7242505216.0000\n",
      "Epoch 1836/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7407683072.0000 - val_loss: 7253383680.0000\n",
      "Epoch 1837/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6972591616.0000 - val_loss: 7182611456.0000\n",
      "Epoch 1838/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7145681408.0000 - val_loss: 8305341952.0000\n",
      "Epoch 1839/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7348909568.0000 - val_loss: 7379713536.0000\n",
      "Epoch 1840/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7128207872.0000 - val_loss: 8480604160.0000\n",
      "Epoch 1841/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7217660928.0000 - val_loss: 7504687616.0000\n",
      "Epoch 1842/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7253129216.0000 - val_loss: 7276832768.0000\n",
      "Epoch 1843/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7324142592.0000 - val_loss: 7539954176.0000\n",
      "Epoch 1844/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7054087168.0000 - val_loss: 7568458240.0000\n",
      "Epoch 1845/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7206989824.0000 - val_loss: 7680893440.0000\n",
      "Epoch 1846/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6989421568.0000 - val_loss: 7480265216.0000\n",
      "Epoch 1847/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6996391424.0000 - val_loss: 7184687104.0000\n",
      "Epoch 1848/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7407086592.0000 - val_loss: 8562360832.0000\n",
      "Epoch 1849/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7700219904.0000 - val_loss: 8925501440.0000\n",
      "Epoch 1850/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7117075968.0000 - val_loss: 7465959936.0000\n",
      "Epoch 1851/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138455040.0000 - val_loss: 7492838912.0000\n",
      "Epoch 1852/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7499000832.0000 - val_loss: 7313290240.0000\n",
      "Epoch 1853/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7077545984.0000 - val_loss: 7292211712.0000\n",
      "Epoch 1854/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7105522176.0000 - val_loss: 7400224256.0000\n",
      "Epoch 1855/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7147961344.0000 - val_loss: 7566518784.0000\n",
      "Epoch 1856/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7016394752.0000 - val_loss: 7416374784.0000\n",
      "Epoch 1857/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7293194240.0000 - val_loss: 7288340992.0000\n",
      "Epoch 1858/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7508404224.0000 - val_loss: 7605126656.0000\n",
      "Epoch 1859/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7349611008.0000 - val_loss: 8447088640.0000\n",
      "Epoch 1860/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7546022400.0000 - val_loss: 7812354048.0000\n",
      "Epoch 1861/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7197904896.0000 - val_loss: 8859285504.0000\n",
      "Epoch 1862/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7431078912.0000 - val_loss: 10238585856.0000\n",
      "Epoch 1863/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7765922304.0000 - val_loss: 7432994816.0000\n",
      "Epoch 1864/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6981927424.0000 - val_loss: 7260987392.0000\n",
      "Epoch 1865/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7258409984.0000 - val_loss: 7942426112.0000\n",
      "Epoch 1866/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7401334784.0000 - val_loss: 9571019776.0000\n",
      "Epoch 1867/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7419858944.0000 - val_loss: 7422915584.0000\n",
      "Epoch 1868/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7031186432.0000 - val_loss: 7529004032.0000\n",
      "Epoch 1869/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7061731840.0000 - val_loss: 7855497216.0000\n",
      "Epoch 1870/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7170895872.0000 - val_loss: 7211232256.0000\n",
      "Epoch 1871/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6963284480.0000 - val_loss: 7189631488.0000\n",
      "Epoch 1872/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7070448640.0000 - val_loss: 7743700480.0000\n",
      "Epoch 1873/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7198867456.0000 - val_loss: 10116342784.0000\n",
      "Epoch 1874/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278907904.0000 - val_loss: 7207938560.0000\n",
      "Epoch 1875/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7210759680.0000 - val_loss: 8150867968.0000\n",
      "Epoch 1876/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7140557824.0000 - val_loss: 7767532032.0000\n",
      "Epoch 1877/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7505096704.0000 - val_loss: 8731198464.0000\n",
      "Epoch 1878/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207929856.0000 - val_loss: 7177890816.0000\n",
      "Epoch 1879/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7120480768.0000 - val_loss: 7811643392.0000\n",
      "Epoch 1880/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7680940544.0000 - val_loss: 7412576256.0000\n",
      "Epoch 1881/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7405446144.0000 - val_loss: 7212501504.0000\n",
      "Epoch 1882/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6927145984.0000 - val_loss: 8258456576.0000\n",
      "Epoch 1883/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7291220480.0000 - val_loss: 7169075200.0000\n",
      "Epoch 1884/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023439872.0000 - val_loss: 10139364352.0000\n",
      "Epoch 1885/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7292826112.0000 - val_loss: 9397207040.0000\n",
      "Epoch 1886/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7192892928.0000 - val_loss: 8204310528.0000\n",
      "Epoch 1887/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7242603520.0000 - val_loss: 8178440704.0000\n",
      "Epoch 1888/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6993520640.0000 - val_loss: 7275365376.0000\n",
      "Epoch 1889/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131784192.0000 - val_loss: 7256762368.0000\n",
      "Epoch 1890/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7219753472.0000 - val_loss: 7499329024.0000\n",
      "Epoch 1891/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7414233088.0000 - val_loss: 7480623104.0000\n",
      "Epoch 1892/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7092286976.0000 - val_loss: 7857900032.0000\n",
      "Epoch 1893/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7114206208.0000 - val_loss: 7695685120.0000\n",
      "Epoch 1894/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138762240.0000 - val_loss: 7285493248.0000\n",
      "Epoch 1895/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7191638016.0000 - val_loss: 11146434560.0000\n",
      "Epoch 1896/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7479341568.0000 - val_loss: 7507116032.0000\n",
      "Epoch 1897/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7177521152.0000 - val_loss: 9125714944.0000\n",
      "Epoch 1898/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7061513216.0000 - val_loss: 7958787584.0000\n",
      "Epoch 1899/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7020989952.0000 - val_loss: 7661953536.0000\n",
      "Epoch 1900/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7032284672.0000 - val_loss: 8447561728.0000\n",
      "Epoch 1901/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7519772160.0000 - val_loss: 11733049344.0000\n",
      "Epoch 1902/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7376371200.0000 - val_loss: 7488334848.0000\n",
      "Epoch 1903/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7643897856.0000 - val_loss: 7268675584.0000\n",
      "Epoch 1904/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7110161920.0000 - val_loss: 9614892032.0000\n",
      "Epoch 1905/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7300588032.0000 - val_loss: 9039566848.0000\n",
      "Epoch 1906/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7030277120.0000 - val_loss: 7295323136.0000\n",
      "Epoch 1907/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7459229184.0000 - val_loss: 8596356096.0000\n",
      "Epoch 1908/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7309031936.0000 - val_loss: 7331579392.0000\n",
      "Epoch 1909/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7222040576.0000 - val_loss: 7641291264.0000\n",
      "Epoch 1910/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7105403392.0000 - val_loss: 7220710400.0000\n",
      "Epoch 1911/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7052086272.0000 - val_loss: 7753931264.0000\n",
      "Epoch 1912/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7267534848.0000 - val_loss: 7791968768.0000\n",
      "Epoch 1913/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7241388032.0000 - val_loss: 7356911104.0000\n",
      "Epoch 1914/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7101673984.0000 - val_loss: 7434861568.0000\n",
      "Epoch 1915/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7604155904.0000 - val_loss: 7258052608.0000\n",
      "Epoch 1916/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7009308160.0000 - val_loss: 7531233280.0000\n",
      "Epoch 1917/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162903040.0000 - val_loss: 8842823680.0000\n",
      "Epoch 1918/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7425554944.0000 - val_loss: 7847367168.0000\n",
      "Epoch 1919/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7064166400.0000 - val_loss: 7752105984.0000\n",
      "Epoch 1920/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7132547072.0000 - val_loss: 8154037248.0000\n",
      "Epoch 1921/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7113266176.0000 - val_loss: 7342181888.0000\n",
      "Epoch 1922/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6870178304.0000 - val_loss: 7197399040.0000\n",
      "Epoch 1923/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6953318912.0000 - val_loss: 7167536640.0000\n",
      "Epoch 1924/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7277458432.0000 - val_loss: 7574736384.0000\n",
      "Epoch 1925/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7242267136.0000 - val_loss: 7254643712.0000\n",
      "Epoch 1926/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7119237632.0000 - val_loss: 7474412544.0000\n",
      "Epoch 1927/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7031090688.0000 - val_loss: 8143628800.0000\n",
      "Epoch 1928/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7024696832.0000 - val_loss: 7842169344.0000\n",
      "Epoch 1929/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7199589888.0000 - val_loss: 7325325312.0000\n",
      "Epoch 1930/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7252626944.0000 - val_loss: 8229389824.0000\n",
      "Epoch 1931/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7170978816.0000 - val_loss: 7484645888.0000\n",
      "Epoch 1932/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7173394432.0000 - val_loss: 7145709056.0000\n",
      "Epoch 1933/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7209001984.0000 - val_loss: 8515113472.0000\n",
      "Epoch 1934/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7015489536.0000 - val_loss: 7188141056.0000\n",
      "Epoch 1935/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7252478976.0000 - val_loss: 7427793920.0000\n",
      "Epoch 1936/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7603109888.0000 - val_loss: 7172570624.0000\n",
      "Epoch 1937/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004312064.0000 - val_loss: 7400346112.0000\n",
      "Epoch 1938/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7126700032.0000 - val_loss: 7313403392.0000\n",
      "Epoch 1939/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7026729472.0000 - val_loss: 8392953856.0000\n",
      "Epoch 1940/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7052253184.0000 - val_loss: 7404102656.0000\n",
      "Epoch 1941/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7635505664.0000 - val_loss: 7309877248.0000\n",
      "Epoch 1942/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7068371968.0000 - val_loss: 8125292544.0000\n",
      "Epoch 1943/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7284791296.0000 - val_loss: 7281844736.0000\n",
      "Epoch 1944/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7109285376.0000 - val_loss: 7435097600.0000\n",
      "Epoch 1945/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7034938880.0000 - val_loss: 7462601728.0000\n",
      "Epoch 1946/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7132303360.0000 - val_loss: 7518729216.0000\n",
      "Epoch 1947/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6995192320.0000 - val_loss: 7451461632.0000\n",
      "Epoch 1948/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7292325888.0000 - val_loss: 7687133184.0000\n",
      "Epoch 1949/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7451889664.0000 - val_loss: 8216897024.0000\n",
      "Epoch 1950/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7297034752.0000 - val_loss: 7877960704.0000\n",
      "Epoch 1951/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7201645056.0000 - val_loss: 7427863552.0000\n",
      "Epoch 1952/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6968828416.0000 - val_loss: 7687417856.0000\n",
      "Epoch 1953/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942994944.0000 - val_loss: 7208649728.0000\n",
      "Epoch 1954/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7025156096.0000 - val_loss: 7351919616.0000\n",
      "Epoch 1955/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7277543936.0000 - val_loss: 7234961920.0000\n",
      "Epoch 1956/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7009220096.0000 - val_loss: 7186236928.0000\n",
      "Epoch 1957/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147726848.0000 - val_loss: 7266881536.0000\n",
      "Epoch 1958/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162219520.0000 - val_loss: 7278173184.0000\n",
      "Epoch 1959/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7312020992.0000 - val_loss: 7898890240.0000\n",
      "Epoch 1960/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7539127296.0000 - val_loss: 7388443136.0000\n",
      "Epoch 1961/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7154639360.0000 - val_loss: 7214932992.0000\n",
      "Epoch 1962/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7410991104.0000 - val_loss: 7574637056.0000\n",
      "Epoch 1963/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7037981696.0000 - val_loss: 7167872000.0000\n",
      "Epoch 1964/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7008873984.0000 - val_loss: 7332300288.0000\n",
      "Epoch 1965/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7051078656.0000 - val_loss: 8028297216.0000\n",
      "Epoch 1966/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7359296512.0000 - val_loss: 9243649024.0000\n",
      "Epoch 1967/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152764928.0000 - val_loss: 7679161856.0000\n",
      "Epoch 1968/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069126144.0000 - val_loss: 7121334784.0000\n",
      "Epoch 1969/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7102440960.0000 - val_loss: 7154097664.0000\n",
      "Epoch 1970/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157167104.0000 - val_loss: 8259446784.0000\n",
      "Epoch 1971/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069689344.0000 - val_loss: 7143466496.0000\n",
      "Epoch 1972/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7039098880.0000 - val_loss: 7149751808.0000\n",
      "Epoch 1973/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7040448000.0000 - val_loss: 7161804288.0000\n",
      "Epoch 1974/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7283963904.0000 - val_loss: 7485988352.0000\n",
      "Epoch 1975/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7109992448.0000 - val_loss: 7158480896.0000\n",
      "Epoch 1976/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7687785472.0000 - val_loss: 10276174848.0000\n",
      "Epoch 1977/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7387977216.0000 - val_loss: 7553754624.0000\n",
      "Epoch 1978/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7244192768.0000 - val_loss: 7343933440.0000\n",
      "Epoch 1979/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7082079744.0000 - val_loss: 7174338560.0000\n",
      "Epoch 1980/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162432512.0000 - val_loss: 9107309568.0000\n",
      "Epoch 1981/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7438453248.0000 - val_loss: 8175391744.0000\n",
      "Epoch 1982/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6982461952.0000 - val_loss: 8323784192.0000\n",
      "Epoch 1983/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7141974528.0000 - val_loss: 7595723776.0000\n",
      "Epoch 1984/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6904027648.0000 - val_loss: 8152560640.0000\n",
      "Epoch 1985/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7218935808.0000 - val_loss: 7152665088.0000\n",
      "Epoch 1986/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7464153600.0000 - val_loss: 8021429760.0000\n",
      "Epoch 1987/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7806597120.0000 - val_loss: 8369828352.0000\n",
      "Epoch 1988/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7140826112.0000 - val_loss: 7219684352.0000\n",
      "Epoch 1989/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7353126400.0000 - val_loss: 7371506176.0000\n",
      "Epoch 1990/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6979439104.0000 - val_loss: 7714660864.0000\n",
      "Epoch 1991/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7041485824.0000 - val_loss: 8044133888.0000\n",
      "Epoch 1992/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7148578304.0000 - val_loss: 7404465664.0000\n",
      "Epoch 1993/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7124804096.0000 - val_loss: 7190535168.0000\n",
      "Epoch 1994/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6963726336.0000 - val_loss: 7357842944.0000\n",
      "Epoch 1995/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7244976128.0000 - val_loss: 7630045184.0000\n",
      "Epoch 1996/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7137196032.0000 - val_loss: 7625024512.0000\n",
      "Epoch 1997/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138147840.0000 - val_loss: 7449852928.0000\n",
      "Epoch 1998/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7143740928.0000 - val_loss: 7378803712.0000\n",
      "Epoch 1999/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7063967744.0000 - val_loss: 7194144256.0000\n",
      "Epoch 2000/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131430400.0000 - val_loss: 7886387200.0000\n",
      "Epoch 2001/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7125617152.0000 - val_loss: 7227088896.0000\n",
      "Epoch 2002/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7145493504.0000 - val_loss: 7659485696.0000\n",
      "Epoch 2003/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7015212032.0000 - val_loss: 7738883584.0000\n",
      "Epoch 2004/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7123457024.0000 - val_loss: 7236235264.0000\n",
      "Epoch 2005/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7037481472.0000 - val_loss: 7461471744.0000\n",
      "Epoch 2006/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7350317568.0000 - val_loss: 7360910848.0000\n",
      "Epoch 2007/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7235025920.0000 - val_loss: 8269047808.0000\n",
      "Epoch 2008/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7062395392.0000 - val_loss: 7608908288.0000\n",
      "Epoch 2009/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7062085120.0000 - val_loss: 9162469376.0000\n",
      "Epoch 2010/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7734844416.0000 - val_loss: 8231272960.0000\n",
      "Epoch 2011/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7208179200.0000 - val_loss: 7502516736.0000\n",
      "Epoch 2012/3000\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 7205684736.0000 - val_loss: 7248330240.0000\n",
      "Epoch 2013/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7298593792.0000 - val_loss: 7654374400.0000\n",
      "Epoch 2014/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6999077888.0000 - val_loss: 8885985280.0000\n",
      "Epoch 2015/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7262064640.0000 - val_loss: 7228582912.0000\n",
      "Epoch 2016/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7052554240.0000 - val_loss: 7839332864.0000\n",
      "Epoch 2017/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7076294144.0000 - val_loss: 7328507392.0000\n",
      "Epoch 2018/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152652288.0000 - val_loss: 7182088192.0000\n",
      "Epoch 2019/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7281529856.0000 - val_loss: 7292623360.0000\n",
      "Epoch 2020/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157168640.0000 - val_loss: 7298175488.0000\n",
      "Epoch 2021/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7283025408.0000 - val_loss: 7359300096.0000\n",
      "Epoch 2022/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7091368960.0000 - val_loss: 8025014272.0000\n",
      "Epoch 2023/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7032604672.0000 - val_loss: 7348593664.0000\n",
      "Epoch 2024/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207534080.0000 - val_loss: 7323046912.0000\n",
      "Epoch 2025/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7701732352.0000 - val_loss: 7287763968.0000\n",
      "Epoch 2026/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7214135296.0000 - val_loss: 7447048704.0000\n",
      "Epoch 2027/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7350498816.0000 - val_loss: 7187039232.0000\n",
      "Epoch 2028/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6930607616.0000 - val_loss: 7173641216.0000\n",
      "Epoch 2029/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7305090560.0000 - val_loss: 7413588992.0000\n",
      "Epoch 2030/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6959581696.0000 - val_loss: 7404808704.0000\n",
      "Epoch 2031/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7056773632.0000 - val_loss: 7209062400.0000\n",
      "Epoch 2032/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6896924672.0000 - val_loss: 7500919296.0000\n",
      "Epoch 2033/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7187374080.0000 - val_loss: 7274191872.0000\n",
      "Epoch 2034/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7061286912.0000 - val_loss: 7356657664.0000\n",
      "Epoch 2035/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6943774720.0000 - val_loss: 7158441984.0000\n",
      "Epoch 2036/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6998557696.0000 - val_loss: 7597789696.0000\n",
      "Epoch 2037/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7058618368.0000 - val_loss: 7696524800.0000\n",
      "Epoch 2038/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7373370880.0000 - val_loss: 7535536640.0000\n",
      "Epoch 2039/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7078359040.0000 - val_loss: 7150848512.0000\n",
      "Epoch 2040/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7232104960.0000 - val_loss: 7662849024.0000\n",
      "Epoch 2041/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7296555520.0000 - val_loss: 7201844224.0000\n",
      "Epoch 2042/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7202866688.0000 - val_loss: 7267901952.0000\n",
      "Epoch 2043/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7044913152.0000 - val_loss: 7262318080.0000\n",
      "Epoch 2044/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7029496832.0000 - val_loss: 7705327616.0000\n",
      "Epoch 2045/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7357390336.0000 - val_loss: 8260295680.0000\n",
      "Epoch 2046/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7058251264.0000 - val_loss: 8695270400.0000\n",
      "Epoch 2047/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7314294784.0000 - val_loss: 7160589312.0000\n",
      "Epoch 2048/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7623055360.0000 - val_loss: 7519660032.0000\n",
      "Epoch 2049/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7025414656.0000 - val_loss: 7254405120.0000\n",
      "Epoch 2050/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7297114624.0000 - val_loss: 7242333696.0000\n",
      "Epoch 2051/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7238550528.0000 - val_loss: 7322956288.0000\n",
      "Epoch 2052/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7040615936.0000 - val_loss: 7925534720.0000\n",
      "Epoch 2053/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7117557760.0000 - val_loss: 8072918016.0000\n",
      "Epoch 2054/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7045076480.0000 - val_loss: 7270807552.0000\n",
      "Epoch 2055/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7155165696.0000 - val_loss: 7519516672.0000\n",
      "Epoch 2056/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7415784960.0000 - val_loss: 7333645824.0000\n",
      "Epoch 2057/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7177800192.0000 - val_loss: 7194568192.0000\n",
      "Epoch 2058/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7374555136.0000 - val_loss: 7262771200.0000\n",
      "Epoch 2059/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6910679552.0000 - val_loss: 7545850368.0000\n",
      "Epoch 2060/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7065720832.0000 - val_loss: 7428956160.0000\n",
      "Epoch 2061/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7146461696.0000 - val_loss: 7609000960.0000\n",
      "Epoch 2062/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6905909248.0000 - val_loss: 8265302016.0000\n",
      "Epoch 2063/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7156047872.0000 - val_loss: 7606386688.0000\n",
      "Epoch 2064/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7255329792.0000 - val_loss: 7258022400.0000\n",
      "Epoch 2065/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7009756672.0000 - val_loss: 7692303360.0000\n",
      "Epoch 2066/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7129112064.0000 - val_loss: 7250255872.0000\n",
      "Epoch 2067/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7166606848.0000 - val_loss: 7225294848.0000\n",
      "Epoch 2068/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7050737664.0000 - val_loss: 7647682560.0000\n",
      "Epoch 2069/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7195936768.0000 - val_loss: 7813661696.0000\n",
      "Epoch 2070/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004566528.0000 - val_loss: 7510868992.0000\n",
      "Epoch 2071/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7182632448.0000 - val_loss: 7187947008.0000\n",
      "Epoch 2072/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7246386688.0000 - val_loss: 8128963584.0000\n",
      "Epoch 2073/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7016614400.0000 - val_loss: 7584428032.0000\n",
      "Epoch 2074/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7461240320.0000 - val_loss: 7157965312.0000\n",
      "Epoch 2075/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6963743232.0000 - val_loss: 7274048512.0000\n",
      "Epoch 2076/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7164097536.0000 - val_loss: 7193793536.0000\n",
      "Epoch 2077/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7086233088.0000 - val_loss: 8089144320.0000\n",
      "Epoch 2078/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7545556992.0000 - val_loss: 7405565952.0000\n",
      "Epoch 2079/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7318035968.0000 - val_loss: 7174438912.0000\n",
      "Epoch 2080/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7605891584.0000 - val_loss: 7323350016.0000\n",
      "Epoch 2081/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7244829696.0000 - val_loss: 8408848384.0000\n",
      "Epoch 2082/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7143041024.0000 - val_loss: 7787750912.0000\n",
      "Epoch 2083/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7205406720.0000 - val_loss: 7210588672.0000\n",
      "Epoch 2084/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7043184128.0000 - val_loss: 7757170688.0000\n",
      "Epoch 2085/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7148030464.0000 - val_loss: 7426876416.0000\n",
      "Epoch 2086/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7025476608.0000 - val_loss: 7410883584.0000\n",
      "Epoch 2087/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7187944448.0000 - val_loss: 7262621184.0000\n",
      "Epoch 2088/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7651894784.0000 - val_loss: 7280129024.0000\n",
      "Epoch 2089/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278192128.0000 - val_loss: 7265619968.0000\n",
      "Epoch 2090/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7084105216.0000 - val_loss: 7882021376.0000\n",
      "Epoch 2091/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7335619072.0000 - val_loss: 7225200640.0000\n",
      "Epoch 2092/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6858511360.0000 - val_loss: 8317666304.0000\n",
      "Epoch 2093/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7227508224.0000 - val_loss: 7270031872.0000\n",
      "Epoch 2094/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6972277760.0000 - val_loss: 7484379136.0000\n",
      "Epoch 2095/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7046673408.0000 - val_loss: 7808811008.0000\n",
      "Epoch 2096/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7173698048.0000 - val_loss: 7281714688.0000\n",
      "Epoch 2097/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7134991872.0000 - val_loss: 7839027200.0000\n",
      "Epoch 2098/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7041414656.0000 - val_loss: 7294808064.0000\n",
      "Epoch 2099/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7136647680.0000 - val_loss: 7498488320.0000\n",
      "Epoch 2100/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7397093888.0000 - val_loss: 9166414848.0000\n",
      "Epoch 2101/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152680960.0000 - val_loss: 7253559296.0000\n",
      "Epoch 2102/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6988819456.0000 - val_loss: 7229059584.0000\n",
      "Epoch 2103/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147518464.0000 - val_loss: 7443580416.0000\n",
      "Epoch 2104/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7045088768.0000 - val_loss: 7206440448.0000\n",
      "Epoch 2105/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7091588608.0000 - val_loss: 7204350464.0000\n",
      "Epoch 2106/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6916254720.0000 - val_loss: 8008550400.0000\n",
      "Epoch 2107/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6941224960.0000 - val_loss: 7485451776.0000\n",
      "Epoch 2108/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7259304448.0000 - val_loss: 7225632768.0000\n",
      "Epoch 2109/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7003177984.0000 - val_loss: 7513356288.0000\n",
      "Epoch 2110/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7052258816.0000 - val_loss: 7476671488.0000\n",
      "Epoch 2111/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7419393536.0000 - val_loss: 7258278912.0000\n",
      "Epoch 2112/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7151287808.0000 - val_loss: 7868195328.0000\n",
      "Epoch 2113/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7009986048.0000 - val_loss: 7204930560.0000\n",
      "Epoch 2114/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101885440.0000 - val_loss: 7252243456.0000\n",
      "Epoch 2115/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7008508416.0000 - val_loss: 7491863040.0000\n",
      "Epoch 2116/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7366583808.0000 - val_loss: 7726066176.0000\n",
      "Epoch 2117/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7085046272.0000 - val_loss: 7314229248.0000\n",
      "Epoch 2118/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7142733312.0000 - val_loss: 7166884352.0000\n",
      "Epoch 2119/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7171625472.0000 - val_loss: 7192946688.0000\n",
      "Epoch 2120/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7249001984.0000 - val_loss: 7349381120.0000\n",
      "Epoch 2121/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7250535936.0000 - val_loss: 7412280320.0000\n",
      "Epoch 2122/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7416164352.0000 - val_loss: 7411147776.0000\n",
      "Epoch 2123/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942887424.0000 - val_loss: 7129007616.0000\n",
      "Epoch 2124/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7017481728.0000 - val_loss: 7149144064.0000\n",
      "Epoch 2125/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7117059072.0000 - val_loss: 7338368512.0000\n",
      "Epoch 2126/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6973790208.0000 - val_loss: 7477877248.0000\n",
      "Epoch 2127/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7159539200.0000 - val_loss: 7504118784.0000\n",
      "Epoch 2128/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7033489408.0000 - val_loss: 7201718784.0000\n",
      "Epoch 2129/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7139706368.0000 - val_loss: 7180351488.0000\n",
      "Epoch 2130/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7273237504.0000 - val_loss: 7714443264.0000\n",
      "Epoch 2131/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023173632.0000 - val_loss: 8255252992.0000\n",
      "Epoch 2132/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7163700736.0000 - val_loss: 7209668608.0000\n",
      "Epoch 2133/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7052724736.0000 - val_loss: 7797795840.0000\n",
      "Epoch 2134/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7299040768.0000 - val_loss: 7206116864.0000\n",
      "Epoch 2135/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7258390528.0000 - val_loss: 7740762624.0000\n",
      "Epoch 2136/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7095074304.0000 - val_loss: 7279412736.0000\n",
      "Epoch 2137/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7161379840.0000 - val_loss: 9547483136.0000\n",
      "Epoch 2138/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7570156544.0000 - val_loss: 7235574784.0000\n",
      "Epoch 2139/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6928285696.0000 - val_loss: 7239361536.0000\n",
      "Epoch 2140/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6948892160.0000 - val_loss: 7372030464.0000\n",
      "Epoch 2141/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7062182912.0000 - val_loss: 7364529152.0000\n",
      "Epoch 2142/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7119549440.0000 - val_loss: 7235077632.0000\n",
      "Epoch 2143/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7316478976.0000 - val_loss: 8763160576.0000\n",
      "Epoch 2144/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7103954944.0000 - val_loss: 7373430784.0000\n",
      "Epoch 2145/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7031536128.0000 - val_loss: 7371688448.0000\n",
      "Epoch 2146/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162373632.0000 - val_loss: 7216444928.0000\n",
      "Epoch 2147/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7065542144.0000 - val_loss: 7409915392.0000\n",
      "Epoch 2148/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6921703936.0000 - val_loss: 7301683200.0000\n",
      "Epoch 2149/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6961953792.0000 - val_loss: 7164647424.0000\n",
      "Epoch 2150/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7098882560.0000 - val_loss: 7163054592.0000\n",
      "Epoch 2151/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7104502272.0000 - val_loss: 7232831488.0000\n",
      "Epoch 2152/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7175447552.0000 - val_loss: 7183370752.0000\n",
      "Epoch 2153/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7095477760.0000 - val_loss: 7150166016.0000\n",
      "Epoch 2154/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023006720.0000 - val_loss: 7270007296.0000\n",
      "Epoch 2155/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7032070656.0000 - val_loss: 7676957696.0000\n",
      "Epoch 2156/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7295662080.0000 - val_loss: 7228843008.0000\n",
      "Epoch 2157/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6999551488.0000 - val_loss: 7266326528.0000\n",
      "Epoch 2158/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6947322368.0000 - val_loss: 7600207872.0000\n",
      "Epoch 2159/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7208216064.0000 - val_loss: 7465028608.0000\n",
      "Epoch 2160/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101970432.0000 - val_loss: 8100582400.0000\n",
      "Epoch 2161/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7187967488.0000 - val_loss: 7190288896.0000\n",
      "Epoch 2162/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7301592576.0000 - val_loss: 7318089728.0000\n",
      "Epoch 2163/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7154628608.0000 - val_loss: 7492961280.0000\n",
      "Epoch 2164/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7048642048.0000 - val_loss: 7340608000.0000\n",
      "Epoch 2165/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7172161024.0000 - val_loss: 7238060544.0000\n",
      "Epoch 2166/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6916637696.0000 - val_loss: 7333723648.0000\n",
      "Epoch 2167/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7124212224.0000 - val_loss: 9626793984.0000\n",
      "Epoch 2168/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7405005824.0000 - val_loss: 7828454912.0000\n",
      "Epoch 2169/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7018990592.0000 - val_loss: 7224733696.0000\n",
      "Epoch 2170/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7150523392.0000 - val_loss: 7371048448.0000\n",
      "Epoch 2171/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7374873088.0000 - val_loss: 7797553152.0000\n",
      "Epoch 2172/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7126307328.0000 - val_loss: 7172832256.0000\n",
      "Epoch 2173/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7050207232.0000 - val_loss: 7470960640.0000\n",
      "Epoch 2174/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7327169536.0000 - val_loss: 10858735616.0000\n",
      "Epoch 2175/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7263201792.0000 - val_loss: 7168504832.0000\n",
      "Epoch 2176/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7200719872.0000 - val_loss: 7154180096.0000\n",
      "Epoch 2177/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7058991616.0000 - val_loss: 7450027520.0000\n",
      "Epoch 2178/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7288441856.0000 - val_loss: 7354804736.0000\n",
      "Epoch 2179/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7115960832.0000 - val_loss: 7747794944.0000\n",
      "Epoch 2180/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6973896192.0000 - val_loss: 7666362880.0000\n",
      "Epoch 2181/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7293825024.0000 - val_loss: 8014226432.0000\n",
      "Epoch 2182/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7050667008.0000 - val_loss: 7191866880.0000\n",
      "Epoch 2183/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7119134208.0000 - val_loss: 7164541440.0000\n",
      "Epoch 2184/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7073872384.0000 - val_loss: 8649562112.0000\n",
      "Epoch 2185/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7078111232.0000 - val_loss: 7094846976.0000\n",
      "Epoch 2186/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7149612032.0000 - val_loss: 7383332864.0000\n",
      "Epoch 2187/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7176869888.0000 - val_loss: 7973850112.0000\n",
      "Epoch 2188/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7117115904.0000 - val_loss: 7238902272.0000\n",
      "Epoch 2189/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7081865728.0000 - val_loss: 7082348544.0000\n",
      "Epoch 2190/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7111113728.0000 - val_loss: 8054138368.0000\n",
      "Epoch 2191/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7190239744.0000 - val_loss: 9249587200.0000\n",
      "Epoch 2192/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7012993536.0000 - val_loss: 7617609728.0000\n",
      "Epoch 2193/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6901727232.0000 - val_loss: 7280838144.0000\n",
      "Epoch 2194/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7324826624.0000 - val_loss: 7236840448.0000\n",
      "Epoch 2195/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7314517504.0000 - val_loss: 7647384576.0000\n",
      "Epoch 2196/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7138104832.0000 - val_loss: 7285394432.0000\n",
      "Epoch 2197/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7338981376.0000 - val_loss: 7451040256.0000\n",
      "Epoch 2198/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7307124736.0000 - val_loss: 7430376960.0000\n",
      "Epoch 2199/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7276060672.0000 - val_loss: 7105090560.0000\n",
      "Epoch 2200/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118824960.0000 - val_loss: 7247963648.0000\n",
      "Epoch 2201/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7506802688.0000 - val_loss: 7514664448.0000\n",
      "Epoch 2202/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7071279616.0000 - val_loss: 7276921856.0000\n",
      "Epoch 2203/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7306738688.0000 - val_loss: 8123933184.0000\n",
      "Epoch 2204/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7086959104.0000 - val_loss: 7533165056.0000\n",
      "Epoch 2205/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6886507008.0000 - val_loss: 7255121920.0000\n",
      "Epoch 2206/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7035400704.0000 - val_loss: 7336776704.0000\n",
      "Epoch 2207/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7374929920.0000 - val_loss: 7276811776.0000\n",
      "Epoch 2208/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7013091328.0000 - val_loss: 7122064384.0000\n",
      "Epoch 2209/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6836862976.0000 - val_loss: 7782462976.0000\n",
      "Epoch 2210/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7249374720.0000 - val_loss: 7355022848.0000\n",
      "Epoch 2211/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7321476096.0000 - val_loss: 7730634752.0000\n",
      "Epoch 2212/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6970529792.0000 - val_loss: 7163245568.0000\n",
      "Epoch 2213/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971441664.0000 - val_loss: 7156023808.0000\n",
      "Epoch 2214/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7084014592.0000 - val_loss: 8059161088.0000\n",
      "Epoch 2215/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7150180864.0000 - val_loss: 7337723904.0000\n",
      "Epoch 2216/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6910984192.0000 - val_loss: 7438767104.0000\n",
      "Epoch 2217/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7526526464.0000 - val_loss: 7355454464.0000\n",
      "Epoch 2218/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7133870592.0000 - val_loss: 7404303872.0000\n",
      "Epoch 2219/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6929953792.0000 - val_loss: 7171145216.0000\n",
      "Epoch 2220/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7058861056.0000 - val_loss: 7240312832.0000\n",
      "Epoch 2221/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7123104768.0000 - val_loss: 9860936704.0000\n",
      "Epoch 2222/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7083447296.0000 - val_loss: 7139211776.0000\n",
      "Epoch 2223/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7042234880.0000 - val_loss: 8013303808.0000\n",
      "Epoch 2224/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6924446720.0000 - val_loss: 7503046656.0000\n",
      "Epoch 2225/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900031488.0000 - val_loss: 7573290496.0000\n",
      "Epoch 2226/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7125906944.0000 - val_loss: 7108764672.0000\n",
      "Epoch 2227/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7324186624.0000 - val_loss: 7285187584.0000\n",
      "Epoch 2228/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6859209728.0000 - val_loss: 7201395712.0000\n",
      "Epoch 2229/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7321675264.0000 - val_loss: 7551275008.0000\n",
      "Epoch 2230/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7148359680.0000 - val_loss: 7344911872.0000\n",
      "Epoch 2231/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7761907712.0000 - val_loss: 7627253248.0000\n",
      "Epoch 2232/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7070566912.0000 - val_loss: 7653793280.0000\n",
      "Epoch 2233/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7322820608.0000 - val_loss: 7575351296.0000\n",
      "Epoch 2234/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6853398016.0000 - val_loss: 7186978304.0000\n",
      "Epoch 2235/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7141624320.0000 - val_loss: 7525528064.0000\n",
      "Epoch 2236/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6980055552.0000 - val_loss: 7201908224.0000\n",
      "Epoch 2237/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6813752832.0000 - val_loss: 7166422016.0000\n",
      "Epoch 2238/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7214585856.0000 - val_loss: 7255824896.0000\n",
      "Epoch 2239/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7439936512.0000 - val_loss: 7288299008.0000\n",
      "Epoch 2240/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7098977280.0000 - val_loss: 7164882432.0000\n",
      "Epoch 2241/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942095360.0000 - val_loss: 7158918656.0000\n",
      "Epoch 2242/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7134824448.0000 - val_loss: 7208155136.0000\n",
      "Epoch 2243/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7076472832.0000 - val_loss: 7714893312.0000\n",
      "Epoch 2244/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7046667776.0000 - val_loss: 7539219456.0000\n",
      "Epoch 2245/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7381453824.0000 - val_loss: 7829702144.0000\n",
      "Epoch 2246/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7193489408.0000 - val_loss: 7128468992.0000\n",
      "Epoch 2247/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7248522752.0000 - val_loss: 7158817792.0000\n",
      "Epoch 2248/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7050414080.0000 - val_loss: 7310153216.0000\n",
      "Epoch 2249/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7092296192.0000 - val_loss: 7487753728.0000\n",
      "Epoch 2250/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7316442112.0000 - val_loss: 7161861632.0000\n",
      "Epoch 2251/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6955106816.0000 - val_loss: 7264546816.0000\n",
      "Epoch 2252/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7115431424.0000 - val_loss: 7196377600.0000\n",
      "Epoch 2253/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6901171712.0000 - val_loss: 7857246208.0000\n",
      "Epoch 2254/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7763065344.0000 - val_loss: 7770334208.0000\n",
      "Epoch 2255/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7056482304.0000 - val_loss: 7325555712.0000\n",
      "Epoch 2256/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7354143744.0000 - val_loss: 8870031360.0000\n",
      "Epoch 2257/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7263871488.0000 - val_loss: 7659391488.0000\n",
      "Epoch 2258/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7196699136.0000 - val_loss: 8097625088.0000\n",
      "Epoch 2259/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7103647232.0000 - val_loss: 7185747456.0000\n",
      "Epoch 2260/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7024329728.0000 - val_loss: 7350760448.0000\n",
      "Epoch 2261/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7082392064.0000 - val_loss: 8163099136.0000\n",
      "Epoch 2262/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7091382784.0000 - val_loss: 7095614464.0000\n",
      "Epoch 2263/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004533760.0000 - val_loss: 7348281344.0000\n",
      "Epoch 2264/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7120621568.0000 - val_loss: 7663664128.0000\n",
      "Epoch 2265/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7075867648.0000 - val_loss: 8691899392.0000\n",
      "Epoch 2266/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7078988288.0000 - val_loss: 7701588480.0000\n",
      "Epoch 2267/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7016947200.0000 - val_loss: 7208247296.0000\n",
      "Epoch 2268/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6940517376.0000 - val_loss: 7113246720.0000\n",
      "Epoch 2269/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7544292352.0000 - val_loss: 7740581376.0000\n",
      "Epoch 2270/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6928629248.0000 - val_loss: 7314299904.0000\n",
      "Epoch 2271/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6880052224.0000 - val_loss: 7554777088.0000\n",
      "Epoch 2272/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7143268864.0000 - val_loss: 7869809152.0000\n",
      "Epoch 2273/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7449223680.0000 - val_loss: 7196453888.0000\n",
      "Epoch 2274/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7154567168.0000 - val_loss: 7213590528.0000\n",
      "Epoch 2275/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049942016.0000 - val_loss: 7271122944.0000\n",
      "Epoch 2276/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6944939008.0000 - val_loss: 7350246400.0000\n",
      "Epoch 2277/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118583296.0000 - val_loss: 7295598080.0000\n",
      "Epoch 2278/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7283206656.0000 - val_loss: 7725783040.0000\n",
      "Epoch 2279/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7056019968.0000 - val_loss: 7507886592.0000\n",
      "Epoch 2280/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6979856896.0000 - val_loss: 7166661632.0000\n",
      "Epoch 2281/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7149314048.0000 - val_loss: 7195901440.0000\n",
      "Epoch 2282/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7002706944.0000 - val_loss: 10779652096.0000\n",
      "Epoch 2283/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7229008384.0000 - val_loss: 8612472832.0000\n",
      "Epoch 2284/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7360215552.0000 - val_loss: 7615135744.0000\n",
      "Epoch 2285/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7130781184.0000 - val_loss: 7203377152.0000\n",
      "Epoch 2286/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7272124928.0000 - val_loss: 7232420352.0000\n",
      "Epoch 2287/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7183672320.0000 - val_loss: 7205318144.0000\n",
      "Epoch 2288/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6918641152.0000 - val_loss: 7318660608.0000\n",
      "Epoch 2289/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6880650240.0000 - val_loss: 7435048448.0000\n",
      "Epoch 2290/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7109645312.0000 - val_loss: 7650214400.0000\n",
      "Epoch 2291/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7308769792.0000 - val_loss: 7449107968.0000\n",
      "Epoch 2292/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7209688064.0000 - val_loss: 7745970176.0000\n",
      "Epoch 2293/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147671040.0000 - val_loss: 7169956864.0000\n",
      "Epoch 2294/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7183790592.0000 - val_loss: 9065238528.0000\n",
      "Epoch 2295/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6990494208.0000 - val_loss: 7096083456.0000\n",
      "Epoch 2296/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6957511680.0000 - val_loss: 7164109824.0000\n",
      "Epoch 2297/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6966030336.0000 - val_loss: 7548445696.0000\n",
      "Epoch 2298/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6879874560.0000 - val_loss: 7193161216.0000\n",
      "Epoch 2299/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6952244736.0000 - val_loss: 7059653632.0000\n",
      "Epoch 2300/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7114861568.0000 - val_loss: 7679023616.0000\n",
      "Epoch 2301/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7026593792.0000 - val_loss: 7648076800.0000\n",
      "Epoch 2302/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7066009088.0000 - val_loss: 7322154496.0000\n",
      "Epoch 2303/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7178018304.0000 - val_loss: 7081822208.0000\n",
      "Epoch 2304/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7151409664.0000 - val_loss: 7162679808.0000\n",
      "Epoch 2305/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7349315072.0000 - val_loss: 7364127232.0000\n",
      "Epoch 2306/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7232124416.0000 - val_loss: 7565186560.0000\n",
      "Epoch 2307/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6896949760.0000 - val_loss: 7960049664.0000\n",
      "Epoch 2308/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6879988736.0000 - val_loss: 7442944000.0000\n",
      "Epoch 2309/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6966764032.0000 - val_loss: 8241369088.0000\n",
      "Epoch 2310/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7130866688.0000 - val_loss: 9101213696.0000\n",
      "Epoch 2311/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7325406720.0000 - val_loss: 7262332416.0000\n",
      "Epoch 2312/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7028473344.0000 - val_loss: 7303169024.0000\n",
      "Epoch 2313/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7016566784.0000 - val_loss: 7682935296.0000\n",
      "Epoch 2314/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7089616896.0000 - val_loss: 7116434432.0000\n",
      "Epoch 2315/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7456172032.0000 - val_loss: 7177418752.0000\n",
      "Epoch 2316/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942484992.0000 - val_loss: 7210266624.0000\n",
      "Epoch 2317/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6881766912.0000 - val_loss: 7348019712.0000\n",
      "Epoch 2318/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6983851520.0000 - val_loss: 7241593856.0000\n",
      "Epoch 2319/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6856366592.0000 - val_loss: 7350024704.0000\n",
      "Epoch 2320/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7200437248.0000 - val_loss: 7228316160.0000\n",
      "Epoch 2321/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7000134144.0000 - val_loss: 7126775296.0000\n",
      "Epoch 2322/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7347956736.0000 - val_loss: 8029929472.0000\n",
      "Epoch 2323/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7061788160.0000 - val_loss: 7533760512.0000\n",
      "Epoch 2324/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7048879104.0000 - val_loss: 7141650432.0000\n",
      "Epoch 2325/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7196450304.0000 - val_loss: 7158697472.0000\n",
      "Epoch 2326/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7127797760.0000 - val_loss: 7402043392.0000\n",
      "Epoch 2327/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7036125184.0000 - val_loss: 8106028032.0000\n",
      "Epoch 2328/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7235159040.0000 - val_loss: 7544969216.0000\n",
      "Epoch 2329/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7121067520.0000 - val_loss: 8086829056.0000\n",
      "Epoch 2330/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7093242368.0000 - val_loss: 7243474432.0000\n",
      "Epoch 2331/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165852672.0000 - val_loss: 7475407872.0000\n",
      "Epoch 2332/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6976438272.0000 - val_loss: 7094404096.0000\n",
      "Epoch 2333/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6931013120.0000 - val_loss: 7739861504.0000\n",
      "Epoch 2334/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7774186496.0000 - val_loss: 7203532800.0000\n",
      "Epoch 2335/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7046376448.0000 - val_loss: 7831840768.0000\n",
      "Epoch 2336/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6837310464.0000 - val_loss: 7258665472.0000\n",
      "Epoch 2337/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7010771968.0000 - val_loss: 9054095360.0000\n",
      "Epoch 2338/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7135741952.0000 - val_loss: 7228395008.0000\n",
      "Epoch 2339/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6958677504.0000 - val_loss: 7102928384.0000\n",
      "Epoch 2340/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7127005184.0000 - val_loss: 7051160576.0000\n",
      "Epoch 2341/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7306052608.0000 - val_loss: 7343869952.0000\n",
      "Epoch 2342/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6964608000.0000 - val_loss: 7948165120.0000\n",
      "Epoch 2343/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7026597888.0000 - val_loss: 7229909504.0000\n",
      "Epoch 2344/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6959162368.0000 - val_loss: 7271992320.0000\n",
      "Epoch 2345/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7000413696.0000 - val_loss: 7074176000.0000\n",
      "Epoch 2346/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7096993792.0000 - val_loss: 7981563392.0000\n",
      "Epoch 2347/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7158429184.0000 - val_loss: 7524454400.0000\n",
      "Epoch 2348/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6872962560.0000 - val_loss: 7079906304.0000\n",
      "Epoch 2349/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7337028608.0000 - val_loss: 8573670912.0000\n",
      "Epoch 2350/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7153201152.0000 - val_loss: 7062899200.0000\n",
      "Epoch 2351/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6916388864.0000 - val_loss: 7180043776.0000\n",
      "Epoch 2352/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7116582400.0000 - val_loss: 7181946368.0000\n",
      "Epoch 2353/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7135860736.0000 - val_loss: 7131941888.0000\n",
      "Epoch 2354/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7011853824.0000 - val_loss: 8502503424.0000\n",
      "Epoch 2355/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7221623296.0000 - val_loss: 7248102400.0000\n",
      "Epoch 2356/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6913019904.0000 - val_loss: 7355199488.0000\n",
      "Epoch 2357/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069676544.0000 - val_loss: 7197074432.0000\n",
      "Epoch 2358/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6932878848.0000 - val_loss: 7590696960.0000\n",
      "Epoch 2359/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7059047424.0000 - val_loss: 7584708608.0000\n",
      "Epoch 2360/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6901762048.0000 - val_loss: 7226123264.0000\n",
      "Epoch 2361/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7160210432.0000 - val_loss: 7442232832.0000\n",
      "Epoch 2362/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7042122752.0000 - val_loss: 7279585792.0000\n",
      "Epoch 2363/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6895539200.0000 - val_loss: 7084161024.0000\n",
      "Epoch 2364/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6978888192.0000 - val_loss: 7135214080.0000\n",
      "Epoch 2365/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7098346496.0000 - val_loss: 7317689344.0000\n",
      "Epoch 2366/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7001088512.0000 - val_loss: 7283774464.0000\n",
      "Epoch 2367/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7654409728.0000 - val_loss: 7666775552.0000\n",
      "Epoch 2368/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7082328064.0000 - val_loss: 7217387520.0000\n",
      "Epoch 2369/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7162847744.0000 - val_loss: 8004843520.0000\n",
      "Epoch 2370/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6872066048.0000 - val_loss: 8314245632.0000\n",
      "Epoch 2371/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971658240.0000 - val_loss: 7362594816.0000\n",
      "Epoch 2372/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7177763840.0000 - val_loss: 8367523840.0000\n",
      "Epoch 2373/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7310474240.0000 - val_loss: 7370821632.0000\n",
      "Epoch 2374/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6927587840.0000 - val_loss: 8556647936.0000\n",
      "Epoch 2375/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7174452224.0000 - val_loss: 7117323264.0000\n",
      "Epoch 2376/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004517888.0000 - val_loss: 7086598144.0000\n",
      "Epoch 2377/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7001422336.0000 - val_loss: 7138339328.0000\n",
      "Epoch 2378/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7151403008.0000 - val_loss: 7363103744.0000\n",
      "Epoch 2379/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6841126912.0000 - val_loss: 7627446272.0000\n",
      "Epoch 2380/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7192817152.0000 - val_loss: 8111328768.0000\n",
      "Epoch 2381/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6831836672.0000 - val_loss: 7421720064.0000\n",
      "Epoch 2382/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6921920512.0000 - val_loss: 7143405056.0000\n",
      "Epoch 2383/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6891808256.0000 - val_loss: 7077716992.0000\n",
      "Epoch 2384/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7099600384.0000 - val_loss: 7536416256.0000\n",
      "Epoch 2385/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7196344832.0000 - val_loss: 7314122752.0000\n",
      "Epoch 2386/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7209225216.0000 - val_loss: 7552735232.0000\n",
      "Epoch 2387/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971366912.0000 - val_loss: 7308546560.0000\n",
      "Epoch 2388/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7233425408.0000 - val_loss: 7602990592.0000\n",
      "Epoch 2389/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7253513728.0000 - val_loss: 7390155264.0000\n",
      "Epoch 2390/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7063939072.0000 - val_loss: 7275456000.0000\n",
      "Epoch 2391/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7074810368.0000 - val_loss: 7632753664.0000\n",
      "Epoch 2392/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069229056.0000 - val_loss: 7039744512.0000\n",
      "Epoch 2393/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7008386048.0000 - val_loss: 8679395328.0000\n",
      "Epoch 2394/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6968250880.0000 - val_loss: 7191866368.0000\n",
      "Epoch 2395/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6976675328.0000 - val_loss: 7519928832.0000\n",
      "Epoch 2396/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6909481984.0000 - val_loss: 7149988864.0000\n",
      "Epoch 2397/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7245119488.0000 - val_loss: 7135220736.0000\n",
      "Epoch 2398/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6908721152.0000 - val_loss: 7383001088.0000\n",
      "Epoch 2399/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6991817216.0000 - val_loss: 7260263424.0000\n",
      "Epoch 2400/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7181338624.0000 - val_loss: 7122013184.0000\n",
      "Epoch 2401/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7108453888.0000 - val_loss: 7888797696.0000\n",
      "Epoch 2402/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900288512.0000 - val_loss: 7088487424.0000\n",
      "Epoch 2403/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7119254528.0000 - val_loss: 7049230848.0000\n",
      "Epoch 2404/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7105999360.0000 - val_loss: 7258417664.0000\n",
      "Epoch 2405/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6839448064.0000 - val_loss: 7501867008.0000\n",
      "Epoch 2406/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7095471616.0000 - val_loss: 7243200512.0000\n",
      "Epoch 2407/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6868325888.0000 - val_loss: 7431089664.0000\n",
      "Epoch 2408/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7307103232.0000 - val_loss: 7103036928.0000\n",
      "Epoch 2409/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6905388544.0000 - val_loss: 7084259328.0000\n",
      "Epoch 2410/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6939161088.0000 - val_loss: 8639900672.0000\n",
      "Epoch 2411/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131400192.0000 - val_loss: 7144613888.0000\n",
      "Epoch 2412/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6962949120.0000 - val_loss: 8573294592.0000\n",
      "Epoch 2413/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7282113024.0000 - val_loss: 7207738368.0000\n",
      "Epoch 2414/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7003441664.0000 - val_loss: 7073537024.0000\n",
      "Epoch 2415/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7029690368.0000 - val_loss: 8489957888.0000\n",
      "Epoch 2416/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6956257792.0000 - val_loss: 7545207808.0000\n",
      "Epoch 2417/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7332925440.0000 - val_loss: 7096691200.0000\n",
      "Epoch 2418/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6867973120.0000 - val_loss: 7315232256.0000\n",
      "Epoch 2419/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6929317888.0000 - val_loss: 7177424896.0000\n",
      "Epoch 2420/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6992212480.0000 - val_loss: 7142577664.0000\n",
      "Epoch 2421/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6939155456.0000 - val_loss: 7197586432.0000\n",
      "Epoch 2422/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7147581440.0000 - val_loss: 7044861440.0000\n",
      "Epoch 2423/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6914235904.0000 - val_loss: 7824926720.0000\n",
      "Epoch 2424/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6974813696.0000 - val_loss: 7189988864.0000\n",
      "Epoch 2425/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6927660032.0000 - val_loss: 7548282880.0000\n",
      "Epoch 2426/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6887158272.0000 - val_loss: 7598973440.0000\n",
      "Epoch 2427/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7053869056.0000 - val_loss: 7047110656.0000\n",
      "Epoch 2428/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7044601856.0000 - val_loss: 8801333248.0000\n",
      "Epoch 2429/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6933351936.0000 - val_loss: 7124855296.0000\n",
      "Epoch 2430/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7424604672.0000 - val_loss: 7101762048.0000\n",
      "Epoch 2431/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7070650368.0000 - val_loss: 7146082304.0000\n",
      "Epoch 2432/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101184512.0000 - val_loss: 7358429696.0000\n",
      "Epoch 2433/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7277904384.0000 - val_loss: 7144902144.0000\n",
      "Epoch 2434/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6963533824.0000 - val_loss: 8095219712.0000\n",
      "Epoch 2435/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7150833664.0000 - val_loss: 7410524160.0000\n",
      "Epoch 2436/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6906396672.0000 - val_loss: 7332802048.0000\n",
      "Epoch 2437/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7442292224.0000 - val_loss: 7137077760.0000\n",
      "Epoch 2438/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7247829504.0000 - val_loss: 7565580288.0000\n",
      "Epoch 2439/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6994479616.0000 - val_loss: 7633375744.0000\n",
      "Epoch 2440/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6892679168.0000 - val_loss: 7059882496.0000\n",
      "Epoch 2441/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7278237696.0000 - val_loss: 7170992128.0000\n",
      "Epoch 2442/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165848576.0000 - val_loss: 7113860096.0000\n",
      "Epoch 2443/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6875753984.0000 - val_loss: 7082868224.0000\n",
      "Epoch 2444/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7030257152.0000 - val_loss: 7035171328.0000\n",
      "Epoch 2445/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6872311296.0000 - val_loss: 7788015104.0000\n",
      "Epoch 2446/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6821758976.0000 - val_loss: 7101761024.0000\n",
      "Epoch 2447/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7299231232.0000 - val_loss: 7316136448.0000\n",
      "Epoch 2448/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6943613952.0000 - val_loss: 7618921984.0000\n",
      "Epoch 2449/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6951280128.0000 - val_loss: 7511319040.0000\n",
      "Epoch 2450/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7441096192.0000 - val_loss: 8697430016.0000\n",
      "Epoch 2451/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7447517696.0000 - val_loss: 7665899520.0000\n",
      "Epoch 2452/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7017371136.0000 - val_loss: 7161908736.0000\n",
      "Epoch 2453/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6934831616.0000 - val_loss: 8136697856.0000\n",
      "Epoch 2454/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7093420032.0000 - val_loss: 7136487936.0000\n",
      "Epoch 2455/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101767680.0000 - val_loss: 7466240512.0000\n",
      "Epoch 2456/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6967935488.0000 - val_loss: 7070573568.0000\n",
      "Epoch 2457/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7277916672.0000 - val_loss: 8710240256.0000\n",
      "Epoch 2458/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7158358528.0000 - val_loss: 8623115264.0000\n",
      "Epoch 2459/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7508619776.0000 - val_loss: 7302144000.0000\n",
      "Epoch 2460/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7383402496.0000 - val_loss: 7436007936.0000\n",
      "Epoch 2461/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7038352896.0000 - val_loss: 7338130432.0000\n",
      "Epoch 2462/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7059386368.0000 - val_loss: 7756585472.0000\n",
      "Epoch 2463/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7083427840.0000 - val_loss: 7250018816.0000\n",
      "Epoch 2464/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7023956992.0000 - val_loss: 7071811584.0000\n",
      "Epoch 2465/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6775261696.0000 - val_loss: 7091417088.0000\n",
      "Epoch 2466/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7027242496.0000 - val_loss: 7186145280.0000\n",
      "Epoch 2467/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6895147008.0000 - val_loss: 7378426368.0000\n",
      "Epoch 2468/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7105721344.0000 - val_loss: 9443456000.0000\n",
      "Epoch 2469/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6968250880.0000 - val_loss: 7115268096.0000\n",
      "Epoch 2470/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6993283584.0000 - val_loss: 7595895296.0000\n",
      "Epoch 2471/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7061158912.0000 - val_loss: 7164219392.0000\n",
      "Epoch 2472/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6934235648.0000 - val_loss: 7109174784.0000\n",
      "Epoch 2473/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6940373504.0000 - val_loss: 7371953664.0000\n",
      "Epoch 2474/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7035047424.0000 - val_loss: 7535742464.0000\n",
      "Epoch 2475/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7065239552.0000 - val_loss: 7713203712.0000\n",
      "Epoch 2476/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7000461824.0000 - val_loss: 8137613312.0000\n",
      "Epoch 2477/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6946909184.0000 - val_loss: 7163836928.0000\n",
      "Epoch 2478/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6846189568.0000 - val_loss: 7805675008.0000\n",
      "Epoch 2479/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6967362560.0000 - val_loss: 7012498432.0000\n",
      "Epoch 2480/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7213737984.0000 - val_loss: 7357423616.0000\n",
      "Epoch 2481/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6810067456.0000 - val_loss: 7130875904.0000\n",
      "Epoch 2482/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7125820928.0000 - val_loss: 7078588928.0000\n",
      "Epoch 2483/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6966812160.0000 - val_loss: 7529151488.0000\n",
      "Epoch 2484/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128609792.0000 - val_loss: 7154136064.0000\n",
      "Epoch 2485/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128979456.0000 - val_loss: 7333802496.0000\n",
      "Epoch 2486/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6825302528.0000 - val_loss: 7153135616.0000\n",
      "Epoch 2487/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6916817408.0000 - val_loss: 7105239552.0000\n",
      "Epoch 2488/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6844928512.0000 - val_loss: 7439030272.0000\n",
      "Epoch 2489/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7223391232.0000 - val_loss: 8221261824.0000\n",
      "Epoch 2490/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7357627904.0000 - val_loss: 7268324864.0000\n",
      "Epoch 2491/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6919995904.0000 - val_loss: 8072777216.0000\n",
      "Epoch 2492/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7276357632.0000 - val_loss: 7279499776.0000\n",
      "Epoch 2493/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7214420480.0000 - val_loss: 8024474112.0000\n",
      "Epoch 2494/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6834663936.0000 - val_loss: 7117366784.0000\n",
      "Epoch 2495/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6910875136.0000 - val_loss: 7038048768.0000\n",
      "Epoch 2496/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7019849728.0000 - val_loss: 7238542848.0000\n",
      "Epoch 2497/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7174219776.0000 - val_loss: 7521261568.0000\n",
      "Epoch 2498/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7411337728.0000 - val_loss: 8602504192.0000\n",
      "Epoch 2499/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6980955648.0000 - val_loss: 7170599936.0000\n",
      "Epoch 2500/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6821025280.0000 - val_loss: 7415187456.0000\n",
      "Epoch 2501/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6870832128.0000 - val_loss: 7623134208.0000\n",
      "Epoch 2502/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7077597696.0000 - val_loss: 7123828736.0000\n",
      "Epoch 2503/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6920151552.0000 - val_loss: 7224924160.0000\n",
      "Epoch 2504/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152732672.0000 - val_loss: 7478076416.0000\n",
      "Epoch 2505/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7066669056.0000 - val_loss: 7444706304.0000\n",
      "Epoch 2506/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7053211648.0000 - val_loss: 7576022016.0000\n",
      "Epoch 2507/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7128741376.0000 - val_loss: 7164705280.0000\n",
      "Epoch 2508/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6804467712.0000 - val_loss: 7192549888.0000\n",
      "Epoch 2509/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900769280.0000 - val_loss: 7014589440.0000\n",
      "Epoch 2510/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7811816448.0000 - val_loss: 8621830144.0000\n",
      "Epoch 2511/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6940429824.0000 - val_loss: 7838113792.0000\n",
      "Epoch 2512/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7012050944.0000 - val_loss: 7170622464.0000\n",
      "Epoch 2513/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6947537920.0000 - val_loss: 7431843328.0000\n",
      "Epoch 2514/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6830080000.0000 - val_loss: 7436828672.0000\n",
      "Epoch 2515/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6955842560.0000 - val_loss: 7348876288.0000\n",
      "Epoch 2516/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6868150784.0000 - val_loss: 7321557504.0000\n",
      "Epoch 2517/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049809920.0000 - val_loss: 7661334528.0000\n",
      "Epoch 2518/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971153920.0000 - val_loss: 8370760704.0000\n",
      "Epoch 2519/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7119875072.0000 - val_loss: 7261811200.0000\n",
      "Epoch 2520/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6916370944.0000 - val_loss: 7296568832.0000\n",
      "Epoch 2521/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7157937664.0000 - val_loss: 7335574016.0000\n",
      "Epoch 2522/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7134404096.0000 - val_loss: 7145174528.0000\n",
      "Epoch 2523/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7069372416.0000 - val_loss: 7624784896.0000\n",
      "Epoch 2524/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6953677312.0000 - val_loss: 7178238976.0000\n",
      "Epoch 2525/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7027255808.0000 - val_loss: 7121853952.0000\n",
      "Epoch 2526/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6915269632.0000 - val_loss: 7089264128.0000\n",
      "Epoch 2527/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7144823296.0000 - val_loss: 7724765696.0000\n",
      "Epoch 2528/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7269583360.0000 - val_loss: 7596756480.0000\n",
      "Epoch 2529/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6866820096.0000 - val_loss: 7364198912.0000\n",
      "Epoch 2530/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7334107136.0000 - val_loss: 7127705088.0000\n",
      "Epoch 2531/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6938955776.0000 - val_loss: 8364680704.0000\n",
      "Epoch 2532/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6987108352.0000 - val_loss: 7122277376.0000\n",
      "Epoch 2533/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6987289600.0000 - val_loss: 7051684864.0000\n",
      "Epoch 2534/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6860817920.0000 - val_loss: 7194009088.0000\n",
      "Epoch 2535/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6812088832.0000 - val_loss: 7142001664.0000\n",
      "Epoch 2536/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6817071104.0000 - val_loss: 7069665280.0000\n",
      "Epoch 2537/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7017618432.0000 - val_loss: 7128167424.0000\n",
      "Epoch 2538/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7121851904.0000 - val_loss: 7532428800.0000\n",
      "Epoch 2539/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6936385536.0000 - val_loss: 7082714112.0000\n",
      "Epoch 2540/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7056144896.0000 - val_loss: 7046589440.0000\n",
      "Epoch 2541/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6824568832.0000 - val_loss: 7087630848.0000\n",
      "Epoch 2542/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6822455808.0000 - val_loss: 7041037312.0000\n",
      "Epoch 2543/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6906489856.0000 - val_loss: 7011080704.0000\n",
      "Epoch 2544/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6850874880.0000 - val_loss: 7394200064.0000\n",
      "Epoch 2545/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118644224.0000 - val_loss: 7310824448.0000\n",
      "Epoch 2546/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6833507840.0000 - val_loss: 7219665408.0000\n",
      "Epoch 2547/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6788717056.0000 - val_loss: 7621917184.0000\n",
      "Epoch 2548/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7098280960.0000 - val_loss: 7007625216.0000\n",
      "Epoch 2549/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7146644992.0000 - val_loss: 7336797696.0000\n",
      "Epoch 2550/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6985357312.0000 - val_loss: 7005942784.0000\n",
      "Epoch 2551/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6944174592.0000 - val_loss: 7813799424.0000\n",
      "Epoch 2552/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7055790080.0000 - val_loss: 7188375552.0000\n",
      "Epoch 2553/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6761686016.0000 - val_loss: 7218760192.0000\n",
      "Epoch 2554/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7011400704.0000 - val_loss: 7412668928.0000\n",
      "Epoch 2555/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7081952768.0000 - val_loss: 7178943488.0000\n",
      "Epoch 2556/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101851136.0000 - val_loss: 7179535360.0000\n",
      "Epoch 2557/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6811594752.0000 - val_loss: 7049583616.0000\n",
      "Epoch 2558/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7400176128.0000 - val_loss: 7342751744.0000\n",
      "Epoch 2559/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7406263808.0000 - val_loss: 7216366080.0000\n",
      "Epoch 2560/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6881735680.0000 - val_loss: 7188216320.0000\n",
      "Epoch 2561/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6835924480.0000 - val_loss: 6987008000.0000\n",
      "Epoch 2562/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6958709760.0000 - val_loss: 7295714304.0000\n",
      "Epoch 2563/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7093146112.0000 - val_loss: 7191523328.0000\n",
      "Epoch 2564/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6815134720.0000 - val_loss: 7434886144.0000\n",
      "Epoch 2565/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6882509824.0000 - val_loss: 7050193920.0000\n",
      "Epoch 2566/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6938174976.0000 - val_loss: 7164086784.0000\n",
      "Epoch 2567/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7056218624.0000 - val_loss: 8111765504.0000\n",
      "Epoch 2568/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6893948416.0000 - val_loss: 7084592128.0000\n",
      "Epoch 2569/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7133071872.0000 - val_loss: 7909501440.0000\n",
      "Epoch 2570/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7420151808.0000 - val_loss: 7125617664.0000\n",
      "Epoch 2571/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6757643264.0000 - val_loss: 7052510208.0000\n",
      "Epoch 2572/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6854095872.0000 - val_loss: 7072267264.0000\n",
      "Epoch 2573/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7072801280.0000 - val_loss: 7137772032.0000\n",
      "Epoch 2574/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6949086720.0000 - val_loss: 7151644160.0000\n",
      "Epoch 2575/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6888872448.0000 - val_loss: 7211469824.0000\n",
      "Epoch 2576/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6852284416.0000 - val_loss: 7723260416.0000\n",
      "Epoch 2577/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7041410048.0000 - val_loss: 7303775744.0000\n",
      "Epoch 2578/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6990475776.0000 - val_loss: 7046773248.0000\n",
      "Epoch 2579/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7246868992.0000 - val_loss: 7490275328.0000\n",
      "Epoch 2580/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6876523520.0000 - val_loss: 9536223232.0000\n",
      "Epoch 2581/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7124255232.0000 - val_loss: 7068893184.0000\n",
      "Epoch 2582/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6842107392.0000 - val_loss: 7137499136.0000\n",
      "Epoch 2583/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6887582720.0000 - val_loss: 7634470912.0000\n",
      "Epoch 2584/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7089765376.0000 - val_loss: 7241896960.0000\n",
      "Epoch 2585/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6939328000.0000 - val_loss: 7427571200.0000\n",
      "Epoch 2586/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7099752960.0000 - val_loss: 9390039040.0000\n",
      "Epoch 2587/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7042813952.0000 - val_loss: 7072391680.0000\n",
      "Epoch 2588/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6883123712.0000 - val_loss: 7096434688.0000\n",
      "Epoch 2589/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6761408512.0000 - val_loss: 7459650560.0000\n",
      "Epoch 2590/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6885035008.0000 - val_loss: 8716770304.0000\n",
      "Epoch 2591/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7108132864.0000 - val_loss: 7020008448.0000\n",
      "Epoch 2592/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6984343552.0000 - val_loss: 7861221888.0000\n",
      "Epoch 2593/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7088578560.0000 - val_loss: 7051081728.0000\n",
      "Epoch 2594/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6978669568.0000 - val_loss: 7089835008.0000\n",
      "Epoch 2595/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7019891712.0000 - val_loss: 7538030080.0000\n",
      "Epoch 2596/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6902794240.0000 - val_loss: 8243464192.0000\n",
      "Epoch 2597/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7748774912.0000 - val_loss: 7218536448.0000\n",
      "Epoch 2598/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6990094336.0000 - val_loss: 7419883520.0000\n",
      "Epoch 2599/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7012989952.0000 - val_loss: 7436604416.0000\n",
      "Epoch 2600/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6822605824.0000 - val_loss: 7003920896.0000\n",
      "Epoch 2601/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7169857536.0000 - val_loss: 7388851712.0000\n",
      "Epoch 2602/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6858540544.0000 - val_loss: 7544078848.0000\n",
      "Epoch 2603/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7309876736.0000 - val_loss: 7562665472.0000\n",
      "Epoch 2604/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7208871424.0000 - val_loss: 7079804928.0000\n",
      "Epoch 2605/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6886869504.0000 - val_loss: 7509800960.0000\n",
      "Epoch 2606/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6936861184.0000 - val_loss: 7092687360.0000\n",
      "Epoch 2607/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6765944320.0000 - val_loss: 6991298560.0000\n",
      "Epoch 2608/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6751915520.0000 - val_loss: 7033554944.0000\n",
      "Epoch 2609/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6854613504.0000 - val_loss: 7332863488.0000\n",
      "Epoch 2610/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7135242240.0000 - val_loss: 7237406720.0000\n",
      "Epoch 2611/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7006803968.0000 - val_loss: 7192664064.0000\n",
      "Epoch 2612/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6779655680.0000 - val_loss: 7254725120.0000\n",
      "Epoch 2613/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7021510656.0000 - val_loss: 7827928064.0000\n",
      "Epoch 2614/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7065920512.0000 - val_loss: 7117463552.0000\n",
      "Epoch 2615/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6896652288.0000 - val_loss: 7807085568.0000\n",
      "Epoch 2616/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6877791744.0000 - val_loss: 7119881728.0000\n",
      "Epoch 2617/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6728981504.0000 - val_loss: 8464520192.0000\n",
      "Epoch 2618/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6958558208.0000 - val_loss: 7118365696.0000\n",
      "Epoch 2619/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6848933888.0000 - val_loss: 7251453440.0000\n",
      "Epoch 2620/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7156569600.0000 - val_loss: 7472385536.0000\n",
      "Epoch 2621/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6970068480.0000 - val_loss: 7210691072.0000\n",
      "Epoch 2622/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6792254464.0000 - val_loss: 7217735168.0000\n",
      "Epoch 2623/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7005041664.0000 - val_loss: 7115573248.0000\n",
      "Epoch 2624/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7097859584.0000 - val_loss: 8914434048.0000\n",
      "Epoch 2625/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7110018560.0000 - val_loss: 7153339392.0000\n",
      "Epoch 2626/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7340143616.0000 - val_loss: 8627301376.0000\n",
      "Epoch 2627/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7454387200.0000 - val_loss: 7455981056.0000\n",
      "Epoch 2628/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6864711168.0000 - val_loss: 7801268224.0000\n",
      "Epoch 2629/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6885274112.0000 - val_loss: 7219501568.0000\n",
      "Epoch 2630/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7194475520.0000 - val_loss: 6987216384.0000\n",
      "Epoch 2631/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6747968000.0000 - val_loss: 7877008896.0000\n",
      "Epoch 2632/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023292416.0000 - val_loss: 7123196928.0000\n",
      "Epoch 2633/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6920761856.0000 - val_loss: 6977467392.0000\n",
      "Epoch 2634/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6877111296.0000 - val_loss: 7251623424.0000\n",
      "Epoch 2635/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7198965248.0000 - val_loss: 7186743808.0000\n",
      "Epoch 2636/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6943569920.0000 - val_loss: 7275287552.0000\n",
      "Epoch 2637/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6796798976.0000 - val_loss: 6985382912.0000\n",
      "Epoch 2638/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7017624576.0000 - val_loss: 7167949312.0000\n",
      "Epoch 2639/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6746654720.0000 - val_loss: 6989292032.0000\n",
      "Epoch 2640/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7398661120.0000 - val_loss: 7148128256.0000\n",
      "Epoch 2641/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7108623872.0000 - val_loss: 7020505088.0000\n",
      "Epoch 2642/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131521024.0000 - val_loss: 8732551168.0000\n",
      "Epoch 2643/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6991634944.0000 - val_loss: 7041381888.0000\n",
      "Epoch 2644/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6817961472.0000 - val_loss: 7283289088.0000\n",
      "Epoch 2645/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7261519872.0000 - val_loss: 7376356352.0000\n",
      "Epoch 2646/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6952192512.0000 - val_loss: 7098556416.0000\n",
      "Epoch 2647/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6754724352.0000 - val_loss: 7008803328.0000\n",
      "Epoch 2648/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6853913088.0000 - val_loss: 8405639680.0000\n",
      "Epoch 2649/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6897310720.0000 - val_loss: 7255018496.0000\n",
      "Epoch 2650/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6860948480.0000 - val_loss: 7375391744.0000\n",
      "Epoch 2651/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6854720000.0000 - val_loss: 7399945216.0000\n",
      "Epoch 2652/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6830189056.0000 - val_loss: 7316591616.0000\n",
      "Epoch 2653/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6870425088.0000 - val_loss: 7161184256.0000\n",
      "Epoch 2654/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6838539776.0000 - val_loss: 7208213504.0000\n",
      "Epoch 2655/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7374988800.0000 - val_loss: 8192292352.0000\n",
      "Epoch 2656/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7211872256.0000 - val_loss: 7009452032.0000\n",
      "Epoch 2657/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6873772032.0000 - val_loss: 7151270400.0000\n",
      "Epoch 2658/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6859712512.0000 - val_loss: 7078939648.0000\n",
      "Epoch 2659/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6703386624.0000 - val_loss: 7107395072.0000\n",
      "Epoch 2660/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7243115520.0000 - val_loss: 7535434240.0000\n",
      "Epoch 2661/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6899767296.0000 - val_loss: 6990749184.0000\n",
      "Epoch 2662/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6823386112.0000 - val_loss: 6956639744.0000\n",
      "Epoch 2663/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6823941120.0000 - val_loss: 8144701952.0000\n",
      "Epoch 2664/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6989693440.0000 - val_loss: 7263030784.0000\n",
      "Epoch 2665/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7005694464.0000 - val_loss: 8323587584.0000\n",
      "Epoch 2666/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6804839424.0000 - val_loss: 7171978240.0000\n",
      "Epoch 2667/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6995981824.0000 - val_loss: 7740515328.0000\n",
      "Epoch 2668/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7154058752.0000 - val_loss: 8026204672.0000\n",
      "Epoch 2669/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6880829440.0000 - val_loss: 7203582464.0000\n",
      "Epoch 2670/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6795889152.0000 - val_loss: 8016650240.0000\n",
      "Epoch 2671/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6988178432.0000 - val_loss: 7533541888.0000\n",
      "Epoch 2672/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6816989184.0000 - val_loss: 7873755136.0000\n",
      "Epoch 2673/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7187483648.0000 - val_loss: 7356880384.0000\n",
      "Epoch 2674/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6965429248.0000 - val_loss: 8727054336.0000\n",
      "Epoch 2675/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6835966976.0000 - val_loss: 7054879232.0000\n",
      "Epoch 2676/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6925019136.0000 - val_loss: 6983997952.0000\n",
      "Epoch 2677/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6866125824.0000 - val_loss: 7573205504.0000\n",
      "Epoch 2678/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6902499328.0000 - val_loss: 7462654464.0000\n",
      "Epoch 2679/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7032501248.0000 - val_loss: 7032937472.0000\n",
      "Epoch 2680/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6997153280.0000 - val_loss: 8555053568.0000\n",
      "Epoch 2681/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7054607872.0000 - val_loss: 7363314688.0000\n",
      "Epoch 2682/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6803202560.0000 - val_loss: 7799546368.0000\n",
      "Epoch 2683/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6861090304.0000 - val_loss: 7039138816.0000\n",
      "Epoch 2684/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6918072832.0000 - val_loss: 7150809600.0000\n",
      "Epoch 2685/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7028849664.0000 - val_loss: 7298244608.0000\n",
      "Epoch 2686/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6989702144.0000 - val_loss: 7528786944.0000\n",
      "Epoch 2687/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7209765376.0000 - val_loss: 7446191104.0000\n",
      "Epoch 2688/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7058247168.0000 - val_loss: 7000072704.0000\n",
      "Epoch 2689/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7193753088.0000 - val_loss: 11532067840.0000\n",
      "Epoch 2690/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7318466048.0000 - val_loss: 7075742720.0000\n",
      "Epoch 2691/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6958043648.0000 - val_loss: 7235354624.0000\n",
      "Epoch 2692/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6763264000.0000 - val_loss: 8329701888.0000\n",
      "Epoch 2693/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7165441024.0000 - val_loss: 7136284672.0000\n",
      "Epoch 2694/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6871208448.0000 - val_loss: 7056427008.0000\n",
      "Epoch 2695/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6776898048.0000 - val_loss: 11010201600.0000\n",
      "Epoch 2696/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7136701952.0000 - val_loss: 8350829056.0000\n",
      "Epoch 2697/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7180121600.0000 - val_loss: 7163267584.0000\n",
      "Epoch 2698/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6814597632.0000 - val_loss: 7193986048.0000\n",
      "Epoch 2699/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7003456000.0000 - val_loss: 8026465792.0000\n",
      "Epoch 2700/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6883720192.0000 - val_loss: 6963515392.0000\n",
      "Epoch 2701/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6775918592.0000 - val_loss: 7245710848.0000\n",
      "Epoch 2702/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6679101440.0000 - val_loss: 6962381824.0000\n",
      "Epoch 2703/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6893442048.0000 - val_loss: 7345195520.0000\n",
      "Epoch 2704/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6934158848.0000 - val_loss: 6978341888.0000\n",
      "Epoch 2705/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7053623296.0000 - val_loss: 8800464896.0000\n",
      "Epoch 2706/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971144704.0000 - val_loss: 7143746048.0000\n",
      "Epoch 2707/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6716302848.0000 - val_loss: 6939133952.0000\n",
      "Epoch 2708/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7028484608.0000 - val_loss: 7939134464.0000\n",
      "Epoch 2709/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7012085760.0000 - val_loss: 7475905536.0000\n",
      "Epoch 2710/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6911080448.0000 - val_loss: 7478918656.0000\n",
      "Epoch 2711/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6925656576.0000 - val_loss: 7060755456.0000\n",
      "Epoch 2712/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6980324352.0000 - val_loss: 7223523840.0000\n",
      "Epoch 2713/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7155564544.0000 - val_loss: 8421742080.0000\n",
      "Epoch 2714/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6871532032.0000 - val_loss: 7037873664.0000\n",
      "Epoch 2715/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6887172096.0000 - val_loss: 7344708096.0000\n",
      "Epoch 2716/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6859248640.0000 - val_loss: 7128329728.0000\n",
      "Epoch 2717/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6862380032.0000 - val_loss: 7200993792.0000\n",
      "Epoch 2718/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7036341248.0000 - val_loss: 6988970496.0000\n",
      "Epoch 2719/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7081030656.0000 - val_loss: 7065459712.0000\n",
      "Epoch 2720/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7111726080.0000 - val_loss: 7086048256.0000\n",
      "Epoch 2721/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971644416.0000 - val_loss: 7055168000.0000\n",
      "Epoch 2722/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6897499136.0000 - val_loss: 7634493952.0000\n",
      "Epoch 2723/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7102233600.0000 - val_loss: 9661030400.0000\n",
      "Epoch 2724/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7014006272.0000 - val_loss: 7116809216.0000\n",
      "Epoch 2725/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6882408960.0000 - val_loss: 7243030528.0000\n",
      "Epoch 2726/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6892094464.0000 - val_loss: 7661921792.0000\n",
      "Epoch 2727/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6810903552.0000 - val_loss: 6964269056.0000\n",
      "Epoch 2728/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6991292928.0000 - val_loss: 7196868096.0000\n",
      "Epoch 2729/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7177185792.0000 - val_loss: 7857889280.0000\n",
      "Epoch 2730/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6994216960.0000 - val_loss: 7026244608.0000\n",
      "Epoch 2731/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7113269760.0000 - val_loss: 7463715328.0000\n",
      "Epoch 2732/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6854173696.0000 - val_loss: 7322227200.0000\n",
      "Epoch 2733/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6937472000.0000 - val_loss: 9174252544.0000\n",
      "Epoch 2734/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6905878016.0000 - val_loss: 7036987392.0000\n",
      "Epoch 2735/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6681482240.0000 - val_loss: 7058971648.0000\n",
      "Epoch 2736/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6928208384.0000 - val_loss: 7767564800.0000\n",
      "Epoch 2737/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7035425792.0000 - val_loss: 7086648320.0000\n",
      "Epoch 2738/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7386991104.0000 - val_loss: 7575663104.0000\n",
      "Epoch 2739/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6975826432.0000 - val_loss: 7083056640.0000\n",
      "Epoch 2740/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6858079744.0000 - val_loss: 7140457984.0000\n",
      "Epoch 2741/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6895700992.0000 - val_loss: 7466832384.0000\n",
      "Epoch 2742/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6865698816.0000 - val_loss: 7130472448.0000\n",
      "Epoch 2743/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6849121792.0000 - val_loss: 7067769856.0000\n",
      "Epoch 2744/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6960536576.0000 - val_loss: 7062270976.0000\n",
      "Epoch 2745/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6750933504.0000 - val_loss: 8029094400.0000\n",
      "Epoch 2746/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6997224960.0000 - val_loss: 7402291200.0000\n",
      "Epoch 2747/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6854332416.0000 - val_loss: 7258997760.0000\n",
      "Epoch 2748/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7016532480.0000 - val_loss: 7572916736.0000\n",
      "Epoch 2749/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6768274944.0000 - val_loss: 7996827136.0000\n",
      "Epoch 2750/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6933511680.0000 - val_loss: 7689656320.0000\n",
      "Epoch 2751/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6940177408.0000 - val_loss: 7110596096.0000\n",
      "Epoch 2752/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6795588096.0000 - val_loss: 11454587904.0000\n",
      "Epoch 2753/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6971503104.0000 - val_loss: 7513872896.0000\n",
      "Epoch 2754/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7157270528.0000 - val_loss: 7063891968.0000\n",
      "Epoch 2755/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6852876288.0000 - val_loss: 6990289920.0000\n",
      "Epoch 2756/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6794831872.0000 - val_loss: 6974305280.0000\n",
      "Epoch 2757/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7044272640.0000 - val_loss: 7033825280.0000\n",
      "Epoch 2758/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6824379392.0000 - val_loss: 6947853312.0000\n",
      "Epoch 2759/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7303171072.0000 - val_loss: 7473807360.0000\n",
      "Epoch 2760/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6952800256.0000 - val_loss: 7014631424.0000\n",
      "Epoch 2761/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6892924416.0000 - val_loss: 7261356544.0000\n",
      "Epoch 2762/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6953099264.0000 - val_loss: 7520466432.0000\n",
      "Epoch 2763/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7074419712.0000 - val_loss: 7326726656.0000\n",
      "Epoch 2764/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6668137984.0000 - val_loss: 7777090560.0000\n",
      "Epoch 2765/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6861508608.0000 - val_loss: 6976499200.0000\n",
      "Epoch 2766/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6738796544.0000 - val_loss: 7354465792.0000\n",
      "Epoch 2767/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6816135680.0000 - val_loss: 7020749312.0000\n",
      "Epoch 2768/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7199881216.0000 - val_loss: 7142952448.0000\n",
      "Epoch 2769/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6909323776.0000 - val_loss: 8100591616.0000\n",
      "Epoch 2770/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6940719616.0000 - val_loss: 7120894464.0000\n",
      "Epoch 2771/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6696643584.0000 - val_loss: 7035754496.0000\n",
      "Epoch 2772/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6925421056.0000 - val_loss: 6973571072.0000\n",
      "Epoch 2773/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7119030272.0000 - val_loss: 7092284416.0000\n",
      "Epoch 2774/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7209158656.0000 - val_loss: 7390361600.0000\n",
      "Epoch 2775/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6844717056.0000 - val_loss: 6950599168.0000\n",
      "Epoch 2776/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6797346816.0000 - val_loss: 7091122688.0000\n",
      "Epoch 2777/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6935994368.0000 - val_loss: 7110889984.0000\n",
      "Epoch 2778/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6825784832.0000 - val_loss: 7100733440.0000\n",
      "Epoch 2779/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6812226560.0000 - val_loss: 7826477056.0000\n",
      "Epoch 2780/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6827047936.0000 - val_loss: 7056356352.0000\n",
      "Epoch 2781/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6781319168.0000 - val_loss: 7453760512.0000\n",
      "Epoch 2782/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6848159232.0000 - val_loss: 7219599872.0000\n",
      "Epoch 2783/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6881614336.0000 - val_loss: 8029926912.0000\n",
      "Epoch 2784/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7285716480.0000 - val_loss: 6985580544.0000\n",
      "Epoch 2785/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6764202496.0000 - val_loss: 7412027392.0000\n",
      "Epoch 2786/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6880399360.0000 - val_loss: 6964861952.0000\n",
      "Epoch 2787/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6956061696.0000 - val_loss: 7261780480.0000\n",
      "Epoch 2788/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7042617856.0000 - val_loss: 7872574976.0000\n",
      "Epoch 2789/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7098247680.0000 - val_loss: 7214232576.0000\n",
      "Epoch 2790/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7000927232.0000 - val_loss: 6991723520.0000\n",
      "Epoch 2791/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6693195776.0000 - val_loss: 7278918144.0000\n",
      "Epoch 2792/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6940598784.0000 - val_loss: 8593148928.0000\n",
      "Epoch 2793/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6921017344.0000 - val_loss: 7040118272.0000\n",
      "Epoch 2794/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6803855360.0000 - val_loss: 7248771072.0000\n",
      "Epoch 2795/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7024711680.0000 - val_loss: 6969371648.0000\n",
      "Epoch 2796/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6843031552.0000 - val_loss: 7041729024.0000\n",
      "Epoch 2797/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7127360000.0000 - val_loss: 7023324160.0000\n",
      "Epoch 2798/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6817997312.0000 - val_loss: 6989693952.0000\n",
      "Epoch 2799/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6881567744.0000 - val_loss: 7032214016.0000\n",
      "Epoch 2800/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6786167808.0000 - val_loss: 8206665216.0000\n",
      "Epoch 2801/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6886036480.0000 - val_loss: 7062537728.0000\n",
      "Epoch 2802/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6839826944.0000 - val_loss: 6976712192.0000\n",
      "Epoch 2803/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6733694464.0000 - val_loss: 7026584576.0000\n",
      "Epoch 2804/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6828160000.0000 - val_loss: 7369072128.0000\n",
      "Epoch 2805/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6722473984.0000 - val_loss: 7024308736.0000\n",
      "Epoch 2806/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7290333184.0000 - val_loss: 7699491840.0000\n",
      "Epoch 2807/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7263772160.0000 - val_loss: 7227556864.0000\n",
      "Epoch 2808/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6985278976.0000 - val_loss: 7305127424.0000\n",
      "Epoch 2809/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900662272.0000 - val_loss: 7001067520.0000\n",
      "Epoch 2810/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6682609664.0000 - val_loss: 8350044672.0000\n",
      "Epoch 2811/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6920713216.0000 - val_loss: 7362243072.0000\n",
      "Epoch 2812/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7049319936.0000 - val_loss: 7306959360.0000\n",
      "Epoch 2813/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6793566720.0000 - val_loss: 7051429376.0000\n",
      "Epoch 2814/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6714866176.0000 - val_loss: 8895924224.0000\n",
      "Epoch 2815/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7231606784.0000 - val_loss: 8341988864.0000\n",
      "Epoch 2816/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6952556544.0000 - val_loss: 6984290304.0000\n",
      "Epoch 2817/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7159680000.0000 - val_loss: 8119848448.0000\n",
      "Epoch 2818/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6885000704.0000 - val_loss: 7083580928.0000\n",
      "Epoch 2819/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6821043712.0000 - val_loss: 7263801344.0000\n",
      "Epoch 2820/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7364923392.0000 - val_loss: 7291166720.0000\n",
      "Epoch 2821/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7150284288.0000 - val_loss: 7433157632.0000\n",
      "Epoch 2822/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7132801536.0000 - val_loss: 7355768832.0000\n",
      "Epoch 2823/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131956224.0000 - val_loss: 9247337472.0000\n",
      "Epoch 2824/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6739426304.0000 - val_loss: 7041865216.0000\n",
      "Epoch 2825/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6628631552.0000 - val_loss: 7312459776.0000\n",
      "Epoch 2826/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 6881072128.0000 - val_loss: 7205977088.0000\n",
      "Epoch 2827/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6772541440.0000 - val_loss: 7779978240.0000\n",
      "Epoch 2828/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7218138624.0000 - val_loss: 10119618560.0000\n",
      "Epoch 2829/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6941257216.0000 - val_loss: 7209754112.0000\n",
      "Epoch 2830/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6811394048.0000 - val_loss: 6986619392.0000\n",
      "Epoch 2831/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6947127808.0000 - val_loss: 7976701440.0000\n",
      "Epoch 2832/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6716157440.0000 - val_loss: 7064636928.0000\n",
      "Epoch 2833/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6823426560.0000 - val_loss: 8117375488.0000\n",
      "Epoch 2834/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7132731904.0000 - val_loss: 7060647936.0000\n",
      "Epoch 2835/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6723873792.0000 - val_loss: 7217425920.0000\n",
      "Epoch 2836/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6667018752.0000 - val_loss: 7403581952.0000\n",
      "Epoch 2837/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6726371328.0000 - val_loss: 8016176128.0000\n",
      "Epoch 2838/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7030698496.0000 - val_loss: 7150135296.0000\n",
      "Epoch 2839/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7078504448.0000 - val_loss: 7041743360.0000\n",
      "Epoch 2840/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6827751936.0000 - val_loss: 7425736192.0000\n",
      "Epoch 2841/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6948264960.0000 - val_loss: 7014758400.0000\n",
      "Epoch 2842/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6754493952.0000 - val_loss: 7856821248.0000\n",
      "Epoch 2843/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6816018944.0000 - val_loss: 7024427520.0000\n",
      "Epoch 2844/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6852370944.0000 - val_loss: 7065405440.0000\n",
      "Epoch 2845/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6818722304.0000 - val_loss: 7580640256.0000\n",
      "Epoch 2846/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6903665664.0000 - val_loss: 7274286080.0000\n",
      "Epoch 2847/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004930048.0000 - val_loss: 7641955840.0000\n",
      "Epoch 2848/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6823993344.0000 - val_loss: 6951538688.0000\n",
      "Epoch 2849/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7139145216.0000 - val_loss: 6998093824.0000\n",
      "Epoch 2850/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7008946176.0000 - val_loss: 7253600768.0000\n",
      "Epoch 2851/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7589014016.0000 - val_loss: 8230944768.0000\n",
      "Epoch 2852/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7161019392.0000 - val_loss: 7017017344.0000\n",
      "Epoch 2853/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6686955008.0000 - val_loss: 7755165184.0000\n",
      "Epoch 2854/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6903987200.0000 - val_loss: 7341213184.0000\n",
      "Epoch 2855/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6654034432.0000 - val_loss: 7062540800.0000\n",
      "Epoch 2856/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152547840.0000 - val_loss: 7030892032.0000\n",
      "Epoch 2857/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6935296512.0000 - val_loss: 6893804544.0000\n",
      "Epoch 2858/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7093790208.0000 - val_loss: 7970937856.0000\n",
      "Epoch 2859/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6845364736.0000 - val_loss: 7017575424.0000\n",
      "Epoch 2860/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6792221184.0000 - val_loss: 7036318720.0000\n",
      "Epoch 2861/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7054522880.0000 - val_loss: 6963665920.0000\n",
      "Epoch 2862/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7140417024.0000 - val_loss: 8024591360.0000\n",
      "Epoch 2863/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6922632192.0000 - val_loss: 7095160832.0000\n",
      "Epoch 2864/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6742579712.0000 - val_loss: 7574702592.0000\n",
      "Epoch 2865/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6913111552.0000 - val_loss: 7441518592.0000\n",
      "Epoch 2866/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6697229824.0000 - val_loss: 6919799808.0000\n",
      "Epoch 2867/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6810610176.0000 - val_loss: 7037968896.0000\n",
      "Epoch 2868/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6765776384.0000 - val_loss: 7179060736.0000\n",
      "Epoch 2869/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6728185856.0000 - val_loss: 6930931712.0000\n",
      "Epoch 2870/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7113443840.0000 - val_loss: 7103408640.0000\n",
      "Epoch 2871/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6943488000.0000 - val_loss: 7100457984.0000\n",
      "Epoch 2872/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7004596224.0000 - val_loss: 6966732288.0000\n",
      "Epoch 2873/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6851450368.0000 - val_loss: 7606881280.0000\n",
      "Epoch 2874/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7096927232.0000 - val_loss: 7106763776.0000\n",
      "Epoch 2875/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6735153664.0000 - val_loss: 7596388864.0000\n",
      "Epoch 2876/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6890085888.0000 - val_loss: 6938800640.0000\n",
      "Epoch 2877/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6885847552.0000 - val_loss: 7036904448.0000\n",
      "Epoch 2878/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6886455808.0000 - val_loss: 7027838464.0000\n",
      "Epoch 2879/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6680594432.0000 - val_loss: 8464951296.0000\n",
      "Epoch 2880/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6931457536.0000 - val_loss: 7356163072.0000\n",
      "Epoch 2881/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6782498304.0000 - val_loss: 7051743744.0000\n",
      "Epoch 2882/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7037922816.0000 - val_loss: 7990956544.0000\n",
      "Epoch 2883/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7131684352.0000 - val_loss: 6905792512.0000\n",
      "Epoch 2884/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6761455104.0000 - val_loss: 7744417792.0000\n",
      "Epoch 2885/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7024329728.0000 - val_loss: 9424614400.0000\n",
      "Epoch 2886/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7304274944.0000 - val_loss: 7580902912.0000\n",
      "Epoch 2887/3000\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 7012783616.0000 - val_loss: 7014996992.0000\n",
      "Epoch 2888/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6791808000.0000 - val_loss: 7068311040.0000\n",
      "Epoch 2889/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7007575040.0000 - val_loss: 7030767616.0000\n",
      "Epoch 2890/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6878311936.0000 - val_loss: 7039216128.0000\n",
      "Epoch 2891/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6975591424.0000 - val_loss: 7055749120.0000\n",
      "Epoch 2892/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6803529728.0000 - val_loss: 7406756352.0000\n",
      "Epoch 2893/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6795219968.0000 - val_loss: 7944408576.0000\n",
      "Epoch 2894/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7090999296.0000 - val_loss: 10399850496.0000\n",
      "Epoch 2895/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7346507776.0000 - val_loss: 7084635136.0000\n",
      "Epoch 2896/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6785155072.0000 - val_loss: 7031653376.0000\n",
      "Epoch 2897/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6774201856.0000 - val_loss: 6997144576.0000\n",
      "Epoch 2898/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6896662016.0000 - val_loss: 6939179008.0000\n",
      "Epoch 2899/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6692688384.0000 - val_loss: 6983027712.0000\n",
      "Epoch 2900/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6765351424.0000 - val_loss: 7036135424.0000\n",
      "Epoch 2901/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6788193280.0000 - val_loss: 7609568256.0000\n",
      "Epoch 2902/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6891811328.0000 - val_loss: 7351985152.0000\n",
      "Epoch 2903/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6842785280.0000 - val_loss: 7053569024.0000\n",
      "Epoch 2904/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7081748480.0000 - val_loss: 8101323776.0000\n",
      "Epoch 2905/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6895669760.0000 - val_loss: 7218738688.0000\n",
      "Epoch 2906/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6997836288.0000 - val_loss: 7126254592.0000\n",
      "Epoch 2907/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6698238464.0000 - val_loss: 8574623232.0000\n",
      "Epoch 2908/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942626816.0000 - val_loss: 7398567936.0000\n",
      "Epoch 2909/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6696865792.0000 - val_loss: 7181205504.0000\n",
      "Epoch 2910/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6926998016.0000 - val_loss: 8545761280.0000\n",
      "Epoch 2911/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7220645888.0000 - val_loss: 8439340544.0000\n",
      "Epoch 2912/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7075536384.0000 - val_loss: 6964924416.0000\n",
      "Epoch 2913/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6897027584.0000 - val_loss: 7244327936.0000\n",
      "Epoch 2914/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6818464768.0000 - val_loss: 7038185472.0000\n",
      "Epoch 2915/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6678643712.0000 - val_loss: 7035762688.0000\n",
      "Epoch 2916/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6825843712.0000 - val_loss: 7103994368.0000\n",
      "Epoch 2917/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6845584896.0000 - val_loss: 9220168704.0000\n",
      "Epoch 2918/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6875308032.0000 - val_loss: 7029968896.0000\n",
      "Epoch 2919/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6803487232.0000 - val_loss: 6899127296.0000\n",
      "Epoch 2920/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6943092736.0000 - val_loss: 7229350912.0000\n",
      "Epoch 2921/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6763111424.0000 - val_loss: 7888477696.0000\n",
      "Epoch 2922/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6845578752.0000 - val_loss: 7351627264.0000\n",
      "Epoch 2923/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6836396032.0000 - val_loss: 7792181248.0000\n",
      "Epoch 2924/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7134436352.0000 - val_loss: 7195022848.0000\n",
      "Epoch 2925/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6722748928.0000 - val_loss: 6983821312.0000\n",
      "Epoch 2926/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6844457472.0000 - val_loss: 6957544448.0000\n",
      "Epoch 2927/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6858209792.0000 - val_loss: 9036637184.0000\n",
      "Epoch 2928/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7072409600.0000 - val_loss: 8876962816.0000\n",
      "Epoch 2929/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6934023680.0000 - val_loss: 7100494336.0000\n",
      "Epoch 2930/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6711272448.0000 - val_loss: 7020245504.0000\n",
      "Epoch 2931/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6807388672.0000 - val_loss: 6936364032.0000\n",
      "Epoch 2932/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7035546624.0000 - val_loss: 7340184576.0000\n",
      "Epoch 2933/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6677807616.0000 - val_loss: 7130087936.0000\n",
      "Epoch 2934/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6896936960.0000 - val_loss: 6937307648.0000\n",
      "Epoch 2935/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6863958016.0000 - val_loss: 7071250432.0000\n",
      "Epoch 2936/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7008439808.0000 - val_loss: 9108624384.0000\n",
      "Epoch 2937/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6957581824.0000 - val_loss: 6982662144.0000\n",
      "Epoch 2938/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6681001472.0000 - val_loss: 7075157504.0000\n",
      "Epoch 2939/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7051887104.0000 - val_loss: 6919418368.0000\n",
      "Epoch 2940/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7118416896.0000 - val_loss: 7110929920.0000\n",
      "Epoch 2941/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6810772992.0000 - val_loss: 7409405440.0000\n",
      "Epoch 2942/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6902182400.0000 - val_loss: 7018948608.0000\n",
      "Epoch 2943/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6957212672.0000 - val_loss: 7899760128.0000\n",
      "Epoch 2944/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6861493760.0000 - val_loss: 8563949056.0000\n",
      "Epoch 2945/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6888454656.0000 - val_loss: 6965120512.0000\n",
      "Epoch 2946/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6807559168.0000 - val_loss: 8145575424.0000\n",
      "Epoch 2947/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7060028928.0000 - val_loss: 7202572288.0000\n",
      "Epoch 2948/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7121161728.0000 - val_loss: 7514578432.0000\n",
      "Epoch 2949/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6838162432.0000 - val_loss: 7369233920.0000\n",
      "Epoch 2950/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6778236416.0000 - val_loss: 7454525440.0000\n",
      "Epoch 2951/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6892967936.0000 - val_loss: 8413386240.0000\n",
      "Epoch 2952/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6882851840.0000 - val_loss: 7177211904.0000\n",
      "Epoch 2953/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6855863296.0000 - val_loss: 7114350080.0000\n",
      "Epoch 2954/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6942391808.0000 - val_loss: 8704976896.0000\n",
      "Epoch 2955/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6903778304.0000 - val_loss: 6998500864.0000\n",
      "Epoch 2956/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6707785216.0000 - val_loss: 7051838976.0000\n",
      "Epoch 2957/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6901651968.0000 - val_loss: 7023716864.0000\n",
      "Epoch 2958/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6939744768.0000 - val_loss: 7134823424.0000\n",
      "Epoch 2959/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6855194624.0000 - val_loss: 7118824960.0000\n",
      "Epoch 2960/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6938956288.0000 - val_loss: 8012871680.0000\n",
      "Epoch 2961/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6814876160.0000 - val_loss: 6964271616.0000\n",
      "Epoch 2962/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6810565632.0000 - val_loss: 7184484352.0000\n",
      "Epoch 2963/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7023221760.0000 - val_loss: 8063698432.0000\n",
      "Epoch 2964/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7163001344.0000 - val_loss: 7382355456.0000\n",
      "Epoch 2965/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7120842752.0000 - val_loss: 7127809024.0000\n",
      "Epoch 2966/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6967744512.0000 - val_loss: 7144742400.0000\n",
      "Epoch 2967/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7101748224.0000 - val_loss: 7132578304.0000\n",
      "Epoch 2968/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6885156864.0000 - val_loss: 7057933312.0000\n",
      "Epoch 2969/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6925273600.0000 - val_loss: 7539089408.0000\n",
      "Epoch 2970/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6757190656.0000 - val_loss: 7703627264.0000\n",
      "Epoch 2971/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6935797760.0000 - val_loss: 8627575808.0000\n",
      "Epoch 2972/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6829306880.0000 - val_loss: 7168718336.0000\n",
      "Epoch 2973/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6846657024.0000 - val_loss: 6926844928.0000\n",
      "Epoch 2974/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6857681920.0000 - val_loss: 8199208960.0000\n",
      "Epoch 2975/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7054359040.0000 - val_loss: 7041346048.0000\n",
      "Epoch 2976/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6722611712.0000 - val_loss: 8500022272.0000\n",
      "Epoch 2977/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900988928.0000 - val_loss: 7219603456.0000\n",
      "Epoch 2978/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6904184320.0000 - val_loss: 7995151872.0000\n",
      "Epoch 2979/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6840196096.0000 - val_loss: 7071304704.0000\n",
      "Epoch 2980/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6900993536.0000 - val_loss: 7042544640.0000\n",
      "Epoch 2981/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7207683072.0000 - val_loss: 6981109760.0000\n",
      "Epoch 2982/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6871881216.0000 - val_loss: 6994217984.0000\n",
      "Epoch 2983/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6888631296.0000 - val_loss: 6965978624.0000\n",
      "Epoch 2984/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7086659072.0000 - val_loss: 8116270592.0000\n",
      "Epoch 2985/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6830713344.0000 - val_loss: 6990682624.0000\n",
      "Epoch 2986/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7082169856.0000 - val_loss: 6910112768.0000\n",
      "Epoch 2987/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7152090624.0000 - val_loss: 7011291136.0000\n",
      "Epoch 2988/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6779962880.0000 - val_loss: 7627144704.0000\n",
      "Epoch 2989/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6870236160.0000 - val_loss: 6943680512.0000\n",
      "Epoch 2990/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6784566272.0000 - val_loss: 7968654336.0000\n",
      "Epoch 2991/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7378063360.0000 - val_loss: 7144638976.0000\n",
      "Epoch 2992/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6885942272.0000 - val_loss: 6955828736.0000\n",
      "Epoch 2993/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6841269248.0000 - val_loss: 8977141760.0000\n",
      "Epoch 2994/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6888166912.0000 - val_loss: 7058081792.0000\n",
      "Epoch 2995/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7026156032.0000 - val_loss: 7204992512.0000\n",
      "Epoch 2996/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6690500608.0000 - val_loss: 6908860928.0000\n",
      "Epoch 2997/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 7052754432.0000 - val_loss: 6919607296.0000\n",
      "Epoch 2998/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6839346176.0000 - val_loss: 7298577408.0000\n",
      "Epoch 2999/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6666146304.0000 - val_loss: 8231900160.0000\n",
      "Epoch 3000/3000\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 6995564544.0000 - val_loss: 6985606656.0000\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 19)                1634      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,794\n",
      "Trainable params: 2,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y= y_train, validation_data= (x_test, y_test), batch_size= 128, epochs= 3000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 895us/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83579.94523153733"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, predict))**.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8331266839114195"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
